{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import abc\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.seq2seq as seq2seq\n",
    "from tensorflow.contrib.rnn import LSTMCell, LSTMStateTuple, GRUCell\n",
    "from tensorflow.python.layers import core as layers_core\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqModel():\n",
    "    def foo(self):\n",
    "        return self.logits\n",
    "    def __init__(self, mode, src_vocab_size, tgt_vocab_size, embedding_size, batch_size, learning_rate, beam_search = False,\n",
    "                 beam_width = 5):\n",
    "        self.mode = mode\n",
    "        self.beam_search = beam_search\n",
    "        self.beam_width = beam_width\n",
    "        self.learning_rate = learning_rate\n",
    "        self._init_placeholders()\n",
    "        self._init_embeddings(src_vocab_size, tgt_vocab_size, embedding_size)\n",
    "        self._init_bidirectional_encoder()\n",
    "        self._init_decoder(tgt_vocab_size, batch_size)\n",
    "        self._init_optimizer(batch_size)\n",
    "        \n",
    "    def _init_debug(self):\n",
    "        self.encoder_inputs = tf.Variable(np.array([[3, 3, 3, 3],[3, 3, 0, 0],[3, 0, 0, 0]]),dtype=np.int32)\n",
    "        self.encoder_input_length = tf.constant(np.array([4,2,1]),dtype=np.int32)\n",
    "\n",
    "        self.decoder_inputs = tf.Variable(np.array([[1, 3, 4, 2, 0],[1, 4, 2, 0, 0],[1, 3, 3, 3, 2]]),dtype=np.int32)\n",
    "        self.decoder_input_length = tf.constant(np.array([4,3,5]),dtype=np.int32)\n",
    "        self.decoder_outputs = tf.Variable(np.array([[1, 3, 4, 2, 0],[1, 4, 2, 0, 0],[1, 3, 3, 3, 2]]),dtype=np.int32)\n",
    "\n",
    "    def _init_placeholders(self):\n",
    "        self.encoder1_inputs = tf.placeholder(\n",
    "            shape=(None, None),\n",
    "            dtype=tf.int32,\n",
    "            name='encoder_inputs',\n",
    "        )\n",
    "        self.encoder2_inputs = tf.placeholder(\n",
    "            shape=(None, None),\n",
    "            dtype=tf.int32,\n",
    "            name='encoder_inputs',\n",
    "        )\n",
    "        self.decoder_inputs = tf.placeholder(\n",
    "            shape=(None, None),\n",
    "            dtype=tf.int32,\n",
    "            name='decoder_inputs',\n",
    "        )\n",
    "        self.decoder_input_length = tf.placeholder(\n",
    "            shape=(None,),\n",
    "            dtype=tf.int32,\n",
    "            name='decoder_input_length',\n",
    "        )\n",
    "        self.decoder_outputs = tf.placeholder(\n",
    "            shape=(None,None),\n",
    "            dtype=tf.int32,\n",
    "            name='decoder_outputs',\n",
    "        )\n",
    "        self.training=tf.placeholder(dtype=tf.bool)\n",
    "    \n",
    "    def _init_embeddings(self, src_vocab_size, tgt_vocab_size, embedding_size):\n",
    "        with tf.variable_scope(\"embedding\", reuse=tf.AUTO_REUSE) as scope:\n",
    "\n",
    "            # Uniform(-sqrt(3), sqrt(3)) has variance=1.\n",
    "            sqrt3 = math.sqrt(3)\n",
    "            initializer = tf.random_uniform_initializer(-sqrt3, sqrt3)\n",
    "\n",
    "            self.encoder_embedding_matrix = tf.get_variable(\n",
    "                name=\"encoder_embedding_matrix\",\n",
    "                shape=[src_vocab_size, embedding_size],\n",
    "                initializer=initializer,\n",
    "                dtype=tf.float32)\n",
    "            \n",
    "            self.decoder_embedding_matrix = tf.get_variable(\n",
    "                name=\"decoder_embedding_matrix\",\n",
    "                shape=[tgt_vocab_size, embedding_size],\n",
    "                initializer=initializer,\n",
    "                dtype=tf.float32)\n",
    "\n",
    "            self.decoder_inputs_embedded = tf.nn.embedding_lookup(\n",
    "                self.decoder_embedding_matrix, self.decoder_inputs)  \n",
    "            \n",
    "    def _init_bidirectional_encoder(self):\n",
    "        \n",
    "        with tf.variable_scope(\"BidirectionalEncoder\", reuse=tf.AUTO_REUSE) as scope:\n",
    "            \n",
    "            encoder_cell1 = LSTMCell(512)\n",
    "            encoder_cell2 = LSTMCell(512)\n",
    "            \n",
    "            self.encoder_states = []\n",
    "            \n",
    "            for i in range(20):\n",
    "                self.encoder1_inputs_embedded = tf.nn.embedding_lookup(\n",
    "                    self.encoder_embedding_matrix, self.encoder1_inputs[i*10:(i*10)+10,:])\n",
    "\n",
    "                self.encoder2_inputs_embedded = tf.nn.embedding_lookup(\n",
    "                    self.encoder_embedding_matrix, self.encoder2_inputs[i,:])\n",
    "\n",
    "                ((encoder_fw_outputs,\n",
    "                  encoder_bw_outputs),\n",
    "                 (encoder_fw_state,\n",
    "                  encoder_bw_state)) = (\n",
    "                    tf.nn.bidirectional_dynamic_rnn(cell_fw=encoder_cell1,\n",
    "                                                    cell_bw=encoder_cell1,\n",
    "                                                    inputs=self.encoder1_inputs_embedded,\n",
    "                                                    time_major=True,\n",
    "                                                    dtype=tf.float32)\n",
    "                    )\n",
    "\n",
    "                \n",
    "                if isinstance(encoder_fw_state, LSTMStateTuple):\n",
    "\n",
    "                    encoder_state_c = tf.concat(\n",
    "                        (encoder_fw_state.c, encoder_bw_state.c), 1, name='bidirectional_concat_c')\n",
    "                    encoder_state_h = tf.concat(\n",
    "                        (encoder_fw_state.h, encoder_bw_state.h), 1, name='bidirectional_concat_h')\n",
    "                    self.encoder_state = LSTMStateTuple(c=encoder_state_c, h=encoder_state_h)\n",
    "\n",
    "                elif isinstance(encoder_fw_state, tf.Tensor):\n",
    "                    self.encoder_state = tf.concat((encoder_fw_state, encoder_bw_state), 2, name='bidirectional_concat')\n",
    "\n",
    "                #self.encoder_states.append(tf.layers.dropout(self.encoder_state.c,training=self.training,rate=0.5))\n",
    "                self.encoder_states.append(tf.layers.dropout(tf.concat((self.encoder_state.c, self.encoder2_inputs_embedded), 1),\n",
    "                                                            training=self.training,rate=0.5))\n",
    "                \n",
    "            self.encoder_states = tf.stack(self.encoder_states)\n",
    "            print(self.encoder_states.get_shape())\n",
    "\n",
    "        with tf.variable_scope(\"BidirectionalEncoder1\", reuse=tf.AUTO_REUSE) as scope:\n",
    "            \n",
    "            ((encoder_fw_outputs,\n",
    "              encoder_bw_outputs),\n",
    "             (encoder_fw_state,\n",
    "              encoder_bw_state)) = (\n",
    "                tf.nn.bidirectional_dynamic_rnn(cell_fw=encoder_cell2,\n",
    "                                                cell_bw=encoder_cell2,\n",
    "                                                inputs=self.encoder_states,\n",
    "                                                time_major=True,\n",
    "                                                dtype=tf.float32)\n",
    "                )\n",
    "            \n",
    "            if isinstance(encoder_fw_state, LSTMStateTuple):\n",
    "\n",
    "                encoder_state_c = tf.concat(\n",
    "                    (encoder_fw_state.c, encoder_bw_state.c), 1, name='bidirectional_concat_c')\n",
    "                encoder_state_h = tf.concat(\n",
    "                    (encoder_fw_state.h, encoder_bw_state.h), 1, name='bidirectional_concat_h')\n",
    "                self.encoder_state = LSTMStateTuple(c=encoder_state_c, h=encoder_state_h)\n",
    "\n",
    "            elif isinstance(encoder_fw_state, tf.Tensor):\n",
    "                self.encoder_state = tf.concat((encoder_fw_state, encoder_bw_state), 2, name='bidirectional_concat')\n",
    "            self.encoder3_outputs = tf.concat((encoder_fw_outputs, encoder_bw_outputs), 2)\n",
    "            #self.encoder_state = tf.layers.dropout(self.encoder_state.c,training=self.training,rate=0.5)\n",
    "                \n",
    "    def _init_decoder(self, tgt_vocab_size, batch_size):\n",
    "        with tf.variable_scope(\"Decoder\", reuse=tf.AUTO_REUSE) as scope:\n",
    "            self.output_layer = layers_core.Dense(\n",
    "                                tgt_vocab_size, use_bias=False)\n",
    "            decoder_cell = LSTMCell(1024)\n",
    "\n",
    "            if self.mode == \"train\":\n",
    "                helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "                            self.decoder_inputs_embedded, self.decoder_input_length, time_major=True)\n",
    "\n",
    "                # Decoder\n",
    "                decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                    decoder_cell, helper, self.encoder_state, output_layer=self.output_layer)\n",
    "                # Dynamic decoding\n",
    "                outputs, _ , _ = tf.contrib.seq2seq.dynamic_decode(decoder)\n",
    "                self.logits = outputs.rnn_output\n",
    "                self.op = outputs.sample_id\n",
    "\n",
    "            else:\n",
    "                helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "                            self.decoder_embedding_matrix,\n",
    "                            start_tokens=tf.fill([batch_size], 0),\n",
    "                            end_token=1)\n",
    "\n",
    "                # Decoder\n",
    "                if self.beam_search:\n",
    "                    self.encoder_state = tf.contrib.seq2seq.tile_batch(\n",
    "                        self.encoder_state, multiplier=self.beam_width)\n",
    "\n",
    "                    # Define a beam-search decoder\n",
    "                    decoder = tf.contrib.seq2seq.BeamSearchDecoder(\n",
    "                            cell=decoder_cell,\n",
    "                            embedding=self.decoder_embedding_matrix,\n",
    "                            start_tokens=tf.fill([batch_size], 0),\n",
    "                            end_token=1,\n",
    "                            initial_state=self.encoder_state,\n",
    "                            beam_width=self.beam_width,\n",
    "                            output_layer=self.output_layer,\n",
    "                            length_penalty_weight=0.0)\n",
    "\n",
    "                else:\n",
    "                    decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                        decoder_cell, helper, self.encoder_state,\n",
    "                        output_layer=self.output_layer)\n",
    "                # Dynamic decoding\n",
    "                outputs, _ , _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "                    decoder, maximum_iterations=100)\n",
    "                if self.beam_search:\n",
    "                    self.op = outputs.predicted_ids\n",
    "                else:\n",
    "                    self.op = outputs.sample_id\n",
    "    \n",
    "    def _init_optimizer(self,batch_size):\n",
    "        if not self.beam_search and self.mode == 'train': \n",
    "            with tf.variable_scope(\"Optimizer\", reuse=tf.AUTO_REUSE) as scope:\n",
    "                #target_output = tf.transpose(self.decoder_outputs)\n",
    "                max_time = tf.reduce_max(self.decoder_input_length)\n",
    "                crossent = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                    labels=self.decoder_outputs, logits=self.logits)\n",
    "                #target_weights = tf.sequence_mask(\n",
    "                #    self.decoder_input_length, max_time, dtype=self.logits.dtype)\n",
    "                #target_weights = tf.transpose(target_weights)\n",
    "                self.loss = tf.reduce_sum(crossent)\n",
    "                self.train_op = tf.train.AdamOptimizer().minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def readFile(fileName,word2id):\n",
    "    with open(fileName) as f:\n",
    "        content = f.readlines()\n",
    "    content = [x.split() for x in content]\n",
    "    i = len(word2id)\n",
    "    for line in content:\n",
    "        for word in line:\n",
    "            if word not in word2id:\n",
    "                word2id[word] = i\n",
    "                i+=1\n",
    "    return content,word2id\n",
    "\n",
    "def sequence_converter(content, word2id):\n",
    "    \n",
    "    input_lengths = np.zeros(len(content))\n",
    "    \n",
    "    for i in range(len(content)):\n",
    "        for j in range(len(content[i])):\n",
    "            content[i][j] = word2id[content[i][j]]\n",
    "            \n",
    "    return np.array(content).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_vocab = {}\n",
    "\n",
    "encoder1_input, encoder_vocab = readFile('WeatherGov/train/train.proc',encoder_vocab)\n",
    "\n",
    "encoder2_input, encoder_vocab = readFile('WeatherGov/train/train.field',encoder_vocab)\n",
    "\n",
    "encoder1_input = sequence_converter(encoder1_input, encoder_vocab)\n",
    "encoder2_input = sequence_converter(encoder2_input, encoder_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_readFile(fileName):\n",
    "    with open(fileName) as f:\n",
    "        content = f.readlines()\n",
    "    content = [x.split() for x in content]\n",
    "    word2id = {}\n",
    "    word2id['sos'] = 0\n",
    "    word2id['eos'] = 1\n",
    "    i = 2\n",
    "    for line in content:\n",
    "        for word in line:\n",
    "            if word not in word2id:\n",
    "                word2id[word] = i\n",
    "                i+=1\n",
    "    return content,word2id\n",
    "\n",
    "def d_sequence_converter(content, word2id, decoder_inputs = False, no_pad = False):\n",
    "    \n",
    "    input_max_length = 0\n",
    "    input_lengths = np.zeros(len(content))\n",
    "    \n",
    "    for i in range(len(content)):\n",
    "        for j in range(len(content[i])):\n",
    "            input_lengths[i] = len(content[i])\n",
    "            input_max_length = max(input_max_length,len(content[i]))\n",
    "\n",
    "    for i in range(len(content)):\n",
    "        if decoder_inputs:\n",
    "            content[i].insert(0,'sos')\n",
    "        if not no_pad:\n",
    "            while len(content[i]) <= input_max_length:\n",
    "                content[i].append('eos')\n",
    "\n",
    "    for i in range(len(content)):\n",
    "        for j in range(len(content[i])):\n",
    "            content[i][j] = word2id[content[i][j]]\n",
    "            \n",
    "    if not no_pad:    \n",
    "        return np.array(content).T, input_lengths\n",
    "    else:\n",
    "        return content, input_lengths\n",
    "\n",
    "decoder_op, decoder_vocab = d_readFile('WeatherGov/train/summaries.txt')\n",
    "\n",
    "decoder_target, decoder_target_lengths = d_sequence_converter(decoder_op, decoder_vocab, no_pad = True)\n",
    "\n",
    "decoder_op, _ = d_readFile('WeatherGov/train/summaries.txt')\n",
    "decoder_input, _ = d_sequence_converter(decoder_op, decoder_vocab, True)\n",
    "\n",
    "decoder_id2word = {}\n",
    "for i,j in decoder_vocab.iteritems():\n",
    "    decoder_id2word[j] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def v_readFile(fileName):\n",
    "    with open(fileName) as f:\n",
    "        content = f.readlines()\n",
    "    content = [x.split() for x in content]\n",
    "    return content\n",
    "\n",
    "def v_sequence_converter(content, word2id):\n",
    "    \n",
    "    input_lengths = np.zeros(len(content))\n",
    "    \n",
    "    for i in range(len(content)):\n",
    "        for j in range(len(content[i])):\n",
    "            content[i][j] = word2id[content[i][j]]\n",
    "            \n",
    "    return np.array(content).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_encoder1_input = v_readFile('WeatherGov/dev/dev.proc')\n",
    "\n",
    "v_encoder2_input = v_readFile('WeatherGov/dev/dev.field')\n",
    "\n",
    "v_encoder1_input = v_sequence_converter(v_encoder1_input, encoder_vocab)\n",
    "v_encoder2_input = v_sequence_converter(v_encoder2_input, encoder_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bleu.main import evaluate\n",
    "\n",
    "def validate_bleu(model1, v_encoder1_input, v_encoder2_input, decoder_input, decoder_target_lengths, epoch):\n",
    "    bi = []\n",
    "    for b in range(0,1000,bs):\n",
    "        max_len = np.max(decoder_target_lengths[b:b+bs])\n",
    "        x = []\n",
    "        for a in decoder_target[b:b+bs]:\n",
    "            x.append((a + [1] * int((max_len - len(a)))))\n",
    "        x= np.array(x).T\n",
    "        feed_dict = {model1.encoder1_inputs: v_encoder1_input[:,b:b+bs],\n",
    "                             model1.encoder2_inputs: v_encoder2_input[:,b:b+bs],\n",
    "                             model1.decoder_inputs: decoder_input[:,b:b+bs],\n",
    "                             model1.decoder_input_length: decoder_target_lengths[b:b+bs],\n",
    "                             model1.decoder_outputs: x,\n",
    "                             model1.training: False\n",
    "                            }\n",
    "        bi.append(sess.run(model1.op, feed_dict=feed_dict))\n",
    "        \n",
    "    f = open('op.txt','w+')\n",
    "\n",
    "    for b in bi:\n",
    "        for i in range(len(b[:,:,0])):\n",
    "            for j in range(len(b[i,:,0])):\n",
    "                if b[i,j,0] == -1 or b[i,j,0] == 1:\n",
    "                    break\n",
    "                else:\n",
    "                    f.write(decoder_id2word[b[i,j,0]]+' ')\n",
    "            f.write('\\n')\n",
    "\n",
    "    f.close()\n",
    "    \n",
    "    f = open('op_epoch'+str(epoch)+'.txt','w+')\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    for lines in open(\"op.txt\"):\n",
    "        if i < 3528:\n",
    "            f.write(lines.strip()+'\\n')\n",
    "            i=i+1\n",
    "        else:\n",
    "            break\n",
    "    f.close()\n",
    "    \n",
    "    return evaluate('op_epoch'+str(epoch)+'.txt', 'WeatherGov/dev/sum.txt', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2SeqModel(\n",
    "                     mode = \"train\",\n",
    "                     src_vocab_size=len(encoder_vocab), \n",
    "                     tgt_vocab_size=len(decoder_vocab), \n",
    "                     embedding_size=256, \n",
    "                     batch_size=bs, \n",
    "                     learning_rate = 0.001\n",
    "                    )\n",
    "\n",
    "model1 = Seq2SeqModel(\n",
    "                     mode = \"test\",\n",
    "                     src_vocab_size=len(encoder_vocab), \n",
    "                     tgt_vocab_size=len(decoder_vocab), \n",
    "                     embedding_size=256, \n",
    "                     batch_size=bs, \n",
    "                     learning_rate = 0.001,\n",
    "                     beam_search = True,\n",
    "                     beam_width = 5\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(allow_soft_placement = True)\n",
    "sess = tf.Session(config = config)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=[]\n",
    "epochs = 20\n",
    "for e in range(epochs):\n",
    "    e_loss = 0\n",
    "    for b in range(0,25000,bs):\n",
    "        max_len = np.max(decoder_target_lengths[b:b+bs])\n",
    "        x = []\n",
    "        for a in decoder_target[b:b+bs]:\n",
    "            x+=((a + [1] * int((max_len - len(a)))))\n",
    "        x= np.array(x).T\n",
    "        x = np.reshape(x,(x.shape[0],1))\n",
    "        feed_dict = {model.encoder1_inputs: encoder1_input[:,b:b+bs],\n",
    "                     model.encoder2_inputs: encoder2_input[:,b:b+bs],\n",
    "                     model.decoder_inputs: decoder_input[:,b:b+bs],\n",
    "                     model.decoder_input_length: decoder_target_lengths[b:b+bs],\n",
    "                     model.decoder_outputs: x,\n",
    "                     model.training: True\n",
    "                    }\n",
    "        a, b1, c = sess.run([model.logits,model.loss,model.train_op], feed_dict=feed_dict)\n",
    "        e_loss += b1\n",
    "    print(e_loss)\n",
    "    tmp.append(validate_bleu(model1, v_encoder1_input, v_encoder2_input, decoder_input, decoder_target_lengths, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "v_encoder1_input = v_readFile('WeatherGov/WeatherGov/test/test.proc')\n",
    "\n",
    "v_encoder2_input = v_readFile('WeatherGov/WeatherGov/test/test.field')\n",
    "\n",
    "v_encoder1_input = v_sequence_converter(v_encoder1_input, encoder_vocab)\n",
    "v_encoder2_input = v_sequence_converter(v_encoder2_input, encoder_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.22382529e-01,  1.24727452e+00,  2.93295813e+00, ...,\n",
       "          4.40763324e-01, -4.78719175e-02,  6.65240824e-01],\n",
       "        [ 1.97941393e-01,  1.10566568e+00,  2.56302810e+00, ...,\n",
       "          2.88410336e-01, -3.27832252e-02,  5.61185300e-01],\n",
       "        [ 4.85007204e-02,  9.09487545e-01,  1.91235495e+00, ...,\n",
       "          2.76726395e-01,  1.54977724e-01,  4.30308342e-01],\n",
       "        ...,\n",
       "        [ 5.02123475e-01,  1.01494293e+01, -8.38002443e-01, ...,\n",
       "         -3.93944502e-01, -6.95817113e-01,  3.49877059e-01],\n",
       "        [ 5.02255857e-01,  1.01536503e+01, -8.38756740e-01, ...,\n",
       "         -3.94043386e-01, -6.95920765e-01,  3.50744903e-01],\n",
       "        [ 5.02350807e-01,  1.01571035e+01, -8.39400947e-01, ...,\n",
       "         -3.94105494e-01, -6.95998192e-01,  3.51515591e-01]],\n",
       "\n",
       "       [[ 2.25078054e-02,  1.24363554e+00,  2.73834276e+00, ...,\n",
       "          3.20210457e-01, -4.07045260e-02,  6.42566860e-01],\n",
       "        [ 1.58236213e-02,  1.38908911e+00,  2.30361533e+00, ...,\n",
       "          4.10956204e-01, -9.38305706e-02,  5.20950079e-01],\n",
       "        [ 7.86433741e-03,  1.31805646e+00,  1.89409256e+00, ...,\n",
       "          3.89636934e-01, -2.64554828e-01,  6.42806768e-01],\n",
       "        ...,\n",
       "        [ 5.02408981e-01,  1.01704979e+01, -8.42524230e-01, ...,\n",
       "         -3.93987000e-01, -6.96078956e-01,  3.55475724e-01],\n",
       "        [ 5.02424359e-01,  1.01710863e+01, -8.42651486e-01, ...,\n",
       "         -3.93986225e-01, -6.96093798e-01,  3.55685145e-01],\n",
       "        [ 5.02436817e-01,  1.01715908e+01, -8.42761874e-01, ...,\n",
       "         -3.93984616e-01, -6.96105659e-01,  3.55868012e-01]],\n",
       "\n",
       "       [[ 9.68560427e-02,  1.00862646e+00,  2.62411785e+00, ...,\n",
       "          4.24501479e-01, -8.00546259e-03,  7.65725136e-01],\n",
       "        [ 1.39937252e-01,  8.28182757e-01,  2.25362659e+00, ...,\n",
       "          4.32420790e-01,  1.11583889e-01,  6.42298996e-01],\n",
       "        [ 6.93959221e-02,  7.67798543e-01,  2.04378819e+00, ...,\n",
       "          4.68774557e-01,  6.52845800e-02,  4.88570124e-01],\n",
       "        ...,\n",
       "        [-1.26445666e-01, -8.27113539e-02, -1.52785927e-01, ...,\n",
       "         -5.96199632e-02, -9.59579870e-02, -9.90951136e-02],\n",
       "        [-5.29634394e-03, -1.00651465e-01, -5.53104579e-02, ...,\n",
       "         -3.16442586e-02,  7.17307068e-03, -1.78407058e-02],\n",
       "        [-1.23503946e-01, -2.24651605e-01, -1.09057836e-01, ...,\n",
       "          1.04509026e-01,  7.68623054e-02,  1.68451238e-02]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 3.60971838e-02,  1.01997495e+00,  2.62733173e+00, ...,\n",
       "          2.40898505e-01,  5.32002151e-02,  6.47760987e-01],\n",
       "        [ 8.76580626e-02,  8.78713727e-01,  2.22486210e+00, ...,\n",
       "          2.86305726e-01, -2.70765200e-02,  6.49471164e-01],\n",
       "        [ 1.43703014e-01,  8.79755497e-01,  1.79369891e+00, ...,\n",
       "          4.74191993e-01,  1.30569100e-01,  7.01393008e-01],\n",
       "        ...,\n",
       "        [ 5.01564801e-01,  1.01514807e+01, -8.38320792e-01, ...,\n",
       "         -3.93157244e-01, -6.94973707e-01,  3.49494219e-01],\n",
       "        [ 5.01734078e-01,  1.01552877e+01, -8.39031458e-01, ...,\n",
       "         -3.93315911e-01, -6.95217669e-01,  3.50491673e-01],\n",
       "        [ 5.01867831e-01,  1.01584187e+01, -8.39638472e-01, ...,\n",
       "         -3.93439561e-01, -6.95409954e-01,  3.51359010e-01]],\n",
       "\n",
       "       [[ 1.01210982e-01,  9.47473884e-01,  2.66588926e+00, ...,\n",
       "          3.73505414e-01,  1.88428730e-01,  5.79852641e-01],\n",
       "        [ 1.59463197e-01,  7.88190663e-01,  2.30872583e+00, ...,\n",
       "          3.36095154e-01,  1.64534464e-01,  5.58426440e-01],\n",
       "        [ 2.11975276e-01,  6.87250495e-01,  1.75977540e+00, ...,\n",
       "          4.58196610e-01,  1.14608191e-01,  5.52982807e-01],\n",
       "        ...,\n",
       "        [ 5.00086486e-01,  1.00668888e+01, -8.25726986e-01, ...,\n",
       "         -3.91437352e-01, -6.91860616e-01,  3.39353830e-01],\n",
       "        [ 5.00843823e-01,  1.00879440e+01, -8.28581691e-01, ...,\n",
       "         -3.92265528e-01, -6.92809522e-01,  3.41387779e-01],\n",
       "        [ 5.01400948e-01,  1.01044693e+01, -8.30920756e-01, ...,\n",
       "         -3.92891288e-01, -6.93541050e-01,  3.43205124e-01]],\n",
       "\n",
       "       [[ 1.72453672e-02,  1.17547679e+00,  2.78462005e+00, ...,\n",
       "          2.15406477e-01,  2.04328343e-01,  4.78451788e-01],\n",
       "        [ 9.64728743e-03,  1.31844056e+00,  2.23977017e+00, ...,\n",
       "          3.08685631e-01,  1.10561162e-01,  3.56945217e-01],\n",
       "        [-4.09813412e-02,  1.28028333e+00,  1.88821328e+00, ...,\n",
       "          2.62519062e-01, -1.12459391e-01,  4.50300097e-01],\n",
       "        ...,\n",
       "        [ 5.02133191e-01,  1.01677523e+01, -8.41988981e-01, ...,\n",
       "         -3.93910587e-01, -6.96107209e-01,  3.54810387e-01],\n",
       "        [ 5.02189696e-01,  1.01687717e+01, -8.42182815e-01, ...,\n",
       "         -3.93927455e-01, -6.96122587e-01,  3.55099976e-01],\n",
       "        [ 5.02236426e-01,  1.01696291e+01, -8.42351317e-01, ...,\n",
       "         -3.93938899e-01, -6.96133912e-01,  3.55354249e-01]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('op.txt','w+')\n",
    "\n",
    "for b in bi:\n",
    "    for i in range(len(b[:,:,0])):\n",
    "        for j in range(len(b[i,:,0])):\n",
    "            if b[i,j,0] == -1 or b[i,j,0] == 1:\n",
    "                break\n",
    "            else:\n",
    "                f.write(decoder_id2word[b[i,j,0]]+' ')\n",
    "        f.write('\\n')\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('op_processed_15.txt','w+')\n",
    "\n",
    "i = 0\n",
    "\n",
    "for lines in open(\"op.txt\"):\n",
    "    if i < 3528:\n",
    "        f.write(lines.strip()+'\\n')\n",
    "        i=i+1\n",
    "    else:\n",
    "        break\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
