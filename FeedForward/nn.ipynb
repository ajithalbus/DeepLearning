{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import sys\n",
    "#hyper-parameters\n",
    "INPUT_LAYER_SIZE=784\n",
    "OUTPUT_LAYER_SIZE=10\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv('./data/train.csv')\n",
    "val=pd.read_csv('./data/val.csv')\n",
    "test=pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data_class =train.iloc[:,-1].copy().as_matrix()\n",
    "training_data=train.iloc[:,1:785].copy().as_matrix()/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validating_data_class =val.iloc[:,-1].copy().as_matrix()\n",
    "validating_data=val.iloc[:,1:785].copy().as_matrix()/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data=sk.preprocessing.scale(training_data)\n",
    "validating_data=sk.preprocessing.scale(validating_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.07072376  0.10359759 -0.07072376 ..., -0.07072376 -0.07072376\n",
      "  0.10359759]\n"
     ]
    }
   ],
   "source": [
    "print (training_data[:,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearDiscriminantAnalysis()\n",
    "clf.fit(training_data,training_data_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data=clf.transform(training_data)\n",
    "validating_data=clf.transform(validating_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data=sk.preprocessing.normalize(training_data)\n",
    "validating_data=sk.preprocessing.normalize(validating_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 9)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training_data=np.vstack((training_data,validating_data))\n",
    "#training_data_class=np.concatenate((training_data_class,validating_data_class))\n",
    "training_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_output(class_labels):\n",
    "    '''returns one-hot vectors'''\n",
    "    output=np.zeros((len(class_labels),10))\n",
    "    for i in range(len(class_labels)):\n",
    "        output[i,class_labels[i]]=1\n",
    "    return output\n",
    "def sigmoid(value):\n",
    "    return 1/(1+np.exp(-value))\n",
    "def tanh(value):\n",
    "    return np.tanh(value)\n",
    "def relu(value):\n",
    "    return [max(0,i) for i in value]\n",
    "def relu_dife(value):\n",
    "    if value>0:\n",
    "        return 1\n",
    "    return 0\n",
    "def relu_dif(value):\n",
    "    return [relu_dife(i) for i in value]\n",
    "def sigmoid_dif(value):\n",
    "    return sigmoid(value)*(1-sigmoid(value))\n",
    "def tanh_dif(value):\n",
    "    return 1-tanh(value)*tanh(value)\n",
    "def softmax(vector):\n",
    "    vector=np.array(vector,dtype=np.float64)\n",
    "    if sum(vector)!=sum(vector):\n",
    "        #print vector\n",
    "        sys.exit()\n",
    "    num= np.exp(vector)\n",
    "    \n",
    "    return num/np.sum(num)\n",
    "def paraCopy(w,b,multiplier=1):\n",
    "    return [i*multiplier for i in w],[i*multiplier for i in b]\n",
    "def paraAdd(A,B):\n",
    "    a,b=A\n",
    "    c,d=B\n",
    "    return [i+j for i,j in zip(a,c)],[i+j for i,j in zip(b,d)]\n",
    "def cliper(A):\n",
    "    return A/np.linalg.norm(A)\n",
    "#def cliper(A,B):\n",
    "#    return [i/np.linalg.norm(i) for i in A],[j/np.linalg.norm(j) for j in B]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shaper(lst):\n",
    "    for i in lst:\n",
    "        print 'shape -',i.shape\n",
    "def loss(list1,list2,loss_type):\n",
    "    if loss_type=='ce': #ce \n",
    "        return -np.sum([j*np.log2(i) for i,j in zip(list1,list2)])\n",
    "    if loss_type=='sq': #sq\n",
    "        return 0.5*np.sum([(i-j)**2 for i,j in zip(list1,list2)])\n",
    "def dumpModel(model):\n",
    "    kp=0\n",
    "    for i,j in zip(model.weights,model.biases):\n",
    "        np.save('./temp/weights_'+str(kp),i)\n",
    "        np.save('./temp/biases_'+str(kp),j)\n",
    "        kp+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NN_Model:\n",
    "    def __init__(self,lr=0.01,momentum=0,hidden_layers=(100,),activation='sigmoid',loss='sq',\n",
    "                 opt='gd',batch_size=1,anneal=False,save_dir='./temp/',expt_dir='./temp/',max_iter=50,ae_mode=False,\n",
    "                noise=0.0,Lambda=0):\n",
    "        self.lr=lr\n",
    "        self.momentum=momentum\n",
    "        self.layers=(INPUT_LAYER_SIZE,)+hidden_layers+(OUTPUT_LAYER_SIZE,)\n",
    "        if activation=='sigmoid':\n",
    "            self.activation=sigmoid\n",
    "            self.activation_diff=sigmoid_dif\n",
    "        elif activation=='tanh':\n",
    "            self.activation=tanh\n",
    "            self.activation_diff=tanh_dif\n",
    "        elif activation=='relu':\n",
    "            self.activation=relu\n",
    "            self.activation_diff=relu_dif\n",
    "        else:\n",
    "            print 'Error : activation function not found'\n",
    "        self.activation_name=activation        \n",
    "        self.p_noise=noise\n",
    "        self.loss=loss\n",
    "        self.opt=opt\n",
    "        self.batch_size=batch_size\n",
    "        self.anneal=anneal\n",
    "        self.save_dir=save_dir\n",
    "        self.expt_dir=expt_dir\n",
    "        self.num_layers=len(self.layers)\n",
    "        self.max_iter=max_iter\n",
    "        self.ae_mode=ae_mode\n",
    "        self.lam=Lambda\n",
    "    \n",
    "    def __forward_propagation(self):\n",
    "        h_set=[]\n",
    "        a_set=[]\n",
    "        h=self.input_data[TRAINER]\n",
    "        h=h+np.random.normal(size=h.shape)*np.random.choice([0, 1], size=h.shape, p=[1-self.p_noise,self.p_noise])\n",
    "\n",
    "        h_set.append(h) #experimental\n",
    "        L=self.num_layers-2 # 2 are input and output layers\n",
    "        for k in range(L): \n",
    "            a=self.biases[k]+np.matmul(self.weights[k],h)\n",
    "            \n",
    "            h=self.activation(a)\n",
    "            if self.activation_name=='relu':\n",
    "                h=cliper(h)\n",
    "            a_set.append(a)\n",
    "            h_set.append(h)\n",
    "        a=self.biases[L]+np.matmul(self.weights[L],h)\n",
    "        \n",
    "        a_set.append(a)\n",
    "        #print a\n",
    "        y=softmax(a)\n",
    "        #sys.exit()\n",
    "        #h_set.append(y) #experimental\n",
    "        #print h.shape\n",
    "            \n",
    "        return h_set,a_set,y\n",
    "    \n",
    "    def __forward_propagation_test(self,h):\n",
    "        L=self.num_layers-2 # 2 are input and output layers\n",
    "        for k in range(L): \n",
    "            a=self.biases[k]+np.matmul(self.weights[k],h)\n",
    "            h=self.activation(a)\n",
    "            if self.activation_name=='relu':\n",
    "                h=cliper(h)\n",
    "            \n",
    "        a=self.biases[L]+np.matmul(self.weights[L],h)\n",
    "        if self.ae_mode==False:\n",
    "            y=softmax(a)\n",
    "        else:\n",
    "            y=a\n",
    "        #h_set.append(y) #experimental\n",
    "        #print h.shape\n",
    "            \n",
    "        return y\n",
    "    \n",
    "    \n",
    "    def __back_propagation(self,h,a,y):\n",
    "        L=self.num_layers-2\n",
    "        dWeights=[]\n",
    "        dBiases=[]\n",
    "        if self.loss=='ce':\n",
    "            daL_loss=-(self.output_data[TRAINER]-y) # for cross-entropy loss function\n",
    "        elif self.loss=='sq':\n",
    "            daL_loss=np.array([2*sum([(y[i]-self.output_data[TRAINER][i])*y[i]*((i==j)*1-y[j]) for i in range(len(y))]) for j in range(len(y))])\n",
    "        else :\n",
    "            print 'Wrong loss function'\n",
    "            return\n",
    "        dA_loss=daL_loss\n",
    "        for k in range(L,-1,-1):\n",
    "            #print 'k=',k\n",
    "            dW_loss=np.outer(dA_loss,h[k]).T\n",
    "            dB_loss=dA_loss\n",
    "            \n",
    "            if k!=0:\n",
    "                dH_loss=np.matmul(self.weights[k].T,dA_loss)\n",
    "            \n",
    "                dA_loss=dH_loss*self.activation_diff(a[k-1])\n",
    "            \n",
    "            \n",
    "            dWeights=[dW_loss.T]+dWeights\n",
    "            dBiases=[dB_loss.T]+dBiases\n",
    "            #print dA_loss.shape\n",
    "            #return _,_\n",
    "            \n",
    "            \n",
    "        return dWeights,dBiases\n",
    "    \n",
    "    def __update(self,dWeights,dBiases):\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i]=self.weights[i]-(dWeights[i]+self.lam*np.absolute(self.weights[i]))\n",
    "            self.biases[i]=self.biases[i]-(dBiases[i]+self.lam*np.absolute(self.biases[i]))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __train(self):\n",
    "        global TRAINER\n",
    "        for i in range(self.max_iter):\n",
    "            if i%5==0 and i!=0 and self.anneal==True:\n",
    "                self.lr/=2\n",
    "            \n",
    "            accuracy=0\n",
    "            if self.batch_size==1:\n",
    "                self.batch_size=len(training_data)\n",
    "            \n",
    "            sets=len(training_data)/self.batch_size # number of batches\n",
    "                \n",
    "            oldDWeights,oldDBiases=paraCopy(self.weights,self.biases,0) # for momentum\n",
    "            for j in range(sets):\n",
    "                #print 'SET=',j\n",
    "                los=0\n",
    "                dWeights,dBiases=paraCopy(self.weights,self.biases,0)\n",
    "                for TRAINER in range(j*self.batch_size,(j+1)*self.batch_size):\n",
    "                    #print 'TRAINER=',TRAINER\n",
    "                    h,a,y=self.__forward_propagation()\n",
    "\n",
    "                    \n",
    "                    dWeights,dBiases=paraAdd(self.__back_propagation(h,a,y),\n",
    "                                         paraCopy(dWeights,dBiases,1))\n",
    "                    \n",
    "                    los+=loss(y,self.output_data[TRAINER],self.loss)\n",
    "\n",
    "                dWeights,dBiases=paraAdd(paraCopy(oldDWeights,oldDBiases,self.momentum),\n",
    "                                         paraCopy(dWeights,dBiases,self.lr))\n",
    "\n",
    "                self.__update(dWeights,dBiases)\n",
    "\n",
    "\n",
    "                \n",
    "                oldDWeights,oldDBiases=paraCopy(dWeights,dBiases,1)\n",
    "\n",
    "                #print np.argmax(y),self.raw_class_labels[TRAINER]\n",
    "                #if np.argmax(y)==self.raw_class_labels[TRAINER]:\n",
    "\n",
    "                 #   accuracy+=1\n",
    "                print 'Epoch : ',i,'Step : ',j,'loss : ',los\n",
    "                #print 'acc=',accuracy*1.0/sets\n",
    "            #print 'validation loss ',sum([loss(i,)])\n",
    "\n",
    "    def fit(self,X,Y):\n",
    "        self.input_data=X\n",
    "        if self.ae_mode== False:\n",
    "            self.output_data=create_output(Y)\n",
    "        else:\n",
    "            self.output_data=Y\n",
    "        self.weights=[]\n",
    "        self.biases=[]\n",
    "        self.raw_class_labels=Y\n",
    "        for i in range(self.num_layers-1):\n",
    "            self.weights.append(np.random.uniform(low=-1.0,high=1.0,size=(self.layers[i+1],self.layers[i])))\n",
    "            self.biases.append(np.random.uniform(low=-1.0,high=1.0,size=(self.layers[i+1])))\n",
    "            \n",
    "            #print self.biases[-1].shape\n",
    "        self.__train()\n",
    "        \n",
    "    def resume(self,X,Y):\n",
    "        self.input_data=X\n",
    "        self.output_data=create_output(Y)\n",
    "        self.weights=[]\n",
    "        self.biases=[]\n",
    "        self.raw_class_labels=Y\n",
    "        for i in range(self.num_layers-1):\n",
    "            self.weights.append(np.load('./temp/weights_'+str(i)+'.npy'))\n",
    "            self.biases.append(np.load('./temp/biases_'+str(i)+'.npy'))\n",
    "            #print self.weights[-1].shape\n",
    "        self.__train()\n",
    "        \n",
    "        \n",
    "    def predict(self,X):\n",
    "        return [np.argmax(self.__forward_propagation_test(i)) for i in X]    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=NN_Model(hidden_layers=(128,128),lr=0.001,max_iter=20,momentum=0.5,batch_size=250,anneal=True,loss='ce',\n",
    "               activation='tanh',ae_mode=False,noise=0.0,Lambda=0.0)\n",
    "training_data=np.array(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  0 Step :  0 loss :  3275.61215564\n",
      "Epoch :  0 Step :  1 loss :  2568.59560899\n",
      "Epoch :  0 Step :  2 loss :  1613.36949865\n",
      "Epoch :  0 Step :  3 loss :  1552.23079299\n",
      "Epoch :  0 Step :  4 loss :  1370.87332768\n",
      "Epoch :  0 Step :  5 loss :  1297.54507895\n",
      "Epoch :  0 Step :  6 loss :  872.768822322\n",
      "Epoch :  0 Step :  7 loss :  981.552584105\n",
      "Epoch :  0 Step :  8 loss :  1021.33712178\n",
      "Epoch :  0 Step :  9 loss :  908.843558125\n",
      "Epoch :  0 Step :  10 loss :  789.47776086\n",
      "Epoch :  0 Step :  11 loss :  1004.57908755\n",
      "Epoch :  0 Step :  12 loss :  880.080083942\n",
      "Epoch :  0 Step :  13 loss :  819.169437261\n",
      "Epoch :  0 Step :  14 loss :  779.692550997\n",
      "Epoch :  0 Step :  15 loss :  921.418867403\n",
      "Epoch :  0 Step :  16 loss :  838.945175211\n",
      "Epoch :  0 Step :  17 loss :  735.891182184\n",
      "Epoch :  0 Step :  18 loss :  632.570345187\n",
      "Epoch :  0 Step :  19 loss :  603.145650158\n",
      "Epoch :  0 Step :  20 loss :  798.993331815\n",
      "Epoch :  0 Step :  21 loss :  771.119003866\n",
      "Epoch :  0 Step :  22 loss :  795.617337665\n",
      "Epoch :  0 Step :  23 loss :  681.904838227\n",
      "Epoch :  0 Step :  24 loss :  680.104982656\n",
      "Epoch :  0 Step :  25 loss :  792.418930816\n",
      "Epoch :  0 Step :  26 loss :  654.659796288\n",
      "Epoch :  0 Step :  27 loss :  589.888691114\n",
      "Epoch :  0 Step :  28 loss :  655.497557474\n",
      "Epoch :  0 Step :  29 loss :  611.330340038\n",
      "Epoch :  0 Step :  30 loss :  731.577970069\n",
      "Epoch :  0 Step :  31 loss :  647.622973156\n",
      "Epoch :  0 Step :  32 loss :  592.04724559\n",
      "Epoch :  0 Step :  33 loss :  560.621479043\n",
      "Epoch :  0 Step :  34 loss :  595.458309828\n",
      "Epoch :  0 Step :  35 loss :  723.451488517\n",
      "Epoch :  0 Step :  36 loss :  554.837833607\n",
      "Epoch :  0 Step :  37 loss :  590.078612755\n",
      "Epoch :  0 Step :  38 loss :  597.458501603\n",
      "Epoch :  0 Step :  39 loss :  576.392745947\n",
      "Epoch :  0 Step :  40 loss :  555.101228259\n",
      "Epoch :  0 Step :  41 loss :  504.173087364\n",
      "Epoch :  0 Step :  42 loss :  498.054848418\n",
      "Epoch :  0 Step :  43 loss :  555.473932855\n",
      "Epoch :  0 Step :  44 loss :  445.258045821\n",
      "Epoch :  0 Step :  45 loss :  597.438389099\n",
      "Epoch :  0 Step :  46 loss :  566.334191934\n",
      "Epoch :  0 Step :  47 loss :  565.504402995\n",
      "Epoch :  0 Step :  48 loss :  579.392171943\n",
      "Epoch :  0 Step :  49 loss :  527.339145269\n",
      "Epoch :  0 Step :  50 loss :  489.511206125\n",
      "Epoch :  0 Step :  51 loss :  422.24254313\n",
      "Epoch :  0 Step :  52 loss :  482.373389999\n",
      "Epoch :  0 Step :  53 loss :  535.006265053\n",
      "Epoch :  0 Step :  54 loss :  494.206412157\n",
      "Epoch :  0 Step :  55 loss :  510.676828397\n",
      "Epoch :  0 Step :  56 loss :  471.956761091\n",
      "Epoch :  0 Step :  57 loss :  418.337668594\n",
      "Epoch :  0 Step :  58 loss :  380.649967282\n",
      "Epoch :  0 Step :  59 loss :  547.432350277\n",
      "Epoch :  0 Step :  60 loss :  497.52011363\n",
      "Epoch :  0 Step :  61 loss :  544.08195222\n",
      "Epoch :  0 Step :  62 loss :  442.017087745\n",
      "Epoch :  0 Step :  63 loss :  462.939034656\n",
      "Epoch :  0 Step :  64 loss :  448.323076837\n",
      "Epoch :  0 Step :  65 loss :  391.679290143\n",
      "Epoch :  0 Step :  66 loss :  469.637825629\n",
      "Epoch :  0 Step :  67 loss :  444.955687517\n",
      "Epoch :  0 Step :  68 loss :  489.330055085\n",
      "Epoch :  0 Step :  69 loss :  576.942930122\n",
      "Epoch :  0 Step :  70 loss :  599.853134373\n",
      "Epoch :  0 Step :  71 loss :  435.517397754\n",
      "Epoch :  0 Step :  72 loss :  510.260795344\n",
      "Epoch :  0 Step :  73 loss :  373.422721768\n",
      "Epoch :  0 Step :  74 loss :  363.599522953\n",
      "Epoch :  0 Step :  75 loss :  419.302644528\n",
      "Epoch :  0 Step :  76 loss :  515.633150204\n",
      "Epoch :  0 Step :  77 loss :  406.02677387\n",
      "Epoch :  0 Step :  78 loss :  396.82712523\n",
      "Epoch :  0 Step :  79 loss :  516.028297633\n",
      "Epoch :  0 Step :  80 loss :  429.729207912\n",
      "Epoch :  0 Step :  81 loss :  447.995426561\n",
      "Epoch :  0 Step :  82 loss :  485.789258129\n",
      "Epoch :  0 Step :  83 loss :  421.745483957\n",
      "Epoch :  0 Step :  84 loss :  415.337027613\n",
      "Epoch :  0 Step :  85 loss :  521.652143487\n",
      "Epoch :  0 Step :  86 loss :  373.446181316\n",
      "Epoch :  0 Step :  87 loss :  378.587125872\n",
      "Epoch :  0 Step :  88 loss :  442.016711506\n",
      "Epoch :  0 Step :  89 loss :  299.082718354\n",
      "Epoch :  0 Step :  90 loss :  529.357985117\n",
      "Epoch :  0 Step :  91 loss :  511.446577245\n",
      "Epoch :  0 Step :  92 loss :  350.372474628\n",
      "Epoch :  0 Step :  93 loss :  423.846364391\n",
      "Epoch :  0 Step :  94 loss :  382.336507339\n",
      "Epoch :  0 Step :  95 loss :  385.930757556\n",
      "Epoch :  0 Step :  96 loss :  405.574000663\n",
      "Epoch :  0 Step :  97 loss :  356.120026702\n",
      "Epoch :  0 Step :  98 loss :  400.162177343\n",
      "Epoch :  0 Step :  99 loss :  487.627087355\n",
      "Epoch :  0 Step :  100 loss :  335.752628674\n",
      "Epoch :  0 Step :  101 loss :  286.922571365\n",
      "Epoch :  0 Step :  102 loss :  406.091270092\n",
      "Epoch :  0 Step :  103 loss :  388.325647027\n",
      "Epoch :  0 Step :  104 loss :  419.818358854\n",
      "Epoch :  0 Step :  105 loss :  437.487313826\n",
      "Epoch :  0 Step :  106 loss :  342.66695467\n",
      "Epoch :  0 Step :  107 loss :  366.01606097\n",
      "Epoch :  0 Step :  108 loss :  415.528312226\n",
      "Epoch :  0 Step :  109 loss :  410.693279389\n",
      "Epoch :  0 Step :  110 loss :  424.789155909\n",
      "Epoch :  0 Step :  111 loss :  315.454284175\n",
      "Epoch :  0 Step :  112 loss :  393.311027928\n",
      "Epoch :  0 Step :  113 loss :  425.019333615\n",
      "Epoch :  0 Step :  114 loss :  388.635758633\n",
      "Epoch :  0 Step :  115 loss :  408.586357423\n",
      "Epoch :  0 Step :  116 loss :  382.214869573\n",
      "Epoch :  0 Step :  117 loss :  409.336585955\n",
      "Epoch :  0 Step :  118 loss :  393.150298859\n",
      "Epoch :  0 Step :  119 loss :  350.9808042\n",
      "Epoch :  0 Step :  120 loss :  404.122216393\n",
      "Epoch :  0 Step :  121 loss :  293.803850104\n",
      "Epoch :  0 Step :  122 loss :  412.40216864\n",
      "Epoch :  0 Step :  123 loss :  368.95795387\n",
      "Epoch :  0 Step :  124 loss :  308.371453283\n",
      "Epoch :  0 Step :  125 loss :  358.874994181\n",
      "Epoch :  0 Step :  126 loss :  361.806168615\n",
      "Epoch :  0 Step :  127 loss :  296.649578735\n",
      "Epoch :  0 Step :  128 loss :  319.963882553\n",
      "Epoch :  0 Step :  129 loss :  297.875027524\n",
      "Epoch :  0 Step :  130 loss :  316.689311896\n",
      "Epoch :  0 Step :  131 loss :  401.017157655\n",
      "Epoch :  0 Step :  132 loss :  291.085546468\n",
      "Epoch :  0 Step :  133 loss :  388.37758344\n",
      "Epoch :  0 Step :  134 loss :  388.449722101\n",
      "Epoch :  0 Step :  135 loss :  462.935752198\n",
      "Epoch :  0 Step :  136 loss :  371.571146586\n",
      "Epoch :  0 Step :  137 loss :  299.755544183\n",
      "Epoch :  0 Step :  138 loss :  297.436186389\n",
      "Epoch :  0 Step :  139 loss :  410.78090673\n",
      "Epoch :  0 Step :  140 loss :  286.524124644\n",
      "Epoch :  0 Step :  141 loss :  406.216507502\n",
      "Epoch :  0 Step :  142 loss :  375.702205134\n",
      "Epoch :  0 Step :  143 loss :  347.935899568\n",
      "Epoch :  0 Step :  144 loss :  408.653809228\n",
      "Epoch :  0 Step :  145 loss :  485.455438572\n",
      "Epoch :  0 Step :  146 loss :  338.54064474\n",
      "Epoch :  0 Step :  147 loss :  371.687528061\n",
      "Epoch :  0 Step :  148 loss :  330.586947481\n",
      "Epoch :  0 Step :  149 loss :  371.716414856\n",
      "Epoch :  0 Step :  150 loss :  351.997548741\n",
      "Epoch :  0 Step :  151 loss :  327.161481089\n",
      "Epoch :  0 Step :  152 loss :  390.983997217\n",
      "Epoch :  0 Step :  153 loss :  255.338535754\n",
      "Epoch :  0 Step :  154 loss :  343.257962724\n",
      "Epoch :  0 Step :  155 loss :  343.13170154\n",
      "Epoch :  0 Step :  156 loss :  391.863206162\n",
      "Epoch :  0 Step :  157 loss :  283.869462042\n",
      "Epoch :  0 Step :  158 loss :  319.39271547\n",
      "Epoch :  0 Step :  159 loss :  290.016517629\n",
      "Epoch :  0 Step :  160 loss :  317.629307691\n",
      "Epoch :  0 Step :  161 loss :  319.437190604\n",
      "Epoch :  0 Step :  162 loss :  299.506564606\n",
      "Epoch :  0 Step :  163 loss :  349.178378646\n",
      "Epoch :  0 Step :  164 loss :  290.251273089\n",
      "Epoch :  0 Step :  165 loss :  353.462160021\n",
      "Epoch :  0 Step :  166 loss :  320.801542316\n",
      "Epoch :  0 Step :  167 loss :  301.385882945\n",
      "Epoch :  0 Step :  168 loss :  335.89020223\n",
      "Epoch :  0 Step :  169 loss :  314.525835136\n",
      "Epoch :  0 Step :  170 loss :  342.002746605\n",
      "Epoch :  0 Step :  171 loss :  357.812716419\n",
      "Epoch :  0 Step :  172 loss :  300.228570118\n",
      "Epoch :  0 Step :  173 loss :  327.857842016\n",
      "Epoch :  0 Step :  174 loss :  339.653946496\n",
      "Epoch :  0 Step :  175 loss :  329.364793353\n",
      "Epoch :  0 Step :  176 loss :  304.595113871\n",
      "Epoch :  0 Step :  177 loss :  314.122737929\n",
      "Epoch :  0 Step :  178 loss :  222.900462905\n",
      "Epoch :  0 Step :  179 loss :  337.731965079\n",
      "Epoch :  0 Step :  180 loss :  323.045537932\n",
      "Epoch :  0 Step :  181 loss :  289.571778394\n",
      "Epoch :  0 Step :  182 loss :  303.315537522\n",
      "Epoch :  0 Step :  183 loss :  318.06352681\n",
      "Epoch :  0 Step :  184 loss :  325.118174418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  0 Step :  185 loss :  292.141802638\n",
      "Epoch :  0 Step :  186 loss :  297.155357984\n",
      "Epoch :  0 Step :  187 loss :  321.059549136\n",
      "Epoch :  0 Step :  188 loss :  421.972238994\n",
      "Epoch :  0 Step :  189 loss :  298.789152438\n",
      "Epoch :  0 Step :  190 loss :  328.294398839\n",
      "Epoch :  0 Step :  191 loss :  255.352253224\n",
      "Epoch :  0 Step :  192 loss :  235.905426999\n",
      "Epoch :  0 Step :  193 loss :  283.245142796\n",
      "Epoch :  0 Step :  194 loss :  289.911481078\n",
      "Epoch :  0 Step :  195 loss :  299.787717165\n",
      "Epoch :  0 Step :  196 loss :  256.914059973\n",
      "Epoch :  0 Step :  197 loss :  320.831857847\n",
      "Epoch :  0 Step :  198 loss :  308.016094291\n",
      "Epoch :  0 Step :  199 loss :  363.460084222\n",
      "Epoch :  0 Step :  200 loss :  335.357719164\n",
      "Epoch :  0 Step :  201 loss :  317.264873789\n",
      "Epoch :  0 Step :  202 loss :  309.39121332\n",
      "Epoch :  0 Step :  203 loss :  276.730516818\n",
      "Epoch :  0 Step :  204 loss :  352.518319051\n",
      "Epoch :  0 Step :  205 loss :  345.323215263\n",
      "Epoch :  0 Step :  206 loss :  319.495527924\n",
      "Epoch :  0 Step :  207 loss :  244.970499001\n",
      "Epoch :  0 Step :  208 loss :  245.89753017\n",
      "Epoch :  0 Step :  209 loss :  259.130467384\n",
      "Epoch :  0 Step :  210 loss :  357.064968202\n",
      "Epoch :  0 Step :  211 loss :  331.964036123\n",
      "Epoch :  0 Step :  212 loss :  330.817918763\n",
      "Epoch :  0 Step :  213 loss :  368.826443016\n",
      "Epoch :  0 Step :  214 loss :  359.829416769\n",
      "Epoch :  0 Step :  215 loss :  298.676438515\n",
      "Epoch :  0 Step :  216 loss :  333.794150328\n",
      "Epoch :  0 Step :  217 loss :  275.131958079\n",
      "Epoch :  0 Step :  218 loss :  298.02191461\n",
      "Epoch :  0 Step :  219 loss :  339.270504199\n",
      "Epoch :  1 Step :  0 loss :  277.278093065\n",
      "Epoch :  1 Step :  1 loss :  274.773198379\n",
      "Epoch :  1 Step :  2 loss :  253.480585078\n",
      "Epoch :  1 Step :  3 loss :  291.390984306\n",
      "Epoch :  1 Step :  4 loss :  344.301928672\n",
      "Epoch :  1 Step :  5 loss :  291.918854874\n",
      "Epoch :  1 Step :  6 loss :  184.085580446\n",
      "Epoch :  1 Step :  7 loss :  231.898288038\n",
      "Epoch :  1 Step :  8 loss :  268.379706904\n",
      "Epoch :  1 Step :  9 loss :  257.035819059\n",
      "Epoch :  1 Step :  10 loss :  235.792258912\n",
      "Epoch :  1 Step :  11 loss :  301.998830902\n",
      "Epoch :  1 Step :  12 loss :  282.569934771\n",
      "Epoch :  1 Step :  13 loss :  238.766427693\n",
      "Epoch :  1 Step :  14 loss :  229.579542355\n",
      "Epoch :  1 Step :  15 loss :  327.176404759\n",
      "Epoch :  1 Step :  16 loss :  237.38708375\n",
      "Epoch :  1 Step :  17 loss :  282.401369848\n",
      "Epoch :  1 Step :  18 loss :  210.555580778\n",
      "Epoch :  1 Step :  19 loss :  202.586005049\n",
      "Epoch :  1 Step :  20 loss :  318.44235406\n",
      "Epoch :  1 Step :  21 loss :  332.216067736\n",
      "Epoch :  1 Step :  22 loss :  366.032879339\n",
      "Epoch :  1 Step :  23 loss :  246.727602135\n",
      "Epoch :  1 Step :  24 loss :  255.68334274\n",
      "Epoch :  1 Step :  25 loss :  321.184827817\n",
      "Epoch :  1 Step :  26 loss :  245.057702765\n",
      "Epoch :  1 Step :  27 loss :  263.734248806\n",
      "Epoch :  1 Step :  28 loss :  265.364105324\n",
      "Epoch :  1 Step :  29 loss :  220.387803911\n",
      "Epoch :  1 Step :  30 loss :  305.451329223\n",
      "Epoch :  1 Step :  31 loss :  281.385646236\n",
      "Epoch :  1 Step :  32 loss :  247.228819913\n",
      "Epoch :  1 Step :  33 loss :  278.282476547\n",
      "Epoch :  1 Step :  34 loss :  262.679372198\n",
      "Epoch :  1 Step :  35 loss :  329.033941751\n",
      "Epoch :  1 Step :  36 loss :  234.989412001\n",
      "Epoch :  1 Step :  37 loss :  277.410908815\n",
      "Epoch :  1 Step :  38 loss :  284.050134046\n",
      "Epoch :  1 Step :  39 loss :  276.842542296\n",
      "Epoch :  1 Step :  40 loss :  230.005091957\n",
      "Epoch :  1 Step :  41 loss :  244.01690534\n",
      "Epoch :  1 Step :  42 loss :  235.675345302\n",
      "Epoch :  1 Step :  43 loss :  250.322973832\n",
      "Epoch :  1 Step :  44 loss :  210.953983214\n",
      "Epoch :  1 Step :  45 loss :  272.204897599\n",
      "Epoch :  1 Step :  46 loss :  282.644562543\n",
      "Epoch :  1 Step :  47 loss :  284.077439517\n",
      "Epoch :  1 Step :  48 loss :  263.269454874\n",
      "Epoch :  1 Step :  49 loss :  270.059885508\n",
      "Epoch :  1 Step :  50 loss :  245.73839975\n",
      "Epoch :  1 Step :  51 loss :  217.181209027\n",
      "Epoch :  1 Step :  52 loss :  253.378385378\n",
      "Epoch :  1 Step :  53 loss :  256.552304098\n",
      "Epoch :  1 Step :  54 loss :  243.299303868\n",
      "Epoch :  1 Step :  55 loss :  242.746641431\n",
      "Epoch :  1 Step :  56 loss :  296.822597474\n",
      "Epoch :  1 Step :  57 loss :  206.632521394\n",
      "Epoch :  1 Step :  58 loss :  227.33339911\n",
      "Epoch :  1 Step :  59 loss :  286.058462467\n",
      "Epoch :  1 Step :  60 loss :  211.91805401\n",
      "Epoch :  1 Step :  61 loss :  266.412390862\n",
      "Epoch :  1 Step :  62 loss :  282.852932054\n",
      "Epoch :  1 Step :  63 loss :  238.200577228\n",
      "Epoch :  1 Step :  64 loss :  242.722590211\n",
      "Epoch :  1 Step :  65 loss :  215.927442988\n",
      "Epoch :  1 Step :  66 loss :  240.551552068\n",
      "Epoch :  1 Step :  67 loss :  240.315171944\n",
      "Epoch :  1 Step :  68 loss :  241.04215151\n",
      "Epoch :  1 Step :  69 loss :  301.257785798\n",
      "Epoch :  1 Step :  70 loss :  321.964337008\n",
      "Epoch :  1 Step :  71 loss :  261.503285343\n",
      "Epoch :  1 Step :  72 loss :  286.54481148\n",
      "Epoch :  1 Step :  73 loss :  240.946891834\n",
      "Epoch :  1 Step :  74 loss :  252.440116404\n",
      "Epoch :  1 Step :  75 loss :  267.385868871\n",
      "Epoch :  1 Step :  76 loss :  340.054501446\n",
      "Epoch :  1 Step :  77 loss :  257.541714371\n",
      "Epoch :  1 Step :  78 loss :  189.044075792\n",
      "Epoch :  1 Step :  79 loss :  256.142487118\n",
      "Epoch :  1 Step :  80 loss :  237.246191532\n",
      "Epoch :  1 Step :  81 loss :  253.022369193\n",
      "Epoch :  1 Step :  82 loss :  245.546032118\n",
      "Epoch :  1 Step :  83 loss :  227.775467005\n",
      "Epoch :  1 Step :  84 loss :  223.448174564\n",
      "Epoch :  1 Step :  85 loss :  304.699303824\n",
      "Epoch :  1 Step :  86 loss :  181.596870393\n",
      "Epoch :  1 Step :  87 loss :  236.712466445\n",
      "Epoch :  1 Step :  88 loss :  261.469270258\n",
      "Epoch :  1 Step :  89 loss :  204.931835419\n",
      "Epoch :  1 Step :  90 loss :  270.851677444\n",
      "Epoch :  1 Step :  91 loss :  281.575668201\n",
      "Epoch :  1 Step :  92 loss :  228.748091478\n",
      "Epoch :  1 Step :  93 loss :  234.704908303\n",
      "Epoch :  1 Step :  94 loss :  194.925522082\n",
      "Epoch :  1 Step :  95 loss :  277.487313151\n",
      "Epoch :  1 Step :  96 loss :  234.218204412\n",
      "Epoch :  1 Step :  97 loss :  235.47182193\n",
      "Epoch :  1 Step :  98 loss :  240.388792053\n",
      "Epoch :  1 Step :  99 loss :  273.819030154\n",
      "Epoch :  1 Step :  100 loss :  209.818172451\n",
      "Epoch :  1 Step :  101 loss :  202.071854485\n",
      "Epoch :  1 Step :  102 loss :  269.131692795\n",
      "Epoch :  1 Step :  103 loss :  273.649475033\n",
      "Epoch :  1 Step :  104 loss :  249.264832212\n",
      "Epoch :  1 Step :  105 loss :  278.587356346\n",
      "Epoch :  1 Step :  106 loss :  189.262297006\n",
      "Epoch :  1 Step :  107 loss :  223.967127933\n",
      "Epoch :  1 Step :  108 loss :  240.975639061\n",
      "Epoch :  1 Step :  109 loss :  258.337820303\n",
      "Epoch :  1 Step :  110 loss :  232.097422958\n",
      "Epoch :  1 Step :  111 loss :  170.441900041\n",
      "Epoch :  1 Step :  112 loss :  267.466556874\n",
      "Epoch :  1 Step :  113 loss :  255.059592025\n",
      "Epoch :  1 Step :  114 loss :  199.056926121\n",
      "Epoch :  1 Step :  115 loss :  270.81539862\n",
      "Epoch :  1 Step :  116 loss :  247.067217989\n",
      "Epoch :  1 Step :  117 loss :  262.240316022\n",
      "Epoch :  1 Step :  118 loss :  229.963799926\n",
      "Epoch :  1 Step :  119 loss :  223.595454657\n",
      "Epoch :  1 Step :  120 loss :  231.553614808\n",
      "Epoch :  1 Step :  121 loss :  211.310555284\n",
      "Epoch :  1 Step :  122 loss :  257.157274422\n",
      "Epoch :  1 Step :  123 loss :  239.731547561\n",
      "Epoch :  1 Step :  124 loss :  216.187919115\n",
      "Epoch :  1 Step :  125 loss :  230.385441612\n",
      "Epoch :  1 Step :  126 loss :  229.830657169\n",
      "Epoch :  1 Step :  127 loss :  179.918578703\n",
      "Epoch :  1 Step :  128 loss :  220.961515032\n",
      "Epoch :  1 Step :  129 loss :  249.352629356\n",
      "Epoch :  1 Step :  130 loss :  203.305238885\n",
      "Epoch :  1 Step :  131 loss :  259.147176821\n",
      "Epoch :  1 Step :  132 loss :  181.183498144\n",
      "Epoch :  1 Step :  133 loss :  266.41686651\n",
      "Epoch :  1 Step :  134 loss :  253.049959817\n",
      "Epoch :  1 Step :  135 loss :  303.963827833\n",
      "Epoch :  1 Step :  136 loss :  236.836072086\n",
      "Epoch :  1 Step :  137 loss :  207.531568143\n",
      "Epoch :  1 Step :  138 loss :  243.638739037\n",
      "Epoch :  1 Step :  139 loss :  245.739796775\n",
      "Epoch :  1 Step :  140 loss :  167.792333134\n",
      "Epoch :  1 Step :  141 loss :  235.413192701\n",
      "Epoch :  1 Step :  142 loss :  233.211319402\n",
      "Epoch :  1 Step :  143 loss :  230.065963514\n",
      "Epoch :  1 Step :  144 loss :  260.115251639\n",
      "Epoch :  1 Step :  145 loss :  295.498732117\n",
      "Epoch :  1 Step :  146 loss :  228.694493397\n",
      "Epoch :  1 Step :  147 loss :  247.924137031\n",
      "Epoch :  1 Step :  148 loss :  207.837723784\n",
      "Epoch :  1 Step :  149 loss :  267.496625586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  1 Step :  150 loss :  207.946251662\n",
      "Epoch :  1 Step :  151 loss :  230.229712423\n",
      "Epoch :  1 Step :  152 loss :  254.019994471\n",
      "Epoch :  1 Step :  153 loss :  191.214405858\n",
      "Epoch :  1 Step :  154 loss :  244.837957942\n",
      "Epoch :  1 Step :  155 loss :  245.150991303\n",
      "Epoch :  1 Step :  156 loss :  250.850356249\n",
      "Epoch :  1 Step :  157 loss :  214.075891244\n",
      "Epoch :  1 Step :  158 loss :  235.013621098\n",
      "Epoch :  1 Step :  159 loss :  213.670643019\n",
      "Epoch :  1 Step :  160 loss :  213.880585071\n",
      "Epoch :  1 Step :  161 loss :  222.815179721\n",
      "Epoch :  1 Step :  162 loss :  222.721295883\n",
      "Epoch :  1 Step :  163 loss :  233.276255125\n",
      "Epoch :  1 Step :  164 loss :  190.466935685\n",
      "Epoch :  1 Step :  165 loss :  232.657651562\n",
      "Epoch :  1 Step :  166 loss :  195.177658261\n",
      "Epoch :  1 Step :  167 loss :  197.114613018\n",
      "Epoch :  1 Step :  168 loss :  220.967494396\n",
      "Epoch :  1 Step :  169 loss :  241.414459187\n",
      "Epoch :  1 Step :  170 loss :  214.041061295\n",
      "Epoch :  1 Step :  171 loss :  228.614700795\n",
      "Epoch :  1 Step :  172 loss :  223.270276114\n",
      "Epoch :  1 Step :  173 loss :  204.036413289\n",
      "Epoch :  1 Step :  174 loss :  228.447002374\n",
      "Epoch :  1 Step :  175 loss :  237.109082866\n",
      "Epoch :  1 Step :  176 loss :  237.465654448\n",
      "Epoch :  1 Step :  177 loss :  221.778446221\n",
      "Epoch :  1 Step :  178 loss :  181.38667138\n",
      "Epoch :  1 Step :  179 loss :  257.769757753\n",
      "Epoch :  1 Step :  180 loss :  233.590290864\n",
      "Epoch :  1 Step :  181 loss :  194.129830294\n",
      "Epoch :  1 Step :  182 loss :  230.17869765\n",
      "Epoch :  1 Step :  183 loss :  207.759865056\n",
      "Epoch :  1 Step :  184 loss :  228.47884567\n",
      "Epoch :  1 Step :  185 loss :  226.859761256\n",
      "Epoch :  1 Step :  186 loss :  198.056052402\n",
      "Epoch :  1 Step :  187 loss :  264.469465387\n",
      "Epoch :  1 Step :  188 loss :  282.325916615\n",
      "Epoch :  1 Step :  189 loss :  217.594900804\n",
      "Epoch :  1 Step :  190 loss :  224.338873026\n",
      "Epoch :  1 Step :  191 loss :  173.074483522\n",
      "Epoch :  1 Step :  192 loss :  156.126320013\n",
      "Epoch :  1 Step :  193 loss :  230.9157287\n",
      "Epoch :  1 Step :  194 loss :  185.855109223\n",
      "Epoch :  1 Step :  195 loss :  222.989153218\n",
      "Epoch :  1 Step :  196 loss :  200.053143906\n",
      "Epoch :  1 Step :  197 loss :  206.662861238\n",
      "Epoch :  1 Step :  198 loss :  199.449490454\n",
      "Epoch :  1 Step :  199 loss :  259.675164736\n",
      "Epoch :  1 Step :  200 loss :  243.620397503\n",
      "Epoch :  1 Step :  201 loss :  191.793340517\n",
      "Epoch :  1 Step :  202 loss :  218.453897758\n",
      "Epoch :  1 Step :  203 loss :  171.04956365\n",
      "Epoch :  1 Step :  204 loss :  233.420623064\n",
      "Epoch :  1 Step :  205 loss :  261.133471747\n",
      "Epoch :  1 Step :  206 loss :  223.285530105\n",
      "Epoch :  1 Step :  207 loss :  191.122528508\n",
      "Epoch :  1 Step :  208 loss :  176.694575982\n",
      "Epoch :  1 Step :  209 loss :  198.588876873\n",
      "Epoch :  1 Step :  210 loss :  266.591154064\n",
      "Epoch :  1 Step :  211 loss :  227.726502618\n",
      "Epoch :  1 Step :  212 loss :  221.087021953\n",
      "Epoch :  1 Step :  213 loss :  255.918598254\n",
      "Epoch :  1 Step :  214 loss :  252.483109219\n",
      "Epoch :  1 Step :  215 loss :  244.251703892\n",
      "Epoch :  1 Step :  216 loss :  245.611961868\n",
      "Epoch :  1 Step :  217 loss :  234.024648808\n",
      "Epoch :  1 Step :  218 loss :  224.524453326\n",
      "Epoch :  1 Step :  219 loss :  261.602154764\n",
      "Epoch :  2 Step :  0 loss :  179.425362194\n",
      "Epoch :  2 Step :  1 loss :  217.298198495\n",
      "Epoch :  2 Step :  2 loss :  171.41939692\n",
      "Epoch :  2 Step :  3 loss :  198.137782356\n",
      "Epoch :  2 Step :  4 loss :  233.025917446\n",
      "Epoch :  2 Step :  5 loss :  233.075419709\n",
      "Epoch :  2 Step :  6 loss :  142.796584058\n",
      "Epoch :  2 Step :  7 loss :  179.554976849\n",
      "Epoch :  2 Step :  8 loss :  211.016201535\n",
      "Epoch :  2 Step :  9 loss :  188.266786316\n",
      "Epoch :  2 Step :  10 loss :  192.965666963\n",
      "Epoch :  2 Step :  11 loss :  245.504003145\n",
      "Epoch :  2 Step :  12 loss :  189.609014393\n",
      "Epoch :  2 Step :  13 loss :  180.75537743\n",
      "Epoch :  2 Step :  14 loss :  191.179756532\n",
      "Epoch :  2 Step :  15 loss :  257.663157713\n",
      "Epoch :  2 Step :  16 loss :  179.963519608\n",
      "Epoch :  2 Step :  17 loss :  192.10060407\n",
      "Epoch :  2 Step :  18 loss :  168.063329211\n",
      "Epoch :  2 Step :  19 loss :  165.687115796\n",
      "Epoch :  2 Step :  20 loss :  240.043497656\n",
      "Epoch :  2 Step :  21 loss :  244.996938501\n",
      "Epoch :  2 Step :  22 loss :  222.860231852\n",
      "Epoch :  2 Step :  23 loss :  183.605588958\n",
      "Epoch :  2 Step :  24 loss :  167.014912375\n",
      "Epoch :  2 Step :  25 loss :  227.975784508\n",
      "Epoch :  2 Step :  26 loss :  190.037622237\n",
      "Epoch :  2 Step :  27 loss :  173.771086061\n",
      "Epoch :  2 Step :  28 loss :  210.474133871\n",
      "Epoch :  2 Step :  29 loss :  190.701257448\n",
      "Epoch :  2 Step :  30 loss :  218.056721483\n",
      "Epoch :  2 Step :  31 loss :  230.503426257\n",
      "Epoch :  2 Step :  32 loss :  202.564393477\n",
      "Epoch :  2 Step :  33 loss :  203.614163045\n",
      "Epoch :  2 Step :  34 loss :  196.155412226\n",
      "Epoch :  2 Step :  35 loss :  248.199802383\n",
      "Epoch :  2 Step :  36 loss :  167.643314649\n",
      "Epoch :  2 Step :  37 loss :  211.170095191\n",
      "Epoch :  2 Step :  38 loss :  213.555001461\n",
      "Epoch :  2 Step :  39 loss :  207.017651861\n",
      "Epoch :  2 Step :  40 loss :  179.944559339\n",
      "Epoch :  2 Step :  41 loss :  214.198117806\n",
      "Epoch :  2 Step :  42 loss :  175.113541148\n",
      "Epoch :  2 Step :  43 loss :  197.376770411\n",
      "Epoch :  2 Step :  44 loss :  184.137752378\n",
      "Epoch :  2 Step :  45 loss :  200.665298621\n",
      "Epoch :  2 Step :  46 loss :  236.706121682\n",
      "Epoch :  2 Step :  47 loss :  222.548052408\n",
      "Epoch :  2 Step :  48 loss :  218.434776861\n",
      "Epoch :  2 Step :  49 loss :  188.128675301\n",
      "Epoch :  2 Step :  50 loss :  215.600768736\n",
      "Epoch :  2 Step :  51 loss :  157.306472305\n",
      "Epoch :  2 Step :  52 loss :  167.177414879\n",
      "Epoch :  2 Step :  53 loss :  216.535230855\n",
      "Epoch :  2 Step :  54 loss :  211.080611654\n",
      "Epoch :  2 Step :  55 loss :  187.82555782\n",
      "Epoch :  2 Step :  56 loss :  214.887652388\n",
      "Epoch :  2 Step :  57 loss :  206.899644974\n",
      "Epoch :  2 Step :  58 loss :  168.496368064\n",
      "Epoch :  2 Step :  59 loss :  222.698029257\n",
      "Epoch :  2 Step :  60 loss :  172.083080969\n",
      "Epoch :  2 Step :  61 loss :  207.783040642\n",
      "Epoch :  2 Step :  62 loss :  230.159951105\n",
      "Epoch :  2 Step :  63 loss :  189.313025963\n",
      "Epoch :  2 Step :  64 loss :  214.044413189\n",
      "Epoch :  2 Step :  65 loss :  181.33139965\n",
      "Epoch :  2 Step :  66 loss :  199.811976685\n",
      "Epoch :  2 Step :  67 loss :  213.195163008\n",
      "Epoch :  2 Step :  68 loss :  175.066905108\n",
      "Epoch :  2 Step :  69 loss :  245.934026317\n",
      "Epoch :  2 Step :  70 loss :  254.20262777\n",
      "Epoch :  2 Step :  71 loss :  204.995806508\n",
      "Epoch :  2 Step :  72 loss :  250.689232699\n",
      "Epoch :  2 Step :  73 loss :  198.136503688\n",
      "Epoch :  2 Step :  74 loss :  180.218351451\n",
      "Epoch :  2 Step :  75 loss :  190.193603975\n",
      "Epoch :  2 Step :  76 loss :  275.42179053\n",
      "Epoch :  2 Step :  77 loss :  209.488690133\n",
      "Epoch :  2 Step :  78 loss :  171.404797254\n",
      "Epoch :  2 Step :  79 loss :  214.866160275\n",
      "Epoch :  2 Step :  80 loss :  183.682233084\n",
      "Epoch :  2 Step :  81 loss :  194.542898271\n",
      "Epoch :  2 Step :  82 loss :  210.24783864\n",
      "Epoch :  2 Step :  83 loss :  197.615801857\n",
      "Epoch :  2 Step :  84 loss :  176.149945392\n",
      "Epoch :  2 Step :  85 loss :  246.755711783\n",
      "Epoch :  2 Step :  86 loss :  151.67968427\n",
      "Epoch :  2 Step :  87 loss :  193.629171783\n",
      "Epoch :  2 Step :  88 loss :  215.650857885\n",
      "Epoch :  2 Step :  89 loss :  155.829278035\n",
      "Epoch :  2 Step :  90 loss :  206.989149695\n",
      "Epoch :  2 Step :  91 loss :  227.432759074\n",
      "Epoch :  2 Step :  92 loss :  185.019620096\n",
      "Epoch :  2 Step :  93 loss :  216.450394292\n",
      "Epoch :  2 Step :  94 loss :  189.594997983\n",
      "Epoch :  2 Step :  95 loss :  202.195889203\n",
      "Epoch :  2 Step :  96 loss :  186.573916213\n",
      "Epoch :  2 Step :  97 loss :  186.789879878\n",
      "Epoch :  2 Step :  98 loss :  184.526891691\n",
      "Epoch :  2 Step :  99 loss :  242.007329891\n",
      "Epoch :  2 Step :  100 loss :  158.896111656\n",
      "Epoch :  2 Step :  101 loss :  160.546364734\n",
      "Epoch :  2 Step :  102 loss :  210.042445337\n",
      "Epoch :  2 Step :  103 loss :  220.005870592\n",
      "Epoch :  2 Step :  104 loss :  210.08634181\n",
      "Epoch :  2 Step :  105 loss :  198.253662074\n",
      "Epoch :  2 Step :  106 loss :  159.255992049\n",
      "Epoch :  2 Step :  107 loss :  160.75977533\n",
      "Epoch :  2 Step :  108 loss :  198.432339377\n",
      "Epoch :  2 Step :  109 loss :  219.644482604\n",
      "Epoch :  2 Step :  110 loss :  182.114471517\n",
      "Epoch :  2 Step :  111 loss :  148.874487924\n",
      "Epoch :  2 Step :  112 loss :  215.912247741\n",
      "Epoch :  2 Step :  113 loss :  207.31250206\n",
      "Epoch :  2 Step :  114 loss :  158.778799349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  2 Step :  115 loss :  214.307239628\n",
      "Epoch :  2 Step :  116 loss :  207.433345115\n",
      "Epoch :  2 Step :  117 loss :  215.911107313\n",
      "Epoch :  2 Step :  118 loss :  220.714660756\n",
      "Epoch :  2 Step :  119 loss :  190.15202346\n",
      "Epoch :  2 Step :  120 loss :  195.838599562\n",
      "Epoch :  2 Step :  121 loss :  165.010550908\n",
      "Epoch :  2 Step :  122 loss :  212.040449235\n",
      "Epoch :  2 Step :  123 loss :  195.405374833\n",
      "Epoch :  2 Step :  124 loss :  182.372703414\n",
      "Epoch :  2 Step :  125 loss :  192.387401759\n",
      "Epoch :  2 Step :  126 loss :  186.098199916\n",
      "Epoch :  2 Step :  127 loss :  165.488807272\n",
      "Epoch :  2 Step :  128 loss :  188.737269478\n",
      "Epoch :  2 Step :  129 loss :  197.821402929\n",
      "Epoch :  2 Step :  130 loss :  158.838442528\n",
      "Epoch :  2 Step :  131 loss :  227.321391912\n",
      "Epoch :  2 Step :  132 loss :  143.031919541\n",
      "Epoch :  2 Step :  133 loss :  213.663461975\n",
      "Epoch :  2 Step :  134 loss :  217.996287872\n",
      "Epoch :  2 Step :  135 loss :  226.379555027\n",
      "Epoch :  2 Step :  136 loss :  216.389694992\n",
      "Epoch :  2 Step :  137 loss :  167.07030234\n",
      "Epoch :  2 Step :  138 loss :  199.63882916\n",
      "Epoch :  2 Step :  139 loss :  205.267935513\n",
      "Epoch :  2 Step :  140 loss :  146.589320435\n",
      "Epoch :  2 Step :  141 loss :  196.901469714\n",
      "Epoch :  2 Step :  142 loss :  199.830682971\n",
      "Epoch :  2 Step :  143 loss :  197.06047553\n",
      "Epoch :  2 Step :  144 loss :  236.516549899\n",
      "Epoch :  2 Step :  145 loss :  228.341636855\n",
      "Epoch :  2 Step :  146 loss :  172.244457719\n",
      "Epoch :  2 Step :  147 loss :  202.897143751\n",
      "Epoch :  2 Step :  148 loss :  178.182317007\n",
      "Epoch :  2 Step :  149 loss :  220.689564175\n",
      "Epoch :  2 Step :  150 loss :  183.460823501\n",
      "Epoch :  2 Step :  151 loss :  198.394057573\n",
      "Epoch :  2 Step :  152 loss :  218.527912181\n",
      "Epoch :  2 Step :  153 loss :  153.488141993\n",
      "Epoch :  2 Step :  154 loss :  193.582949964\n",
      "Epoch :  2 Step :  155 loss :  206.208976138\n",
      "Epoch :  2 Step :  156 loss :  223.79179888\n",
      "Epoch :  2 Step :  157 loss :  189.249513803\n",
      "Epoch :  2 Step :  158 loss :  195.749559672\n",
      "Epoch :  2 Step :  159 loss :  176.359159448\n",
      "Epoch :  2 Step :  160 loss :  188.778283476\n",
      "Epoch :  2 Step :  161 loss :  158.987900105\n",
      "Epoch :  2 Step :  162 loss :  201.114814307\n",
      "Epoch :  2 Step :  163 loss :  191.127625594\n",
      "Epoch :  2 Step :  164 loss :  153.241787072\n",
      "Epoch :  2 Step :  165 loss :  208.848999947\n",
      "Epoch :  2 Step :  166 loss :  169.36274192\n",
      "Epoch :  2 Step :  167 loss :  163.028862389\n",
      "Epoch :  2 Step :  168 loss :  188.933740966\n",
      "Epoch :  2 Step :  169 loss :  202.357053056\n",
      "Epoch :  2 Step :  170 loss :  170.280361241\n",
      "Epoch :  2 Step :  171 loss :  180.007390963\n",
      "Epoch :  2 Step :  172 loss :  186.825485803\n",
      "Epoch :  2 Step :  173 loss :  166.761884874\n",
      "Epoch :  2 Step :  174 loss :  192.656184409\n",
      "Epoch :  2 Step :  175 loss :  186.198988436\n",
      "Epoch :  2 Step :  176 loss :  189.860269667\n",
      "Epoch :  2 Step :  177 loss :  183.693617708\n",
      "Epoch :  2 Step :  178 loss :  162.193666453\n",
      "Epoch :  2 Step :  179 loss :  233.037915569\n",
      "Epoch :  2 Step :  180 loss :  194.708780208\n",
      "Epoch :  2 Step :  181 loss :  166.400668504\n",
      "Epoch :  2 Step :  182 loss :  188.101372175\n",
      "Epoch :  2 Step :  183 loss :  184.379005992\n",
      "Epoch :  2 Step :  184 loss :  182.3715049\n",
      "Epoch :  2 Step :  185 loss :  174.0430911\n",
      "Epoch :  2 Step :  186 loss :  167.711423282\n",
      "Epoch :  2 Step :  187 loss :  221.945003923\n",
      "Epoch :  2 Step :  188 loss :  215.675280372\n",
      "Epoch :  2 Step :  189 loss :  191.369696517\n",
      "Epoch :  2 Step :  190 loss :  183.818742623\n",
      "Epoch :  2 Step :  191 loss :  146.148122258\n",
      "Epoch :  2 Step :  192 loss :  135.102436346\n",
      "Epoch :  2 Step :  193 loss :  199.91824646\n",
      "Epoch :  2 Step :  194 loss :  170.400278847\n",
      "Epoch :  2 Step :  195 loss :  188.962688391\n",
      "Epoch :  2 Step :  196 loss :  160.207211149\n",
      "Epoch :  2 Step :  197 loss :  189.11742576\n",
      "Epoch :  2 Step :  198 loss :  189.103808811\n",
      "Epoch :  2 Step :  199 loss :  207.06966772\n",
      "Epoch :  2 Step :  200 loss :  213.24270295\n",
      "Epoch :  2 Step :  201 loss :  164.951883028\n",
      "Epoch :  2 Step :  202 loss :  182.291092368\n",
      "Epoch :  2 Step :  203 loss :  162.694953112\n",
      "Epoch :  2 Step :  204 loss :  194.287669842\n",
      "Epoch :  2 Step :  205 loss :  228.359489126\n",
      "Epoch :  2 Step :  206 loss :  203.916513292\n",
      "Epoch :  2 Step :  207 loss :  184.575542803\n",
      "Epoch :  2 Step :  208 loss :  148.551645915\n",
      "Epoch :  2 Step :  209 loss :  180.926183121\n",
      "Epoch :  2 Step :  210 loss :  226.945248457\n",
      "Epoch :  2 Step :  211 loss :  197.975113936\n",
      "Epoch :  2 Step :  212 loss :  193.182498616\n",
      "Epoch :  2 Step :  213 loss :  221.150902174\n",
      "Epoch :  2 Step :  214 loss :  229.722585843\n",
      "Epoch :  2 Step :  215 loss :  214.016011491\n",
      "Epoch :  2 Step :  216 loss :  211.833593753\n",
      "Epoch :  2 Step :  217 loss :  193.177409228\n",
      "Epoch :  2 Step :  218 loss :  206.118606537\n",
      "Epoch :  2 Step :  219 loss :  200.042798415\n",
      "Epoch :  3 Step :  0 loss :  166.486629452\n",
      "Epoch :  3 Step :  1 loss :  192.257179313\n",
      "Epoch :  3 Step :  2 loss :  172.194338058\n",
      "Epoch :  3 Step :  3 loss :  179.51262202\n",
      "Epoch :  3 Step :  4 loss :  194.911122127\n",
      "Epoch :  3 Step :  5 loss :  190.448941498\n",
      "Epoch :  3 Step :  6 loss :  126.94513538\n",
      "Epoch :  3 Step :  7 loss :  158.933541418\n",
      "Epoch :  3 Step :  8 loss :  175.632848373\n",
      "Epoch :  3 Step :  9 loss :  162.768206388\n",
      "Epoch :  3 Step :  10 loss :  166.241129798\n",
      "Epoch :  3 Step :  11 loss :  218.109034579\n",
      "Epoch :  3 Step :  12 loss :  168.639963193\n",
      "Epoch :  3 Step :  13 loss :  163.710935798\n",
      "Epoch :  3 Step :  14 loss :  182.400101618\n",
      "Epoch :  3 Step :  15 loss :  209.531295801\n",
      "Epoch :  3 Step :  16 loss :  148.50399591\n",
      "Epoch :  3 Step :  17 loss :  170.996613566\n",
      "Epoch :  3 Step :  18 loss :  156.971822033\n",
      "Epoch :  3 Step :  19 loss :  143.58027091\n",
      "Epoch :  3 Step :  20 loss :  200.706120079\n",
      "Epoch :  3 Step :  21 loss :  229.563129937\n",
      "Epoch :  3 Step :  22 loss :  197.343725167\n",
      "Epoch :  3 Step :  23 loss :  157.302224998\n",
      "Epoch :  3 Step :  24 loss :  164.345796874\n",
      "Epoch :  3 Step :  25 loss :  203.065793934\n",
      "Epoch :  3 Step :  26 loss :  160.507634963\n",
      "Epoch :  3 Step :  27 loss :  156.045092819\n",
      "Epoch :  3 Step :  28 loss :  162.807148933\n",
      "Epoch :  3 Step :  29 loss :  156.944060026\n",
      "Epoch :  3 Step :  30 loss :  189.871436429\n",
      "Epoch :  3 Step :  31 loss :  176.952022538\n",
      "Epoch :  3 Step :  32 loss :  172.711165716\n",
      "Epoch :  3 Step :  33 loss :  169.551191934\n",
      "Epoch :  3 Step :  34 loss :  176.475566967\n",
      "Epoch :  3 Step :  35 loss :  215.164259628\n",
      "Epoch :  3 Step :  36 loss :  167.762206198\n",
      "Epoch :  3 Step :  37 loss :  172.454151331\n",
      "Epoch :  3 Step :  38 loss :  196.885665373\n",
      "Epoch :  3 Step :  39 loss :  190.328917198\n",
      "Epoch :  3 Step :  40 loss :  150.737722443\n",
      "Epoch :  3 Step :  41 loss :  182.644950012\n",
      "Epoch :  3 Step :  42 loss :  150.452259153\n",
      "Epoch :  3 Step :  43 loss :  166.97452094\n",
      "Epoch :  3 Step :  44 loss :  163.276415545\n",
      "Epoch :  3 Step :  45 loss :  181.484762974\n",
      "Epoch :  3 Step :  46 loss :  208.056042855\n",
      "Epoch :  3 Step :  47 loss :  208.235976451\n",
      "Epoch :  3 Step :  48 loss :  193.905609399\n",
      "Epoch :  3 Step :  49 loss :  175.16584356\n",
      "Epoch :  3 Step :  50 loss :  176.13063683\n",
      "Epoch :  3 Step :  51 loss :  143.589910466\n",
      "Epoch :  3 Step :  52 loss :  161.281768924\n",
      "Epoch :  3 Step :  53 loss :  176.895214626\n",
      "Epoch :  3 Step :  54 loss :  190.913981461\n",
      "Epoch :  3 Step :  55 loss :  164.615662588\n",
      "Epoch :  3 Step :  56 loss :  200.942716937\n",
      "Epoch :  3 Step :  57 loss :  175.345684457\n",
      "Epoch :  3 Step :  58 loss :  160.956952078\n",
      "Epoch :  3 Step :  59 loss :  188.925070202\n",
      "Epoch :  3 Step :  60 loss :  158.503107008\n",
      "Epoch :  3 Step :  61 loss :  181.868318397\n",
      "Epoch :  3 Step :  62 loss :  196.325903208\n",
      "Epoch :  3 Step :  63 loss :  162.815218289\n",
      "Epoch :  3 Step :  64 loss :  191.179447593\n",
      "Epoch :  3 Step :  65 loss :  156.231609969\n",
      "Epoch :  3 Step :  66 loss :  189.063840189\n",
      "Epoch :  3 Step :  67 loss :  174.519564944\n",
      "Epoch :  3 Step :  68 loss :  158.269390315\n",
      "Epoch :  3 Step :  69 loss :  224.32097561\n",
      "Epoch :  3 Step :  70 loss :  223.121819896\n",
      "Epoch :  3 Step :  71 loss :  185.534297479\n",
      "Epoch :  3 Step :  72 loss :  205.852935598\n",
      "Epoch :  3 Step :  73 loss :  191.953200942\n",
      "Epoch :  3 Step :  74 loss :  155.439140757\n",
      "Epoch :  3 Step :  75 loss :  173.090759858\n",
      "Epoch :  3 Step :  76 loss :  240.588154547\n",
      "Epoch :  3 Step :  77 loss :  174.504727574\n",
      "Epoch :  3 Step :  78 loss :  137.738400943\n",
      "Epoch :  3 Step :  79 loss :  194.670448075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  3 Step :  80 loss :  154.201947759\n",
      "Epoch :  3 Step :  81 loss :  184.961501522\n",
      "Epoch :  3 Step :  82 loss :  194.282425786\n",
      "Epoch :  3 Step :  83 loss :  172.585005669\n",
      "Epoch :  3 Step :  84 loss :  156.879658575\n",
      "Epoch :  3 Step :  85 loss :  202.755691506\n",
      "Epoch :  3 Step :  86 loss :  137.332086965\n",
      "Epoch :  3 Step :  87 loss :  159.996531603\n",
      "Epoch :  3 Step :  88 loss :  196.479659413\n",
      "Epoch :  3 Step :  89 loss :  133.726065778\n",
      "Epoch :  3 Step :  90 loss :  169.773717279\n",
      "Epoch :  3 Step :  91 loss :  207.419862435\n",
      "Epoch :  3 Step :  92 loss :  173.13224964\n",
      "Epoch :  3 Step :  93 loss :  190.233935243\n",
      "Epoch :  3 Step :  94 loss :  152.51831558\n",
      "Epoch :  3 Step :  95 loss :  161.709940993\n",
      "Epoch :  3 Step :  96 loss :  161.640362293\n",
      "Epoch :  3 Step :  97 loss :  168.155189427\n",
      "Epoch :  3 Step :  98 loss :  178.435424688\n",
      "Epoch :  3 Step :  99 loss :  201.208427353\n",
      "Epoch :  3 Step :  100 loss :  133.792006071\n",
      "Epoch :  3 Step :  101 loss :  146.458448111\n",
      "Epoch :  3 Step :  102 loss :  184.595383983\n",
      "Epoch :  3 Step :  103 loss :  202.051382201\n",
      "Epoch :  3 Step :  104 loss :  187.861251233\n",
      "Epoch :  3 Step :  105 loss :  171.427378952\n",
      "Epoch :  3 Step :  106 loss :  132.097493952\n",
      "Epoch :  3 Step :  107 loss :  133.683475976\n",
      "Epoch :  3 Step :  108 loss :  184.203187812\n",
      "Epoch :  3 Step :  109 loss :  181.841171228\n",
      "Epoch :  3 Step :  110 loss :  171.085459482\n",
      "Epoch :  3 Step :  111 loss :  127.273639724\n",
      "Epoch :  3 Step :  112 loss :  186.347453261\n",
      "Epoch :  3 Step :  113 loss :  188.914731099\n",
      "Epoch :  3 Step :  114 loss :  148.867811425\n",
      "Epoch :  3 Step :  115 loss :  180.2311141\n",
      "Epoch :  3 Step :  116 loss :  179.136228931\n",
      "Epoch :  3 Step :  117 loss :  200.71530849\n",
      "Epoch :  3 Step :  118 loss :  186.368402041\n",
      "Epoch :  3 Step :  119 loss :  166.780695192\n",
      "Epoch :  3 Step :  120 loss :  176.945580229\n",
      "Epoch :  3 Step :  121 loss :  153.641411768\n",
      "Epoch :  3 Step :  122 loss :  188.136938179\n",
      "Epoch :  3 Step :  123 loss :  174.073785884\n",
      "Epoch :  3 Step :  124 loss :  159.815627202\n",
      "Epoch :  3 Step :  125 loss :  175.934951104\n",
      "Epoch :  3 Step :  126 loss :  172.09087961\n",
      "Epoch :  3 Step :  127 loss :  139.823469949\n",
      "Epoch :  3 Step :  128 loss :  173.653872989\n",
      "Epoch :  3 Step :  129 loss :  184.711607902\n",
      "Epoch :  3 Step :  130 loss :  130.33065194\n",
      "Epoch :  3 Step :  131 loss :  217.658273218\n",
      "Epoch :  3 Step :  132 loss :  124.029510407\n",
      "Epoch :  3 Step :  133 loss :  192.317145734\n",
      "Epoch :  3 Step :  134 loss :  186.380706043\n",
      "Epoch :  3 Step :  135 loss :  205.517662931\n",
      "Epoch :  3 Step :  136 loss :  181.188210075\n",
      "Epoch :  3 Step :  137 loss :  150.321954422\n",
      "Epoch :  3 Step :  138 loss :  182.135130689\n",
      "Epoch :  3 Step :  139 loss :  191.967972307\n",
      "Epoch :  3 Step :  140 loss :  137.405031413\n",
      "Epoch :  3 Step :  141 loss :  176.068181406\n",
      "Epoch :  3 Step :  142 loss :  179.986778209\n",
      "Epoch :  3 Step :  143 loss :  175.420815397\n",
      "Epoch :  3 Step :  144 loss :  212.243862664\n",
      "Epoch :  3 Step :  145 loss :  204.110694499\n",
      "Epoch :  3 Step :  146 loss :  152.519651656\n",
      "Epoch :  3 Step :  147 loss :  189.202466501\n",
      "Epoch :  3 Step :  148 loss :  156.390915618\n",
      "Epoch :  3 Step :  149 loss :  191.946952842\n",
      "Epoch :  3 Step :  150 loss :  160.620126589\n",
      "Epoch :  3 Step :  151 loss :  187.16828707\n",
      "Epoch :  3 Step :  152 loss :  197.178619612\n",
      "Epoch :  3 Step :  153 loss :  149.484269545\n",
      "Epoch :  3 Step :  154 loss :  173.804138905\n",
      "Epoch :  3 Step :  155 loss :  184.354625102\n",
      "Epoch :  3 Step :  156 loss :  192.766875731\n",
      "Epoch :  3 Step :  157 loss :  171.480470149\n",
      "Epoch :  3 Step :  158 loss :  182.130740856\n",
      "Epoch :  3 Step :  159 loss :  151.411577758\n",
      "Epoch :  3 Step :  160 loss :  164.770126962\n",
      "Epoch :  3 Step :  161 loss :  157.779132708\n",
      "Epoch :  3 Step :  162 loss :  160.803406094\n",
      "Epoch :  3 Step :  163 loss :  173.943033741\n",
      "Epoch :  3 Step :  164 loss :  129.37475131\n",
      "Epoch :  3 Step :  165 loss :  180.588237225\n",
      "Epoch :  3 Step :  166 loss :  150.086438476\n",
      "Epoch :  3 Step :  167 loss :  159.321393845\n",
      "Epoch :  3 Step :  168 loss :  174.792867916\n",
      "Epoch :  3 Step :  169 loss :  161.286913927\n",
      "Epoch :  3 Step :  170 loss :  165.19251044\n",
      "Epoch :  3 Step :  171 loss :  172.219823273\n",
      "Epoch :  3 Step :  172 loss :  170.691406402\n",
      "Epoch :  3 Step :  173 loss :  150.06343111\n",
      "Epoch :  3 Step :  174 loss :  152.285076957\n",
      "Epoch :  3 Step :  175 loss :  169.445738251\n",
      "Epoch :  3 Step :  176 loss :  174.588407229\n",
      "Epoch :  3 Step :  177 loss :  172.251452172\n",
      "Epoch :  3 Step :  178 loss :  145.383658224\n",
      "Epoch :  3 Step :  179 loss :  207.033739072\n",
      "Epoch :  3 Step :  180 loss :  173.839751237\n",
      "Epoch :  3 Step :  181 loss :  151.451693599\n",
      "Epoch :  3 Step :  182 loss :  168.438801993\n",
      "Epoch :  3 Step :  183 loss :  173.121614916\n",
      "Epoch :  3 Step :  184 loss :  151.996610565\n",
      "Epoch :  3 Step :  185 loss :  150.431313572\n",
      "Epoch :  3 Step :  186 loss :  154.722995101\n",
      "Epoch :  3 Step :  187 loss :  184.233179603\n",
      "Epoch :  3 Step :  188 loss :  205.168032165\n",
      "Epoch :  3 Step :  189 loss :  164.150711954\n",
      "Epoch :  3 Step :  190 loss :  171.780429392\n",
      "Epoch :  3 Step :  191 loss :  126.966458942\n",
      "Epoch :  3 Step :  192 loss :  115.161788615\n",
      "Epoch :  3 Step :  193 loss :  176.180075937\n",
      "Epoch :  3 Step :  194 loss :  158.767595294\n",
      "Epoch :  3 Step :  195 loss :  163.487600633\n",
      "Epoch :  3 Step :  196 loss :  143.759142225\n",
      "Epoch :  3 Step :  197 loss :  165.764142059\n",
      "Epoch :  3 Step :  198 loss :  171.014820706\n",
      "Epoch :  3 Step :  199 loss :  183.638773794\n",
      "Epoch :  3 Step :  200 loss :  192.982917132\n",
      "Epoch :  3 Step :  201 loss :  153.087711149\n",
      "Epoch :  3 Step :  202 loss :  160.276104778\n",
      "Epoch :  3 Step :  203 loss :  149.155527269\n",
      "Epoch :  3 Step :  204 loss :  179.960989708\n",
      "Epoch :  3 Step :  205 loss :  194.799157781\n",
      "Epoch :  3 Step :  206 loss :  180.95086842\n",
      "Epoch :  3 Step :  207 loss :  167.42159747\n",
      "Epoch :  3 Step :  208 loss :  133.576595404\n",
      "Epoch :  3 Step :  209 loss :  167.927302011\n",
      "Epoch :  3 Step :  210 loss :  200.921389668\n",
      "Epoch :  3 Step :  211 loss :  178.671684728\n",
      "Epoch :  3 Step :  212 loss :  169.383610897\n",
      "Epoch :  3 Step :  213 loss :  205.790650672\n",
      "Epoch :  3 Step :  214 loss :  203.452697231\n",
      "Epoch :  3 Step :  215 loss :  172.14397164\n",
      "Epoch :  3 Step :  216 loss :  191.820266713\n",
      "Epoch :  3 Step :  217 loss :  161.374376879\n",
      "Epoch :  3 Step :  218 loss :  190.039778582\n",
      "Epoch :  3 Step :  219 loss :  195.947869475\n",
      "Epoch :  4 Step :  0 loss :  146.824733447\n",
      "Epoch :  4 Step :  1 loss :  166.30840573\n",
      "Epoch :  4 Step :  2 loss :  154.938543089\n",
      "Epoch :  4 Step :  3 loss :  152.373569537\n",
      "Epoch :  4 Step :  4 loss :  192.001623559\n",
      "Epoch :  4 Step :  5 loss :  165.923288505\n",
      "Epoch :  4 Step :  6 loss :  116.635061577\n",
      "Epoch :  4 Step :  7 loss :  138.019054875\n",
      "Epoch :  4 Step :  8 loss :  172.563652173\n",
      "Epoch :  4 Step :  9 loss :  157.995698264\n",
      "Epoch :  4 Step :  10 loss :  147.36327255\n",
      "Epoch :  4 Step :  11 loss :  200.708746968\n",
      "Epoch :  4 Step :  12 loss :  135.267094571\n",
      "Epoch :  4 Step :  13 loss :  154.725816305\n",
      "Epoch :  4 Step :  14 loss :  161.702069421\n",
      "Epoch :  4 Step :  15 loss :  184.779461641\n",
      "Epoch :  4 Step :  16 loss :  135.543525557\n",
      "Epoch :  4 Step :  17 loss :  145.040380086\n",
      "Epoch :  4 Step :  18 loss :  146.304390041\n",
      "Epoch :  4 Step :  19 loss :  132.832793257\n",
      "Epoch :  4 Step :  20 loss :  195.71884789\n",
      "Epoch :  4 Step :  21 loss :  207.783494729\n",
      "Epoch :  4 Step :  22 loss :  169.577047501\n",
      "Epoch :  4 Step :  23 loss :  135.012053657\n",
      "Epoch :  4 Step :  24 loss :  148.102385961\n",
      "Epoch :  4 Step :  25 loss :  179.033310454\n",
      "Epoch :  4 Step :  26 loss :  145.346982527\n",
      "Epoch :  4 Step :  27 loss :  136.322595329\n",
      "Epoch :  4 Step :  28 loss :  152.136831351\n",
      "Epoch :  4 Step :  29 loss :  141.084902485\n",
      "Epoch :  4 Step :  30 loss :  173.151409873\n",
      "Epoch :  4 Step :  31 loss :  169.369263217\n",
      "Epoch :  4 Step :  32 loss :  151.779485821\n",
      "Epoch :  4 Step :  33 loss :  152.793089432\n",
      "Epoch :  4 Step :  34 loss :  158.239630212\n",
      "Epoch :  4 Step :  35 loss :  185.542149643\n",
      "Epoch :  4 Step :  36 loss :  136.289930673\n",
      "Epoch :  4 Step :  37 loss :  162.080775605\n",
      "Epoch :  4 Step :  38 loss :  173.274650633\n",
      "Epoch :  4 Step :  39 loss :  177.001702851\n",
      "Epoch :  4 Step :  40 loss :  138.385347136\n",
      "Epoch :  4 Step :  41 loss :  164.381897401\n",
      "Epoch :  4 Step :  42 loss :  146.05813815\n",
      "Epoch :  4 Step :  43 loss :  153.289982716\n",
      "Epoch :  4 Step :  44 loss :  155.196686434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  4 Step :  45 loss :  172.192373527\n",
      "Epoch :  4 Step :  46 loss :  181.994089597\n",
      "Epoch :  4 Step :  47 loss :  194.046721952\n",
      "Epoch :  4 Step :  48 loss :  169.925879269\n",
      "Epoch :  4 Step :  49 loss :  150.583667968\n",
      "Epoch :  4 Step :  50 loss :  160.525233522\n",
      "Epoch :  4 Step :  51 loss :  122.82728244\n",
      "Epoch :  4 Step :  52 loss :  150.259630398\n",
      "Epoch :  4 Step :  53 loss :  155.324659717\n",
      "Epoch :  4 Step :  54 loss :  170.671684055\n",
      "Epoch :  4 Step :  55 loss :  148.729115143\n",
      "Epoch :  4 Step :  56 loss :  184.358753397\n",
      "Epoch :  4 Step :  57 loss :  169.997880593\n",
      "Epoch :  4 Step :  58 loss :  139.43511995\n",
      "Epoch :  4 Step :  59 loss :  175.945872444\n",
      "Epoch :  4 Step :  60 loss :  137.969561092\n",
      "Epoch :  4 Step :  61 loss :  170.326294542\n",
      "Epoch :  4 Step :  62 loss :  178.795343047\n",
      "Epoch :  4 Step :  63 loss :  152.068430519\n",
      "Epoch :  4 Step :  64 loss :  175.692443088\n",
      "Epoch :  4 Step :  65 loss :  145.296147111\n",
      "Epoch :  4 Step :  66 loss :  173.522276773\n",
      "Epoch :  4 Step :  67 loss :  163.242951915\n",
      "Epoch :  4 Step :  68 loss :  140.97813268\n",
      "Epoch :  4 Step :  69 loss :  197.898295775\n",
      "Epoch :  4 Step :  70 loss :  190.789718324\n",
      "Epoch :  4 Step :  71 loss :  162.422758318\n",
      "Epoch :  4 Step :  72 loss :  196.440136565\n",
      "Epoch :  4 Step :  73 loss :  165.312284761\n",
      "Epoch :  4 Step :  74 loss :  141.769178591\n",
      "Epoch :  4 Step :  75 loss :  162.535524769\n",
      "Epoch :  4 Step :  76 loss :  229.94401842\n",
      "Epoch :  4 Step :  77 loss :  154.368634172\n",
      "Epoch :  4 Step :  78 loss :  120.164024091\n",
      "Epoch :  4 Step :  79 loss :  169.917319561\n",
      "Epoch :  4 Step :  80 loss :  148.109861295\n",
      "Epoch :  4 Step :  81 loss :  159.922849901\n",
      "Epoch :  4 Step :  82 loss :  173.701425699\n",
      "Epoch :  4 Step :  83 loss :  174.013294043\n",
      "Epoch :  4 Step :  84 loss :  133.297493674\n",
      "Epoch :  4 Step :  85 loss :  191.204227248\n",
      "Epoch :  4 Step :  86 loss :  120.32423166\n",
      "Epoch :  4 Step :  87 loss :  150.566895303\n",
      "Epoch :  4 Step :  88 loss :  178.645348008\n",
      "Epoch :  4 Step :  89 loss :  123.865281556\n",
      "Epoch :  4 Step :  90 loss :  148.548289008\n",
      "Epoch :  4 Step :  91 loss :  178.836098741\n",
      "Epoch :  4 Step :  92 loss :  150.388515599\n",
      "Epoch :  4 Step :  93 loss :  162.862057092\n",
      "Epoch :  4 Step :  94 loss :  137.065310624\n",
      "Epoch :  4 Step :  95 loss :  132.376903815\n",
      "Epoch :  4 Step :  96 loss :  140.073670022\n",
      "Epoch :  4 Step :  97 loss :  151.614554018\n",
      "Epoch :  4 Step :  98 loss :  161.908228516\n",
      "Epoch :  4 Step :  99 loss :  177.8169827\n",
      "Epoch :  4 Step :  100 loss :  112.423482027\n",
      "Epoch :  4 Step :  101 loss :  141.370936326\n",
      "Epoch :  4 Step :  102 loss :  184.983382185\n",
      "Epoch :  4 Step :  103 loss :  176.026232882\n",
      "Epoch :  4 Step :  104 loss :  180.237940161\n",
      "Epoch :  4 Step :  105 loss :  164.34557314\n",
      "Epoch :  4 Step :  106 loss :  123.304091653\n",
      "Epoch :  4 Step :  107 loss :  128.311153193\n",
      "Epoch :  4 Step :  108 loss :  163.371182817\n",
      "Epoch :  4 Step :  109 loss :  156.51642286\n",
      "Epoch :  4 Step :  110 loss :  168.698459222\n",
      "Epoch :  4 Step :  111 loss :  124.885312366\n",
      "Epoch :  4 Step :  112 loss :  176.710834488\n",
      "Epoch :  4 Step :  113 loss :  167.548158033\n",
      "Epoch :  4 Step :  114 loss :  136.292488607\n",
      "Epoch :  4 Step :  115 loss :  163.575403475\n",
      "Epoch :  4 Step :  116 loss :  163.298236856\n",
      "Epoch :  4 Step :  117 loss :  177.236387359\n",
      "Epoch :  4 Step :  118 loss :  177.152009274\n",
      "Epoch :  4 Step :  119 loss :  142.92927284\n",
      "Epoch :  4 Step :  120 loss :  154.073370874\n",
      "Epoch :  4 Step :  121 loss :  139.216470739\n",
      "Epoch :  4 Step :  122 loss :  167.81230743\n",
      "Epoch :  4 Step :  123 loss :  161.450602419\n",
      "Epoch :  4 Step :  124 loss :  136.781633437\n",
      "Epoch :  4 Step :  125 loss :  156.527114823\n",
      "Epoch :  4 Step :  126 loss :  151.157330073\n",
      "Epoch :  4 Step :  127 loss :  123.295106543\n",
      "Epoch :  4 Step :  128 loss :  161.707244398\n",
      "Epoch :  4 Step :  129 loss :  172.962966996\n",
      "Epoch :  4 Step :  130 loss :  120.895340521\n",
      "Epoch :  4 Step :  131 loss :  196.616517549\n",
      "Epoch :  4 Step :  132 loss :  119.973152727\n",
      "Epoch :  4 Step :  133 loss :  174.960320509\n",
      "Epoch :  4 Step :  134 loss :  167.712614807\n",
      "Epoch :  4 Step :  135 loss :  186.994245835\n",
      "Epoch :  4 Step :  136 loss :  161.310558738\n",
      "Epoch :  4 Step :  137 loss :  143.117208334\n",
      "Epoch :  4 Step :  138 loss :  164.659668738\n",
      "Epoch :  4 Step :  139 loss :  174.227740398\n",
      "Epoch :  4 Step :  140 loss :  123.32346783\n",
      "Epoch :  4 Step :  141 loss :  154.544705226\n",
      "Epoch :  4 Step :  142 loss :  168.420037613\n",
      "Epoch :  4 Step :  143 loss :  161.290098732\n",
      "Epoch :  4 Step :  144 loss :  193.369917173\n",
      "Epoch :  4 Step :  145 loss :  175.232777933\n",
      "Epoch :  4 Step :  146 loss :  140.990382962\n",
      "Epoch :  4 Step :  147 loss :  175.529808862\n",
      "Epoch :  4 Step :  148 loss :  135.645515129\n",
      "Epoch :  4 Step :  149 loss :  182.921887789\n",
      "Epoch :  4 Step :  150 loss :  149.553714974\n",
      "Epoch :  4 Step :  151 loss :  173.748108326\n",
      "Epoch :  4 Step :  152 loss :  186.957696445\n",
      "Epoch :  4 Step :  153 loss :  128.969552946\n",
      "Epoch :  4 Step :  154 loss :  163.054187599\n",
      "Epoch :  4 Step :  155 loss :  166.58260921\n",
      "Epoch :  4 Step :  156 loss :  166.377624721\n",
      "Epoch :  4 Step :  157 loss :  164.02564655\n",
      "Epoch :  4 Step :  158 loss :  171.284011045\n",
      "Epoch :  4 Step :  159 loss :  141.195558541\n",
      "Epoch :  4 Step :  160 loss :  157.345343452\n",
      "Epoch :  4 Step :  161 loss :  133.980321178\n",
      "Epoch :  4 Step :  162 loss :  154.665590734\n",
      "Epoch :  4 Step :  163 loss :  155.584883507\n",
      "Epoch :  4 Step :  164 loss :  116.214731155\n",
      "Epoch :  4 Step :  165 loss :  166.794608572\n",
      "Epoch :  4 Step :  166 loss :  134.253560659\n",
      "Epoch :  4 Step :  167 loss :  142.7179016\n",
      "Epoch :  4 Step :  168 loss :  153.574655973\n",
      "Epoch :  4 Step :  169 loss :  145.851064279\n",
      "Epoch :  4 Step :  170 loss :  151.233042028\n",
      "Epoch :  4 Step :  171 loss :  149.148991852\n",
      "Epoch :  4 Step :  172 loss :  143.444114162\n",
      "Epoch :  4 Step :  173 loss :  136.792013367\n",
      "Epoch :  4 Step :  174 loss :  144.208589056\n",
      "Epoch :  4 Step :  175 loss :  151.705861692\n",
      "Epoch :  4 Step :  176 loss :  161.765295279\n",
      "Epoch :  4 Step :  177 loss :  153.707282533\n",
      "Epoch :  4 Step :  178 loss :  145.710088282\n",
      "Epoch :  4 Step :  179 loss :  196.216473691\n",
      "Epoch :  4 Step :  180 loss :  160.946796543\n",
      "Epoch :  4 Step :  181 loss :  132.425890186\n",
      "Epoch :  4 Step :  182 loss :  162.937526357\n",
      "Epoch :  4 Step :  183 loss :  160.714306815\n",
      "Epoch :  4 Step :  184 loss :  142.783160943\n",
      "Epoch :  4 Step :  185 loss :  140.975760496\n",
      "Epoch :  4 Step :  186 loss :  140.43054248\n",
      "Epoch :  4 Step :  187 loss :  164.154449435\n",
      "Epoch :  4 Step :  188 loss :  193.883463788\n",
      "Epoch :  4 Step :  189 loss :  156.057552911\n",
      "Epoch :  4 Step :  190 loss :  157.557596288\n",
      "Epoch :  4 Step :  191 loss :  112.130411075\n",
      "Epoch :  4 Step :  192 loss :  106.122736852\n",
      "Epoch :  4 Step :  193 loss :  154.215067939\n",
      "Epoch :  4 Step :  194 loss :  145.831320966\n",
      "Epoch :  4 Step :  195 loss :  149.543869622\n",
      "Epoch :  4 Step :  196 loss :  126.978477237\n",
      "Epoch :  4 Step :  197 loss :  148.454506963\n",
      "Epoch :  4 Step :  198 loss :  155.542001411\n",
      "Epoch :  4 Step :  199 loss :  171.829341806\n",
      "Epoch :  4 Step :  200 loss :  178.258146183\n",
      "Epoch :  4 Step :  201 loss :  144.586657299\n",
      "Epoch :  4 Step :  202 loss :  148.639242432\n",
      "Epoch :  4 Step :  203 loss :  136.956892693\n",
      "Epoch :  4 Step :  204 loss :  175.665571938\n",
      "Epoch :  4 Step :  205 loss :  182.866013278\n",
      "Epoch :  4 Step :  206 loss :  168.457050179\n",
      "Epoch :  4 Step :  207 loss :  151.596229052\n",
      "Epoch :  4 Step :  208 loss :  123.101806955\n",
      "Epoch :  4 Step :  209 loss :  155.244704303\n",
      "Epoch :  4 Step :  210 loss :  184.109394893\n",
      "Epoch :  4 Step :  211 loss :  172.690085609\n",
      "Epoch :  4 Step :  212 loss :  152.752597349\n",
      "Epoch :  4 Step :  213 loss :  191.098020094\n",
      "Epoch :  4 Step :  214 loss :  186.878527856\n",
      "Epoch :  4 Step :  215 loss :  159.067141334\n",
      "Epoch :  4 Step :  216 loss :  178.768567284\n",
      "Epoch :  4 Step :  217 loss :  146.515805214\n",
      "Epoch :  4 Step :  218 loss :  178.248145587\n",
      "Epoch :  4 Step :  219 loss :  177.790923071\n",
      "Epoch :  5 Step :  0 loss :  128.682783249\n",
      "Epoch :  5 Step :  1 loss :  150.571345768\n",
      "Epoch :  5 Step :  2 loss :  144.712134129\n",
      "Epoch :  5 Step :  3 loss :  141.915113164\n",
      "Epoch :  5 Step :  4 loss :  167.033436222\n",
      "Epoch :  5 Step :  5 loss :  141.981304095\n",
      "Epoch :  5 Step :  6 loss :  106.892677941\n",
      "Epoch :  5 Step :  7 loss :  124.800840174\n",
      "Epoch :  5 Step :  8 loss :  151.55818295\n",
      "Epoch :  5 Step :  9 loss :  144.271930401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  5 Step :  10 loss :  139.763369859\n",
      "Epoch :  5 Step :  11 loss :  180.670590051\n",
      "Epoch :  5 Step :  12 loss :  120.176310948\n",
      "Epoch :  5 Step :  13 loss :  140.697476958\n",
      "Epoch :  5 Step :  14 loss :  151.449091935\n",
      "Epoch :  5 Step :  15 loss :  171.0147227\n",
      "Epoch :  5 Step :  16 loss :  119.948256009\n",
      "Epoch :  5 Step :  17 loss :  136.332505218\n",
      "Epoch :  5 Step :  18 loss :  132.283346483\n",
      "Epoch :  5 Step :  19 loss :  116.217018932\n",
      "Epoch :  5 Step :  20 loss :  176.758801761\n",
      "Epoch :  5 Step :  21 loss :  182.716069963\n",
      "Epoch :  5 Step :  22 loss :  159.417880512\n",
      "Epoch :  5 Step :  23 loss :  116.37879229\n",
      "Epoch :  5 Step :  24 loss :  136.37935719\n",
      "Epoch :  5 Step :  25 loss :  159.685854972\n",
      "Epoch :  5 Step :  26 loss :  125.675713515\n",
      "Epoch :  5 Step :  27 loss :  126.773458424\n",
      "Epoch :  5 Step :  28 loss :  135.921487257\n",
      "Epoch :  5 Step :  29 loss :  132.960489098\n",
      "Epoch :  5 Step :  30 loss :  158.95479111\n",
      "Epoch :  5 Step :  31 loss :  149.455950577\n",
      "Epoch :  5 Step :  32 loss :  143.157405684\n",
      "Epoch :  5 Step :  33 loss :  129.264300718\n",
      "Epoch :  5 Step :  34 loss :  138.671141161\n",
      "Epoch :  5 Step :  35 loss :  170.562164808\n",
      "Epoch :  5 Step :  36 loss :  127.902079322\n",
      "Epoch :  5 Step :  37 loss :  144.853787975\n",
      "Epoch :  5 Step :  38 loss :  148.359007767\n",
      "Epoch :  5 Step :  39 loss :  164.049256211\n",
      "Epoch :  5 Step :  40 loss :  126.907858567\n",
      "Epoch :  5 Step :  41 loss :  146.600493768\n",
      "Epoch :  5 Step :  42 loss :  131.314794035\n",
      "Epoch :  5 Step :  43 loss :  142.476148645\n",
      "Epoch :  5 Step :  44 loss :  136.09788637\n",
      "Epoch :  5 Step :  45 loss :  147.456171212\n",
      "Epoch :  5 Step :  46 loss :  165.080312801\n",
      "Epoch :  5 Step :  47 loss :  180.432118852\n",
      "Epoch :  5 Step :  48 loss :  153.507968981\n",
      "Epoch :  5 Step :  49 loss :  138.580672253\n",
      "Epoch :  5 Step :  50 loss :  145.174697277\n",
      "Epoch :  5 Step :  51 loss :  107.324553207\n",
      "Epoch :  5 Step :  52 loss :  132.003166448\n",
      "Epoch :  5 Step :  53 loss :  139.412353192\n",
      "Epoch :  5 Step :  54 loss :  158.587039626\n",
      "Epoch :  5 Step :  55 loss :  148.753227444\n",
      "Epoch :  5 Step :  56 loss :  164.624821985\n",
      "Epoch :  5 Step :  57 loss :  151.365169605\n",
      "Epoch :  5 Step :  58 loss :  123.525352971\n",
      "Epoch :  5 Step :  59 loss :  152.86645009\n",
      "Epoch :  5 Step :  60 loss :  130.576234613\n",
      "Epoch :  5 Step :  61 loss :  146.464981603\n",
      "Epoch :  5 Step :  62 loss :  154.4565874\n",
      "Epoch :  5 Step :  63 loss :  135.962484334\n",
      "Epoch :  5 Step :  64 loss :  153.111435831\n",
      "Epoch :  5 Step :  65 loss :  130.433880223\n",
      "Epoch :  5 Step :  66 loss :  159.383831725\n",
      "Epoch :  5 Step :  67 loss :  148.20303378\n",
      "Epoch :  5 Step :  68 loss :  122.991416364\n",
      "Epoch :  5 Step :  69 loss :  175.812777873\n",
      "Epoch :  5 Step :  70 loss :  172.779959973\n",
      "Epoch :  5 Step :  71 loss :  153.166387632\n",
      "Epoch :  5 Step :  72 loss :  168.863244625\n",
      "Epoch :  5 Step :  73 loss :  150.75897395\n",
      "Epoch :  5 Step :  74 loss :  115.9150103\n",
      "Epoch :  5 Step :  75 loss :  155.475503666\n",
      "Epoch :  5 Step :  76 loss :  206.301117371\n",
      "Epoch :  5 Step :  77 loss :  141.504149511\n",
      "Epoch :  5 Step :  78 loss :  105.827759145\n",
      "Epoch :  5 Step :  79 loss :  158.317337369\n",
      "Epoch :  5 Step :  80 loss :  145.998388593\n",
      "Epoch :  5 Step :  81 loss :  145.696775684\n",
      "Epoch :  5 Step :  82 loss :  156.149523826\n",
      "Epoch :  5 Step :  83 loss :  158.274956357\n",
      "Epoch :  5 Step :  84 loss :  123.467265083\n",
      "Epoch :  5 Step :  85 loss :  172.024078134\n",
      "Epoch :  5 Step :  86 loss :  107.403356844\n",
      "Epoch :  5 Step :  87 loss :  130.038990064\n",
      "Epoch :  5 Step :  88 loss :  160.442530827\n",
      "Epoch :  5 Step :  89 loss :  108.662638192\n",
      "Epoch :  5 Step :  90 loss :  134.491485352\n",
      "Epoch :  5 Step :  91 loss :  158.071463542\n",
      "Epoch :  5 Step :  92 loss :  136.914845857\n",
      "Epoch :  5 Step :  93 loss :  141.550860022\n",
      "Epoch :  5 Step :  94 loss :  123.656188325\n",
      "Epoch :  5 Step :  95 loss :  122.165344235\n",
      "Epoch :  5 Step :  96 loss :  130.70723832\n",
      "Epoch :  5 Step :  97 loss :  138.606365496\n",
      "Epoch :  5 Step :  98 loss :  143.317637989\n",
      "Epoch :  5 Step :  99 loss :  158.33371799\n",
      "Epoch :  5 Step :  100 loss :  110.077316928\n",
      "Epoch :  5 Step :  101 loss :  123.21032336\n",
      "Epoch :  5 Step :  102 loss :  153.771211966\n",
      "Epoch :  5 Step :  103 loss :  158.484183169\n",
      "Epoch :  5 Step :  104 loss :  156.573006558\n",
      "Epoch :  5 Step :  105 loss :  140.515637251\n",
      "Epoch :  5 Step :  106 loss :  108.720727294\n",
      "Epoch :  5 Step :  107 loss :  112.815505715\n",
      "Epoch :  5 Step :  108 loss :  138.194271341\n",
      "Epoch :  5 Step :  109 loss :  137.37215676\n",
      "Epoch :  5 Step :  110 loss :  154.103260302\n",
      "Epoch :  5 Step :  111 loss :  103.553445013\n",
      "Epoch :  5 Step :  112 loss :  155.546656444\n",
      "Epoch :  5 Step :  113 loss :  146.843334784\n",
      "Epoch :  5 Step :  114 loss :  114.813108775\n",
      "Epoch :  5 Step :  115 loss :  137.55669798\n",
      "Epoch :  5 Step :  116 loss :  145.510395598\n",
      "Epoch :  5 Step :  117 loss :  156.794324141\n",
      "Epoch :  5 Step :  118 loss :  161.126714789\n",
      "Epoch :  5 Step :  119 loss :  121.458265107\n",
      "Epoch :  5 Step :  120 loss :  141.548158677\n",
      "Epoch :  5 Step :  121 loss :  119.471765426\n",
      "Epoch :  5 Step :  122 loss :  150.049379954\n",
      "Epoch :  5 Step :  123 loss :  142.192511733\n",
      "Epoch :  5 Step :  124 loss :  123.311759561\n",
      "Epoch :  5 Step :  125 loss :  137.029761036\n",
      "Epoch :  5 Step :  126 loss :  140.223551988\n",
      "Epoch :  5 Step :  127 loss :  108.826344424\n",
      "Epoch :  5 Step :  128 loss :  134.110961646\n",
      "Epoch :  5 Step :  129 loss :  157.864096863\n",
      "Epoch :  5 Step :  130 loss :  104.040094132\n",
      "Epoch :  5 Step :  131 loss :  174.805020013\n",
      "Epoch :  5 Step :  132 loss :  113.955383757\n",
      "Epoch :  5 Step :  133 loss :  162.933634144\n",
      "Epoch :  5 Step :  134 loss :  160.950242986\n",
      "Epoch :  5 Step :  135 loss :  171.825007833\n",
      "Epoch :  5 Step :  136 loss :  143.634250065\n",
      "Epoch :  5 Step :  137 loss :  133.515106028\n",
      "Epoch :  5 Step :  138 loss :  135.297473318\n",
      "Epoch :  5 Step :  139 loss :  151.250465151\n",
      "Epoch :  5 Step :  140 loss :  116.752448896\n",
      "Epoch :  5 Step :  141 loss :  142.442144904\n",
      "Epoch :  5 Step :  142 loss :  147.749930638\n",
      "Epoch :  5 Step :  143 loss :  136.828512652\n",
      "Epoch :  5 Step :  144 loss :  177.315115225\n",
      "Epoch :  5 Step :  145 loss :  154.292562171\n",
      "Epoch :  5 Step :  146 loss :  131.048460266\n",
      "Epoch :  5 Step :  147 loss :  160.840600538\n",
      "Epoch :  5 Step :  148 loss :  126.790607787\n",
      "Epoch :  5 Step :  149 loss :  167.562778171\n",
      "Epoch :  5 Step :  150 loss :  135.138743027\n",
      "Epoch :  5 Step :  151 loss :  144.563985143\n",
      "Epoch :  5 Step :  152 loss :  167.16698354\n",
      "Epoch :  5 Step :  153 loss :  121.62396036\n",
      "Epoch :  5 Step :  154 loss :  144.440052621\n",
      "Epoch :  5 Step :  155 loss :  143.147088187\n",
      "Epoch :  5 Step :  156 loss :  146.240784607\n",
      "Epoch :  5 Step :  157 loss :  146.219958084\n",
      "Epoch :  5 Step :  158 loss :  149.980290362\n",
      "Epoch :  5 Step :  159 loss :  121.646295011\n",
      "Epoch :  5 Step :  160 loss :  139.04208321\n",
      "Epoch :  5 Step :  161 loss :  117.362266276\n",
      "Epoch :  5 Step :  162 loss :  134.984510627\n",
      "Epoch :  5 Step :  163 loss :  131.304086107\n",
      "Epoch :  5 Step :  164 loss :  109.138076902\n",
      "Epoch :  5 Step :  165 loss :  150.06191165\n",
      "Epoch :  5 Step :  166 loss :  119.996271594\n",
      "Epoch :  5 Step :  167 loss :  134.754904471\n",
      "Epoch :  5 Step :  168 loss :  137.918089466\n",
      "Epoch :  5 Step :  169 loss :  128.517508814\n",
      "Epoch :  5 Step :  170 loss :  137.034673817\n",
      "Epoch :  5 Step :  171 loss :  137.08230754\n",
      "Epoch :  5 Step :  172 loss :  122.328556089\n",
      "Epoch :  5 Step :  173 loss :  125.880433038\n",
      "Epoch :  5 Step :  174 loss :  122.476314224\n",
      "Epoch :  5 Step :  175 loss :  145.28978671\n",
      "Epoch :  5 Step :  176 loss :  140.536847826\n",
      "Epoch :  5 Step :  177 loss :  133.508915825\n",
      "Epoch :  5 Step :  178 loss :  125.79019762\n",
      "Epoch :  5 Step :  179 loss :  176.899777947\n",
      "Epoch :  5 Step :  180 loss :  144.289218428\n",
      "Epoch :  5 Step :  181 loss :  112.004613322\n",
      "Epoch :  5 Step :  182 loss :  140.420247835\n",
      "Epoch :  5 Step :  183 loss :  137.324840063\n",
      "Epoch :  5 Step :  184 loss :  133.160683075\n",
      "Epoch :  5 Step :  185 loss :  126.280257698\n",
      "Epoch :  5 Step :  186 loss :  123.076869654\n",
      "Epoch :  5 Step :  187 loss :  142.888618139\n",
      "Epoch :  5 Step :  188 loss :  167.204244854\n",
      "Epoch :  5 Step :  189 loss :  139.840094224\n",
      "Epoch :  5 Step :  190 loss :  137.738917956\n",
      "Epoch :  5 Step :  191 loss :  98.0276917474\n",
      "Epoch :  5 Step :  192 loss :  94.0551592004\n",
      "Epoch :  5 Step :  193 loss :  143.370588052\n",
      "Epoch :  5 Step :  194 loss :  134.382865229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  5 Step :  195 loss :  133.010175508\n",
      "Epoch :  5 Step :  196 loss :  106.744769555\n",
      "Epoch :  5 Step :  197 loss :  133.957547847\n",
      "Epoch :  5 Step :  198 loss :  133.942292189\n",
      "Epoch :  5 Step :  199 loss :  153.138851771\n",
      "Epoch :  5 Step :  200 loss :  157.121099883\n",
      "Epoch :  5 Step :  201 loss :  125.486811893\n",
      "Epoch :  5 Step :  202 loss :  135.567223365\n",
      "Epoch :  5 Step :  203 loss :  125.187961597\n",
      "Epoch :  5 Step :  204 loss :  146.952393681\n",
      "Epoch :  5 Step :  205 loss :  159.062675321\n",
      "Epoch :  5 Step :  206 loss :  149.529628514\n",
      "Epoch :  5 Step :  207 loss :  130.850403472\n",
      "Epoch :  5 Step :  208 loss :  109.38565461\n",
      "Epoch :  5 Step :  209 loss :  135.482719778\n",
      "Epoch :  5 Step :  210 loss :  150.527539121\n",
      "Epoch :  5 Step :  211 loss :  149.087647919\n",
      "Epoch :  5 Step :  212 loss :  123.710091513\n",
      "Epoch :  5 Step :  213 loss :  169.118581739\n",
      "Epoch :  5 Step :  214 loss :  164.834337732\n",
      "Epoch :  5 Step :  215 loss :  141.768236961\n",
      "Epoch :  5 Step :  216 loss :  156.826805095\n",
      "Epoch :  5 Step :  217 loss :  130.022729099\n",
      "Epoch :  5 Step :  218 loss :  159.083564044\n",
      "Epoch :  5 Step :  219 loss :  163.309073504\n",
      "Epoch :  6 Step :  0 loss :  120.650759004\n",
      "Epoch :  6 Step :  1 loss :  144.854449906\n",
      "Epoch :  6 Step :  2 loss :  141.701777733\n",
      "Epoch :  6 Step :  3 loss :  128.16121993\n",
      "Epoch :  6 Step :  4 loss :  160.97089\n",
      "Epoch :  6 Step :  5 loss :  137.214673473\n",
      "Epoch :  6 Step :  6 loss :  103.146371969\n",
      "Epoch :  6 Step :  7 loss :  117.21622201\n",
      "Epoch :  6 Step :  8 loss :  135.720165369\n",
      "Epoch :  6 Step :  9 loss :  132.983999674\n",
      "Epoch :  6 Step :  10 loss :  128.946884462\n",
      "Epoch :  6 Step :  11 loss :  165.313775841\n",
      "Epoch :  6 Step :  12 loss :  114.792625087\n",
      "Epoch :  6 Step :  13 loss :  132.910928762\n",
      "Epoch :  6 Step :  14 loss :  143.963993142\n",
      "Epoch :  6 Step :  15 loss :  161.289977733\n",
      "Epoch :  6 Step :  16 loss :  109.625904521\n",
      "Epoch :  6 Step :  17 loss :  130.915671195\n",
      "Epoch :  6 Step :  18 loss :  122.657121211\n",
      "Epoch :  6 Step :  19 loss :  109.278958515\n",
      "Epoch :  6 Step :  20 loss :  172.585821334\n",
      "Epoch :  6 Step :  21 loss :  174.16999312\n",
      "Epoch :  6 Step :  22 loss :  146.437258298\n",
      "Epoch :  6 Step :  23 loss :  108.631370686\n",
      "Epoch :  6 Step :  24 loss :  126.88898531\n",
      "Epoch :  6 Step :  25 loss :  144.982007887\n",
      "Epoch :  6 Step :  26 loss :  117.45931252\n",
      "Epoch :  6 Step :  27 loss :  118.147762881\n",
      "Epoch :  6 Step :  28 loss :  126.180590475\n",
      "Epoch :  6 Step :  29 loss :  125.800127985\n",
      "Epoch :  6 Step :  30 loss :  146.625027262\n",
      "Epoch :  6 Step :  31 loss :  136.364708658\n",
      "Epoch :  6 Step :  32 loss :  132.497185348\n",
      "Epoch :  6 Step :  33 loss :  126.5054494\n",
      "Epoch :  6 Step :  34 loss :  127.498456512\n",
      "Epoch :  6 Step :  35 loss :  162.087437528\n",
      "Epoch :  6 Step :  36 loss :  121.413823865\n",
      "Epoch :  6 Step :  37 loss :  137.23005934\n",
      "Epoch :  6 Step :  38 loss :  141.711613666\n",
      "Epoch :  6 Step :  39 loss :  154.138251404\n",
      "Epoch :  6 Step :  40 loss :  121.665046902\n",
      "Epoch :  6 Step :  41 loss :  138.632339442\n",
      "Epoch :  6 Step :  42 loss :  125.329034697\n",
      "Epoch :  6 Step :  43 loss :  135.775353767\n",
      "Epoch :  6 Step :  44 loss :  131.684220584\n",
      "Epoch :  6 Step :  45 loss :  138.782288317\n",
      "Epoch :  6 Step :  46 loss :  154.38184798\n",
      "Epoch :  6 Step :  47 loss :  171.13730076\n",
      "Epoch :  6 Step :  48 loss :  143.876213572\n",
      "Epoch :  6 Step :  49 loss :  135.927617216\n",
      "Epoch :  6 Step :  50 loss :  139.013672471\n",
      "Epoch :  6 Step :  51 loss :  98.2334583811\n",
      "Epoch :  6 Step :  52 loss :  120.647775393\n",
      "Epoch :  6 Step :  53 loss :  126.862357433\n",
      "Epoch :  6 Step :  54 loss :  150.205118603\n",
      "Epoch :  6 Step :  55 loss :  142.524961573\n",
      "Epoch :  6 Step :  56 loss :  156.482306312\n",
      "Epoch :  6 Step :  57 loss :  143.997060808\n",
      "Epoch :  6 Step :  58 loss :  119.220819532\n",
      "Epoch :  6 Step :  59 loss :  141.280030035\n",
      "Epoch :  6 Step :  60 loss :  124.986562801\n",
      "Epoch :  6 Step :  61 loss :  137.555433577\n",
      "Epoch :  6 Step :  62 loss :  144.673158158\n",
      "Epoch :  6 Step :  63 loss :  124.202735249\n",
      "Epoch :  6 Step :  64 loss :  146.067109127\n",
      "Epoch :  6 Step :  65 loss :  120.696625612\n",
      "Epoch :  6 Step :  66 loss :  153.923643607\n",
      "Epoch :  6 Step :  67 loss :  139.612909943\n",
      "Epoch :  6 Step :  68 loss :  113.798071027\n",
      "Epoch :  6 Step :  69 loss :  169.514782385\n",
      "Epoch :  6 Step :  70 loss :  163.913364239\n",
      "Epoch :  6 Step :  71 loss :  142.595437414\n",
      "Epoch :  6 Step :  72 loss :  161.597943167\n",
      "Epoch :  6 Step :  73 loss :  143.699444745\n",
      "Epoch :  6 Step :  74 loss :  110.688011074\n",
      "Epoch :  6 Step :  75 loss :  147.48657676\n",
      "Epoch :  6 Step :  76 loss :  197.688814239\n",
      "Epoch :  6 Step :  77 loss :  134.936581448\n",
      "Epoch :  6 Step :  78 loss :  98.9677893173\n",
      "Epoch :  6 Step :  79 loss :  152.411478326\n",
      "Epoch :  6 Step :  80 loss :  140.144070688\n",
      "Epoch :  6 Step :  81 loss :  138.371844104\n",
      "Epoch :  6 Step :  82 loss :  146.000386418\n",
      "Epoch :  6 Step :  83 loss :  151.27298445\n",
      "Epoch :  6 Step :  84 loss :  117.486891986\n",
      "Epoch :  6 Step :  85 loss :  167.124840959\n",
      "Epoch :  6 Step :  86 loss :  99.3774412215\n",
      "Epoch :  6 Step :  87 loss :  124.412435665\n",
      "Epoch :  6 Step :  88 loss :  154.687133785\n",
      "Epoch :  6 Step :  89 loss :  101.705467299\n",
      "Epoch :  6 Step :  90 loss :  124.432573597\n",
      "Epoch :  6 Step :  91 loss :  151.691392805\n",
      "Epoch :  6 Step :  92 loss :  128.421124028\n",
      "Epoch :  6 Step :  93 loss :  131.87633046\n",
      "Epoch :  6 Step :  94 loss :  118.84146599\n",
      "Epoch :  6 Step :  95 loss :  114.042832844\n",
      "Epoch :  6 Step :  96 loss :  121.677447552\n",
      "Epoch :  6 Step :  97 loss :  129.084729822\n",
      "Epoch :  6 Step :  98 loss :  135.174065347\n",
      "Epoch :  6 Step :  99 loss :  147.905479983\n",
      "Epoch :  6 Step :  100 loss :  104.118062012\n",
      "Epoch :  6 Step :  101 loss :  116.897727592\n",
      "Epoch :  6 Step :  102 loss :  143.421832906\n",
      "Epoch :  6 Step :  103 loss :  150.381048658\n",
      "Epoch :  6 Step :  104 loss :  147.559819976\n",
      "Epoch :  6 Step :  105 loss :  133.004382782\n",
      "Epoch :  6 Step :  106 loss :  102.141744148\n",
      "Epoch :  6 Step :  107 loss :  108.905293345\n",
      "Epoch :  6 Step :  108 loss :  131.310815908\n",
      "Epoch :  6 Step :  109 loss :  130.556438371\n",
      "Epoch :  6 Step :  110 loss :  144.828653599\n",
      "Epoch :  6 Step :  111 loss :  97.7401833633\n",
      "Epoch :  6 Step :  112 loss :  150.751559831\n",
      "Epoch :  6 Step :  113 loss :  140.000746133\n",
      "Epoch :  6 Step :  114 loss :  108.769798017\n",
      "Epoch :  6 Step :  115 loss :  130.680550906\n",
      "Epoch :  6 Step :  116 loss :  140.301237456\n",
      "Epoch :  6 Step :  117 loss :  152.422220441\n",
      "Epoch :  6 Step :  118 loss :  156.25917327\n",
      "Epoch :  6 Step :  119 loss :  115.819704589\n",
      "Epoch :  6 Step :  120 loss :  133.461021538\n",
      "Epoch :  6 Step :  121 loss :  114.944277718\n",
      "Epoch :  6 Step :  122 loss :  142.670475026\n",
      "Epoch :  6 Step :  123 loss :  135.86337695\n",
      "Epoch :  6 Step :  124 loss :  116.685896472\n",
      "Epoch :  6 Step :  125 loss :  129.986638762\n",
      "Epoch :  6 Step :  126 loss :  133.550175827\n",
      "Epoch :  6 Step :  127 loss :  103.453579229\n",
      "Epoch :  6 Step :  128 loss :  127.419680511\n",
      "Epoch :  6 Step :  129 loss :  153.04100178\n",
      "Epoch :  6 Step :  130 loss :  96.5875998288\n",
      "Epoch :  6 Step :  131 loss :  169.268158876\n",
      "Epoch :  6 Step :  132 loss :  110.075929228\n",
      "Epoch :  6 Step :  133 loss :  158.09715558\n",
      "Epoch :  6 Step :  134 loss :  155.390677094\n",
      "Epoch :  6 Step :  135 loss :  164.712431091\n",
      "Epoch :  6 Step :  136 loss :  140.745994234\n",
      "Epoch :  6 Step :  137 loss :  128.264909939\n",
      "Epoch :  6 Step :  138 loss :  130.18766883\n",
      "Epoch :  6 Step :  139 loss :  147.266729244\n",
      "Epoch :  6 Step :  140 loss :  110.756402135\n",
      "Epoch :  6 Step :  141 loss :  138.626392864\n",
      "Epoch :  6 Step :  142 loss :  140.966009353\n",
      "Epoch :  6 Step :  143 loss :  131.325179395\n",
      "Epoch :  6 Step :  144 loss :  172.332216662\n",
      "Epoch :  6 Step :  145 loss :  148.682044757\n",
      "Epoch :  6 Step :  146 loss :  127.005724714\n",
      "Epoch :  6 Step :  147 loss :  153.758109185\n",
      "Epoch :  6 Step :  148 loss :  120.258429908\n",
      "Epoch :  6 Step :  149 loss :  161.257638406\n",
      "Epoch :  6 Step :  150 loss :  131.777354119\n",
      "Epoch :  6 Step :  151 loss :  136.429747869\n",
      "Epoch :  6 Step :  152 loss :  162.238577691\n",
      "Epoch :  6 Step :  153 loss :  117.241762958\n",
      "Epoch :  6 Step :  154 loss :  140.517479196\n",
      "Epoch :  6 Step :  155 loss :  137.500106345\n",
      "Epoch :  6 Step :  156 loss :  138.622836887\n",
      "Epoch :  6 Step :  157 loss :  141.982400664\n",
      "Epoch :  6 Step :  158 loss :  144.109025521\n",
      "Epoch :  6 Step :  159 loss :  113.610664484\n",
      "Epoch :  6 Step :  160 loss :  132.799770175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  6 Step :  161 loss :  113.256779531\n",
      "Epoch :  6 Step :  162 loss :  129.335289977\n",
      "Epoch :  6 Step :  163 loss :  127.014927934\n",
      "Epoch :  6 Step :  164 loss :  105.400070833\n",
      "Epoch :  6 Step :  165 loss :  142.590702922\n",
      "Epoch :  6 Step :  166 loss :  114.280902923\n",
      "Epoch :  6 Step :  167 loss :  132.171505463\n",
      "Epoch :  6 Step :  168 loss :  131.902855247\n",
      "Epoch :  6 Step :  169 loss :  122.516719871\n",
      "Epoch :  6 Step :  170 loss :  132.699906204\n",
      "Epoch :  6 Step :  171 loss :  130.53274551\n",
      "Epoch :  6 Step :  172 loss :  118.158307132\n",
      "Epoch :  6 Step :  173 loss :  119.95428011\n",
      "Epoch :  6 Step :  174 loss :  118.063388584\n",
      "Epoch :  6 Step :  175 loss :  141.567513048\n",
      "Epoch :  6 Step :  176 loss :  136.864138291\n",
      "Epoch :  6 Step :  177 loss :  128.807918896\n",
      "Epoch :  6 Step :  178 loss :  119.839662762\n",
      "Epoch :  6 Step :  179 loss :  174.077831107\n",
      "Epoch :  6 Step :  180 loss :  139.849719583\n",
      "Epoch :  6 Step :  181 loss :  107.023810906\n",
      "Epoch :  6 Step :  182 loss :  136.33289011\n",
      "Epoch :  6 Step :  183 loss :  130.53333675\n",
      "Epoch :  6 Step :  184 loss :  127.489588351\n",
      "Epoch :  6 Step :  185 loss :  121.361759183\n",
      "Epoch :  6 Step :  186 loss :  120.138218718\n",
      "Epoch :  6 Step :  187 loss :  136.889517262\n",
      "Epoch :  6 Step :  188 loss :  159.387830103\n",
      "Epoch :  6 Step :  189 loss :  134.741185044\n",
      "Epoch :  6 Step :  190 loss :  130.538476588\n",
      "Epoch :  6 Step :  191 loss :  94.1991540833\n",
      "Epoch :  6 Step :  192 loss :  88.2929015438\n",
      "Epoch :  6 Step :  193 loss :  139.700624552\n",
      "Epoch :  6 Step :  194 loss :  130.234050455\n",
      "Epoch :  6 Step :  195 loss :  127.674543824\n",
      "Epoch :  6 Step :  196 loss :  103.638762013\n",
      "Epoch :  6 Step :  197 loss :  128.551955586\n",
      "Epoch :  6 Step :  198 loss :  128.263213998\n",
      "Epoch :  6 Step :  199 loss :  148.231302946\n",
      "Epoch :  6 Step :  200 loss :  152.286343275\n",
      "Epoch :  6 Step :  201 loss :  120.172344343\n",
      "Epoch :  6 Step :  202 loss :  129.791360488\n",
      "Epoch :  6 Step :  203 loss :  122.059550192\n",
      "Epoch :  6 Step :  204 loss :  139.611638769\n",
      "Epoch :  6 Step :  205 loss :  152.970651767\n",
      "Epoch :  6 Step :  206 loss :  143.113410762\n",
      "Epoch :  6 Step :  207 loss :  125.538017483\n",
      "Epoch :  6 Step :  208 loss :  103.780984847\n",
      "Epoch :  6 Step :  209 loss :  130.956379264\n",
      "Epoch :  6 Step :  210 loss :  142.274221895\n",
      "Epoch :  6 Step :  211 loss :  144.459622798\n",
      "Epoch :  6 Step :  212 loss :  117.743945264\n",
      "Epoch :  6 Step :  213 loss :  161.982750913\n",
      "Epoch :  6 Step :  214 loss :  158.814930465\n",
      "Epoch :  6 Step :  215 loss :  138.168891841\n",
      "Epoch :  6 Step :  216 loss :  151.224679842\n",
      "Epoch :  6 Step :  217 loss :  126.034396145\n",
      "Epoch :  6 Step :  218 loss :  153.642453586\n",
      "Epoch :  6 Step :  219 loss :  158.752054185\n",
      "Epoch :  7 Step :  0 loss :  115.935773128\n",
      "Epoch :  7 Step :  1 loss :  137.322344408\n",
      "Epoch :  7 Step :  2 loss :  137.042579409\n",
      "Epoch :  7 Step :  3 loss :  118.936686592\n",
      "Epoch :  7 Step :  4 loss :  156.057229541\n",
      "Epoch :  7 Step :  5 loss :  130.524496814\n",
      "Epoch :  7 Step :  6 loss :  98.6521446383\n",
      "Epoch :  7 Step :  7 loss :  111.577418976\n",
      "Epoch :  7 Step :  8 loss :  128.547734005\n",
      "Epoch :  7 Step :  9 loss :  128.567971745\n",
      "Epoch :  7 Step :  10 loss :  122.811424116\n",
      "Epoch :  7 Step :  11 loss :  156.36528937\n",
      "Epoch :  7 Step :  12 loss :  107.052369883\n",
      "Epoch :  7 Step :  13 loss :  126.631712835\n",
      "Epoch :  7 Step :  14 loss :  137.652605934\n",
      "Epoch :  7 Step :  15 loss :  153.918023932\n",
      "Epoch :  7 Step :  16 loss :  103.684750791\n",
      "Epoch :  7 Step :  17 loss :  125.59706267\n",
      "Epoch :  7 Step :  18 loss :  115.703552991\n",
      "Epoch :  7 Step :  19 loss :  105.907608461\n",
      "Epoch :  7 Step :  20 loss :  166.46690598\n",
      "Epoch :  7 Step :  21 loss :  166.222517027\n",
      "Epoch :  7 Step :  22 loss :  136.601238022\n",
      "Epoch :  7 Step :  23 loss :  103.749590502\n",
      "Epoch :  7 Step :  24 loss :  121.567540979\n",
      "Epoch :  7 Step :  25 loss :  137.860410012\n",
      "Epoch :  7 Step :  26 loss :  110.164603447\n",
      "Epoch :  7 Step :  27 loss :  111.971900178\n",
      "Epoch :  7 Step :  28 loss :  120.934205782\n",
      "Epoch :  7 Step :  29 loss :  118.15999544\n",
      "Epoch :  7 Step :  30 loss :  139.090372224\n",
      "Epoch :  7 Step :  31 loss :  128.427140188\n",
      "Epoch :  7 Step :  32 loss :  125.307799547\n",
      "Epoch :  7 Step :  33 loss :  122.365250292\n",
      "Epoch :  7 Step :  34 loss :  121.424731888\n",
      "Epoch :  7 Step :  35 loss :  156.60928131\n",
      "Epoch :  7 Step :  36 loss :  116.066914028\n",
      "Epoch :  7 Step :  37 loss :  131.565580494\n",
      "Epoch :  7 Step :  38 loss :  135.725425077\n",
      "Epoch :  7 Step :  39 loss :  148.229506239\n",
      "Epoch :  7 Step :  40 loss :  118.524552272\n",
      "Epoch :  7 Step :  41 loss :  132.699257761\n",
      "Epoch :  7 Step :  42 loss :  119.742878052\n",
      "Epoch :  7 Step :  43 loss :  129.735738257\n",
      "Epoch :  7 Step :  44 loss :  126.375409943\n",
      "Epoch :  7 Step :  45 loss :  134.256546787\n",
      "Epoch :  7 Step :  46 loss :  148.975841239\n",
      "Epoch :  7 Step :  47 loss :  163.800378149\n",
      "Epoch :  7 Step :  48 loss :  138.151246012\n",
      "Epoch :  7 Step :  49 loss :  130.655283247\n",
      "Epoch :  7 Step :  50 loss :  134.459018028\n",
      "Epoch :  7 Step :  51 loss :  92.899519757\n",
      "Epoch :  7 Step :  52 loss :  114.314047734\n",
      "Epoch :  7 Step :  53 loss :  118.147449212\n",
      "Epoch :  7 Step :  54 loss :  145.276609511\n",
      "Epoch :  7 Step :  55 loss :  138.237372373\n",
      "Epoch :  7 Step :  56 loss :  151.735054181\n",
      "Epoch :  7 Step :  57 loss :  138.22033429\n",
      "Epoch :  7 Step :  58 loss :  114.219308956\n",
      "Epoch :  7 Step :  59 loss :  134.651619622\n",
      "Epoch :  7 Step :  60 loss :  119.498521641\n",
      "Epoch :  7 Step :  61 loss :  131.721479651\n",
      "Epoch :  7 Step :  62 loss :  138.57645698\n",
      "Epoch :  7 Step :  63 loss :  115.176340744\n",
      "Epoch :  7 Step :  64 loss :  140.03066048\n",
      "Epoch :  7 Step :  65 loss :  112.855402801\n",
      "Epoch :  7 Step :  66 loss :  148.550945117\n",
      "Epoch :  7 Step :  67 loss :  134.396434207\n",
      "Epoch :  7 Step :  68 loss :  109.164900545\n",
      "Epoch :  7 Step :  69 loss :  163.965302601\n",
      "Epoch :  7 Step :  70 loss :  158.345422745\n",
      "Epoch :  7 Step :  71 loss :  135.603217941\n",
      "Epoch :  7 Step :  72 loss :  153.643950319\n",
      "Epoch :  7 Step :  73 loss :  138.630391752\n",
      "Epoch :  7 Step :  74 loss :  107.566341476\n",
      "Epoch :  7 Step :  75 loss :  140.290828549\n",
      "Epoch :  7 Step :  76 loss :  190.627595646\n",
      "Epoch :  7 Step :  77 loss :  128.521023964\n",
      "Epoch :  7 Step :  78 loss :  94.8666237285\n",
      "Epoch :  7 Step :  79 loss :  146.855367341\n",
      "Epoch :  7 Step :  80 loss :  136.134886413\n",
      "Epoch :  7 Step :  81 loss :  132.408842265\n",
      "Epoch :  7 Step :  82 loss :  140.675100737\n",
      "Epoch :  7 Step :  83 loss :  146.813151319\n",
      "Epoch :  7 Step :  84 loss :  112.11054398\n",
      "Epoch :  7 Step :  85 loss :  162.478267587\n",
      "Epoch :  7 Step :  86 loss :  94.3361086463\n",
      "Epoch :  7 Step :  87 loss :  119.512109638\n",
      "Epoch :  7 Step :  88 loss :  149.258811201\n",
      "Epoch :  7 Step :  89 loss :  95.9936004514\n",
      "Epoch :  7 Step :  90 loss :  119.168027839\n",
      "Epoch :  7 Step :  91 loss :  145.520580551\n",
      "Epoch :  7 Step :  92 loss :  123.651902077\n",
      "Epoch :  7 Step :  93 loss :  124.179520248\n",
      "Epoch :  7 Step :  94 loss :  113.8707884\n",
      "Epoch :  7 Step :  95 loss :  109.407637056\n",
      "Epoch :  7 Step :  96 loss :  116.119183879\n",
      "Epoch :  7 Step :  97 loss :  123.065338611\n",
      "Epoch :  7 Step :  98 loss :  129.912972741\n",
      "Epoch :  7 Step :  99 loss :  140.590434091\n",
      "Epoch :  7 Step :  100 loss :  99.3142315186\n",
      "Epoch :  7 Step :  101 loss :  111.984431421\n",
      "Epoch :  7 Step :  102 loss :  136.980316793\n",
      "Epoch :  7 Step :  103 loss :  142.770248466\n",
      "Epoch :  7 Step :  104 loss :  141.495677567\n",
      "Epoch :  7 Step :  105 loss :  126.250373293\n",
      "Epoch :  7 Step :  106 loss :  97.2806813935\n",
      "Epoch :  7 Step :  107 loss :  106.047678452\n",
      "Epoch :  7 Step :  108 loss :  126.317281973\n",
      "Epoch :  7 Step :  109 loss :  124.839117699\n",
      "Epoch :  7 Step :  110 loss :  138.561839445\n",
      "Epoch :  7 Step :  111 loss :  92.5949310167\n",
      "Epoch :  7 Step :  112 loss :  146.476641208\n",
      "Epoch :  7 Step :  113 loss :  135.9958368\n",
      "Epoch :  7 Step :  114 loss :  104.201005707\n",
      "Epoch :  7 Step :  115 loss :  124.152390708\n",
      "Epoch :  7 Step :  116 loss :  135.582040828\n",
      "Epoch :  7 Step :  117 loss :  146.274350013\n",
      "Epoch :  7 Step :  118 loss :  151.012988159\n",
      "Epoch :  7 Step :  119 loss :  110.839414713\n",
      "Epoch :  7 Step :  120 loss :  127.568304353\n",
      "Epoch :  7 Step :  121 loss :  111.588893577\n",
      "Epoch :  7 Step :  122 loss :  137.743760521\n",
      "Epoch :  7 Step :  123 loss :  130.742852147\n",
      "Epoch :  7 Step :  124 loss :  111.597807204\n",
      "Epoch :  7 Step :  125 loss :  125.822766147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  7 Step :  126 loss :  127.815852203\n",
      "Epoch :  7 Step :  127 loss :  99.5851892311\n",
      "Epoch :  7 Step :  128 loss :  122.758905324\n",
      "Epoch :  7 Step :  129 loss :  147.930751505\n",
      "Epoch :  7 Step :  130 loss :  90.7098857407\n",
      "Epoch :  7 Step :  131 loss :  164.883344334\n",
      "Epoch :  7 Step :  132 loss :  106.775698128\n",
      "Epoch :  7 Step :  133 loss :  153.46681374\n",
      "Epoch :  7 Step :  134 loss :  150.380784734\n",
      "Epoch :  7 Step :  135 loss :  159.830742349\n",
      "Epoch :  7 Step :  136 loss :  137.429822299\n",
      "Epoch :  7 Step :  137 loss :  124.617516417\n",
      "Epoch :  7 Step :  138 loss :  125.545937303\n",
      "Epoch :  7 Step :  139 loss :  142.887520855\n",
      "Epoch :  7 Step :  140 loss :  105.016006769\n",
      "Epoch :  7 Step :  141 loss :  136.37451717\n",
      "Epoch :  7 Step :  142 loss :  135.832877403\n",
      "Epoch :  7 Step :  143 loss :  126.302885731\n",
      "Epoch :  7 Step :  144 loss :  167.07335737\n",
      "Epoch :  7 Step :  145 loss :  142.616399716\n",
      "Epoch :  7 Step :  146 loss :  123.24804982\n",
      "Epoch :  7 Step :  147 loss :  149.148609229\n",
      "Epoch :  7 Step :  148 loss :  114.900768986\n",
      "Epoch :  7 Step :  149 loss :  156.865759439\n",
      "Epoch :  7 Step :  150 loss :  128.526906236\n",
      "Epoch :  7 Step :  151 loss :  129.735609625\n",
      "Epoch :  7 Step :  152 loss :  156.896553993\n",
      "Epoch :  7 Step :  153 loss :  112.779845969\n",
      "Epoch :  7 Step :  154 loss :  136.489086621\n",
      "Epoch :  7 Step :  155 loss :  133.316671807\n",
      "Epoch :  7 Step :  156 loss :  133.334962229\n",
      "Epoch :  7 Step :  157 loss :  138.020525333\n",
      "Epoch :  7 Step :  158 loss :  138.395531524\n",
      "Epoch :  7 Step :  159 loss :  108.439838015\n",
      "Epoch :  7 Step :  160 loss :  127.656498097\n",
      "Epoch :  7 Step :  161 loss :  109.836692137\n",
      "Epoch :  7 Step :  162 loss :  125.120948579\n",
      "Epoch :  7 Step :  163 loss :  123.783490875\n",
      "Epoch :  7 Step :  164 loss :  102.414593525\n",
      "Epoch :  7 Step :  165 loss :  136.693724568\n",
      "Epoch :  7 Step :  166 loss :  110.315610253\n",
      "Epoch :  7 Step :  167 loss :  129.957017173\n",
      "Epoch :  7 Step :  168 loss :  126.889463267\n",
      "Epoch :  7 Step :  169 loss :  116.882244819\n",
      "Epoch :  7 Step :  170 loss :  128.006611703\n",
      "Epoch :  7 Step :  171 loss :  123.968503056\n",
      "Epoch :  7 Step :  172 loss :  114.069536617\n",
      "Epoch :  7 Step :  173 loss :  115.201681179\n",
      "Epoch :  7 Step :  174 loss :  113.62052533\n",
      "Epoch :  7 Step :  175 loss :  138.038412202\n",
      "Epoch :  7 Step :  176 loss :  132.657969673\n",
      "Epoch :  7 Step :  177 loss :  125.827734192\n",
      "Epoch :  7 Step :  178 loss :  115.555056599\n",
      "Epoch :  7 Step :  179 loss :  170.141640327\n",
      "Epoch :  7 Step :  180 loss :  135.097928146\n",
      "Epoch :  7 Step :  181 loss :  101.369113558\n",
      "Epoch :  7 Step :  182 loss :  133.128747444\n",
      "Epoch :  7 Step :  183 loss :  126.569848546\n",
      "Epoch :  7 Step :  184 loss :  122.312455675\n",
      "Epoch :  7 Step :  185 loss :  117.24485151\n",
      "Epoch :  7 Step :  186 loss :  116.732661372\n",
      "Epoch :  7 Step :  187 loss :  132.302014364\n",
      "Epoch :  7 Step :  188 loss :  153.00537717\n",
      "Epoch :  7 Step :  189 loss :  130.584477579\n",
      "Epoch :  7 Step :  190 loss :  125.449923077\n",
      "Epoch :  7 Step :  191 loss :  90.8234898624\n",
      "Epoch :  7 Step :  192 loss :  83.2181285015\n",
      "Epoch :  7 Step :  193 loss :  135.304943079\n",
      "Epoch :  7 Step :  194 loss :  126.304782157\n",
      "Epoch :  7 Step :  195 loss :  121.701727803\n",
      "Epoch :  7 Step :  196 loss :  101.436049559\n",
      "Epoch :  7 Step :  197 loss :  123.230397666\n",
      "Epoch :  7 Step :  198 loss :  123.307186337\n",
      "Epoch :  7 Step :  199 loss :  143.724294618\n",
      "Epoch :  7 Step :  200 loss :  147.501989243\n",
      "Epoch :  7 Step :  201 loss :  115.514183267\n",
      "Epoch :  7 Step :  202 loss :  123.81113476\n",
      "Epoch :  7 Step :  203 loss :  118.798068741\n",
      "Epoch :  7 Step :  204 loss :  133.567429575\n",
      "Epoch :  7 Step :  205 loss :  147.261069597\n",
      "Epoch :  7 Step :  206 loss :  137.157746827\n",
      "Epoch :  7 Step :  207 loss :  121.102058832\n",
      "Epoch :  7 Step :  208 loss :  99.6306446397\n",
      "Epoch :  7 Step :  209 loss :  126.523858712\n",
      "Epoch :  7 Step :  210 loss :  135.668998803\n",
      "Epoch :  7 Step :  211 loss :  139.40381555\n",
      "Epoch :  7 Step :  212 loss :  112.478473141\n",
      "Epoch :  7 Step :  213 loss :  156.13377639\n",
      "Epoch :  7 Step :  214 loss :  153.10381908\n",
      "Epoch :  7 Step :  215 loss :  133.054973454\n",
      "Epoch :  7 Step :  216 loss :  147.442828771\n",
      "Epoch :  7 Step :  217 loss :  122.98590073\n",
      "Epoch :  7 Step :  218 loss :  148.586754837\n",
      "Epoch :  7 Step :  219 loss :  156.001385496\n",
      "Epoch :  8 Step :  0 loss :  111.576898319\n",
      "Epoch :  8 Step :  1 loss :  131.141827662\n",
      "Epoch :  8 Step :  2 loss :  132.674153509\n",
      "Epoch :  8 Step :  3 loss :  112.838148931\n",
      "Epoch :  8 Step :  4 loss :  151.809311845\n",
      "Epoch :  8 Step :  5 loss :  124.79038118\n",
      "Epoch :  8 Step :  6 loss :  95.0101927219\n",
      "Epoch :  8 Step :  7 loss :  106.164978654\n",
      "Epoch :  8 Step :  8 loss :  124.279236679\n",
      "Epoch :  8 Step :  9 loss :  125.058329798\n",
      "Epoch :  8 Step :  10 loss :  117.428160578\n",
      "Epoch :  8 Step :  11 loss :  149.803524128\n",
      "Epoch :  8 Step :  12 loss :  101.420761409\n",
      "Epoch :  8 Step :  13 loss :  121.275460667\n",
      "Epoch :  8 Step :  14 loss :  133.098120483\n",
      "Epoch :  8 Step :  15 loss :  148.117515412\n",
      "Epoch :  8 Step :  16 loss :  99.1989411854\n",
      "Epoch :  8 Step :  17 loss :  120.650721945\n",
      "Epoch :  8 Step :  18 loss :  111.004119157\n",
      "Epoch :  8 Step :  19 loss :  102.614907501\n",
      "Epoch :  8 Step :  20 loss :  160.333725125\n",
      "Epoch :  8 Step :  21 loss :  159.738505241\n",
      "Epoch :  8 Step :  22 loss :  129.82938193\n",
      "Epoch :  8 Step :  23 loss :  100.022084204\n",
      "Epoch :  8 Step :  24 loss :  118.244440674\n",
      "Epoch :  8 Step :  25 loss :  131.800120026\n",
      "Epoch :  8 Step :  26 loss :  104.194875135\n",
      "Epoch :  8 Step :  27 loss :  107.241760082\n",
      "Epoch :  8 Step :  28 loss :  116.4953944\n",
      "Epoch :  8 Step :  29 loss :  111.895297269\n",
      "Epoch :  8 Step :  30 loss :  134.198070121\n",
      "Epoch :  8 Step :  31 loss :  122.018389817\n",
      "Epoch :  8 Step :  32 loss :  118.123461212\n",
      "Epoch :  8 Step :  33 loss :  119.133449789\n",
      "Epoch :  8 Step :  34 loss :  115.938710511\n",
      "Epoch :  8 Step :  35 loss :  152.357835173\n",
      "Epoch :  8 Step :  36 loss :  111.855596013\n",
      "Epoch :  8 Step :  37 loss :  126.623796733\n",
      "Epoch :  8 Step :  38 loss :  130.634883883\n",
      "Epoch :  8 Step :  39 loss :  142.976742677\n",
      "Epoch :  8 Step :  40 loss :  116.706832707\n",
      "Epoch :  8 Step :  41 loss :  128.236154471\n",
      "Epoch :  8 Step :  42 loss :  115.046803163\n",
      "Epoch :  8 Step :  43 loss :  124.879441233\n",
      "Epoch :  8 Step :  44 loss :  121.085780083\n",
      "Epoch :  8 Step :  45 loss :  130.285667553\n",
      "Epoch :  8 Step :  46 loss :  144.427140638\n",
      "Epoch :  8 Step :  47 loss :  157.767090117\n",
      "Epoch :  8 Step :  48 loss :  133.667518269\n",
      "Epoch :  8 Step :  49 loss :  126.33970655\n",
      "Epoch :  8 Step :  50 loss :  130.638038342\n",
      "Epoch :  8 Step :  51 loss :  88.9966184044\n",
      "Epoch :  8 Step :  52 loss :  109.92514372\n",
      "Epoch :  8 Step :  53 loss :  113.120955293\n",
      "Epoch :  8 Step :  54 loss :  140.776315302\n",
      "Epoch :  8 Step :  55 loss :  135.22321215\n",
      "Epoch :  8 Step :  56 loss :  147.932553132\n",
      "Epoch :  8 Step :  57 loss :  133.103522035\n",
      "Epoch :  8 Step :  58 loss :  109.535466705\n",
      "Epoch :  8 Step :  59 loss :  128.87633072\n",
      "Epoch :  8 Step :  60 loss :  115.734434571\n",
      "Epoch :  8 Step :  61 loss :  126.997462294\n",
      "Epoch :  8 Step :  62 loss :  133.696215461\n",
      "Epoch :  8 Step :  63 loss :  108.604002675\n",
      "Epoch :  8 Step :  64 loss :  135.160604104\n",
      "Epoch :  8 Step :  65 loss :  106.648224859\n",
      "Epoch :  8 Step :  66 loss :  142.919999963\n",
      "Epoch :  8 Step :  67 loss :  129.782186982\n",
      "Epoch :  8 Step :  68 loss :  105.088876733\n",
      "Epoch :  8 Step :  69 loss :  158.168457156\n",
      "Epoch :  8 Step :  70 loss :  153.547792374\n",
      "Epoch :  8 Step :  71 loss :  129.91352967\n",
      "Epoch :  8 Step :  72 loss :  147.166358019\n",
      "Epoch :  8 Step :  73 loss :  133.046943437\n",
      "Epoch :  8 Step :  74 loss :  104.186393481\n",
      "Epoch :  8 Step :  75 loss :  135.045494114\n",
      "Epoch :  8 Step :  76 loss :  183.972514235\n",
      "Epoch :  8 Step :  77 loss :  123.972767029\n",
      "Epoch :  8 Step :  78 loss :  90.8089762973\n",
      "Epoch :  8 Step :  79 loss :  142.445559922\n",
      "Epoch :  8 Step :  80 loss :  132.100867378\n",
      "Epoch :  8 Step :  81 loss :  126.509955536\n",
      "Epoch :  8 Step :  82 loss :  135.522752736\n",
      "Epoch :  8 Step :  83 loss :  143.369271072\n",
      "Epoch :  8 Step :  84 loss :  106.906170492\n",
      "Epoch :  8 Step :  85 loss :  158.192247642\n",
      "Epoch :  8 Step :  86 loss :  90.4698668801\n",
      "Epoch :  8 Step :  87 loss :  113.946580599\n",
      "Epoch :  8 Step :  88 loss :  144.113911853\n",
      "Epoch :  8 Step :  89 loss :  91.5985445681\n",
      "Epoch :  8 Step :  90 loss :  114.852202548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  8 Step :  91 loss :  139.874293672\n",
      "Epoch :  8 Step :  92 loss :  119.635553244\n",
      "Epoch :  8 Step :  93 loss :  118.548157853\n",
      "Epoch :  8 Step :  94 loss :  110.069682784\n",
      "Epoch :  8 Step :  95 loss :  105.81129069\n",
      "Epoch :  8 Step :  96 loss :  111.996840549\n",
      "Epoch :  8 Step :  97 loss :  119.049813299\n",
      "Epoch :  8 Step :  98 loss :  124.977088359\n",
      "Epoch :  8 Step :  99 loss :  133.770395176\n",
      "Epoch :  8 Step :  100 loss :  94.7704740389\n",
      "Epoch :  8 Step :  101 loss :  107.274237515\n",
      "Epoch :  8 Step :  102 loss :  132.061052704\n",
      "Epoch :  8 Step :  103 loss :  135.992368184\n",
      "Epoch :  8 Step :  104 loss :  135.937581903\n",
      "Epoch :  8 Step :  105 loss :  120.423147712\n",
      "Epoch :  8 Step :  106 loss :  92.6428248876\n",
      "Epoch :  8 Step :  107 loss :  102.592280941\n",
      "Epoch :  8 Step :  108 loss :  121.234773786\n",
      "Epoch :  8 Step :  109 loss :  120.238161026\n",
      "Epoch :  8 Step :  110 loss :  133.971713846\n",
      "Epoch :  8 Step :  111 loss :  89.132407511\n",
      "Epoch :  8 Step :  112 loss :  141.517628592\n",
      "Epoch :  8 Step :  113 loss :  132.489501431\n",
      "Epoch :  8 Step :  114 loss :  100.396297234\n",
      "Epoch :  8 Step :  115 loss :  118.398699466\n",
      "Epoch :  8 Step :  116 loss :  131.171736085\n",
      "Epoch :  8 Step :  117 loss :  142.553874146\n",
      "Epoch :  8 Step :  118 loss :  146.264196319\n",
      "Epoch :  8 Step :  119 loss :  105.973909168\n",
      "Epoch :  8 Step :  120 loss :  122.575567293\n",
      "Epoch :  8 Step :  121 loss :  108.55617587\n",
      "Epoch :  8 Step :  122 loss :  133.549461\n",
      "Epoch :  8 Step :  123 loss :  125.925015323\n",
      "Epoch :  8 Step :  124 loss :  108.209645694\n",
      "Epoch :  8 Step :  125 loss :  122.320895859\n",
      "Epoch :  8 Step :  126 loss :  123.018381109\n",
      "Epoch :  8 Step :  127 loss :  96.43198364\n",
      "Epoch :  8 Step :  128 loss :  118.368560472\n",
      "Epoch :  8 Step :  129 loss :  143.309899343\n",
      "Epoch :  8 Step :  130 loss :  85.4953600989\n",
      "Epoch :  8 Step :  131 loss :  160.926058381\n",
      "Epoch :  8 Step :  132 loss :  103.646855261\n",
      "Epoch :  8 Step :  133 loss :  148.583489425\n",
      "Epoch :  8 Step :  134 loss :  146.024605438\n",
      "Epoch :  8 Step :  135 loss :  155.574537643\n",
      "Epoch :  8 Step :  136 loss :  134.339032112\n",
      "Epoch :  8 Step :  137 loss :  121.338993642\n",
      "Epoch :  8 Step :  138 loss :  121.408912681\n",
      "Epoch :  8 Step :  139 loss :  138.531556561\n",
      "Epoch :  8 Step :  140 loss :  101.675511795\n",
      "Epoch :  8 Step :  141 loss :  134.523162023\n",
      "Epoch :  8 Step :  142 loss :  131.452087611\n",
      "Epoch :  8 Step :  143 loss :  121.18703395\n",
      "Epoch :  8 Step :  144 loss :  161.400669465\n",
      "Epoch :  8 Step :  145 loss :  136.535754302\n",
      "Epoch :  8 Step :  146 loss :  119.786032315\n",
      "Epoch :  8 Step :  147 loss :  145.701092889\n",
      "Epoch :  8 Step :  148 loss :  110.620982996\n",
      "Epoch :  8 Step :  149 loss :  152.509362539\n",
      "Epoch :  8 Step :  150 loss :  124.461602921\n",
      "Epoch :  8 Step :  151 loss :  123.345039147\n",
      "Epoch :  8 Step :  152 loss :  151.580084514\n",
      "Epoch :  8 Step :  153 loss :  108.949542371\n",
      "Epoch :  8 Step :  154 loss :  133.3417503\n",
      "Epoch :  8 Step :  155 loss :  127.798495613\n",
      "Epoch :  8 Step :  156 loss :  128.704230074\n",
      "Epoch :  8 Step :  157 loss :  135.379389697\n",
      "Epoch :  8 Step :  158 loss :  133.660444059\n",
      "Epoch :  8 Step :  159 loss :  103.667821033\n",
      "Epoch :  8 Step :  160 loss :  124.211116862\n",
      "Epoch :  8 Step :  161 loss :  106.221623181\n",
      "Epoch :  8 Step :  162 loss :  121.496140391\n",
      "Epoch :  8 Step :  163 loss :  120.691835157\n",
      "Epoch :  8 Step :  164 loss :  99.1280418676\n",
      "Epoch :  8 Step :  165 loss :  131.721751712\n",
      "Epoch :  8 Step :  166 loss :  106.944771867\n",
      "Epoch :  8 Step :  167 loss :  126.104729217\n",
      "Epoch :  8 Step :  168 loss :  123.342971439\n",
      "Epoch :  8 Step :  169 loss :  112.073886282\n",
      "Epoch :  8 Step :  170 loss :  123.831714063\n",
      "Epoch :  8 Step :  171 loss :  119.405847331\n",
      "Epoch :  8 Step :  172 loss :  110.793306324\n",
      "Epoch :  8 Step :  173 loss :  111.986766034\n",
      "Epoch :  8 Step :  174 loss :  110.617025076\n",
      "Epoch :  8 Step :  175 loss :  135.530373613\n",
      "Epoch :  8 Step :  176 loss :  128.064444078\n",
      "Epoch :  8 Step :  177 loss :  122.959623197\n",
      "Epoch :  8 Step :  178 loss :  111.95176421\n",
      "Epoch :  8 Step :  179 loss :  166.824367918\n",
      "Epoch :  8 Step :  180 loss :  130.07051609\n",
      "Epoch :  8 Step :  181 loss :  96.4998560918\n",
      "Epoch :  8 Step :  182 loss :  130.138881994\n",
      "Epoch :  8 Step :  183 loss :  123.106936526\n",
      "Epoch :  8 Step :  184 loss :  117.736717477\n",
      "Epoch :  8 Step :  185 loss :  113.556942215\n",
      "Epoch :  8 Step :  186 loss :  113.429311559\n",
      "Epoch :  8 Step :  187 loss :  128.483696251\n",
      "Epoch :  8 Step :  188 loss :  148.01539061\n",
      "Epoch :  8 Step :  189 loss :  127.026498988\n",
      "Epoch :  8 Step :  190 loss :  120.787726295\n",
      "Epoch :  8 Step :  191 loss :  86.9269977379\n",
      "Epoch :  8 Step :  192 loss :  78.8586753874\n",
      "Epoch :  8 Step :  193 loss :  131.368802606\n",
      "Epoch :  8 Step :  194 loss :  122.372760485\n",
      "Epoch :  8 Step :  195 loss :  116.329695087\n",
      "Epoch :  8 Step :  196 loss :  98.2024817014\n",
      "Epoch :  8 Step :  197 loss :  118.303998422\n",
      "Epoch :  8 Step :  198 loss :  119.572729688\n",
      "Epoch :  8 Step :  199 loss :  139.090787753\n",
      "Epoch :  8 Step :  200 loss :  143.465006805\n",
      "Epoch :  8 Step :  201 loss :  111.96703448\n",
      "Epoch :  8 Step :  202 loss :  118.894251846\n",
      "Epoch :  8 Step :  203 loss :  115.15240461\n",
      "Epoch :  8 Step :  204 loss :  128.595935279\n",
      "Epoch :  8 Step :  205 loss :  141.832335813\n",
      "Epoch :  8 Step :  206 loss :  131.579088649\n",
      "Epoch :  8 Step :  207 loss :  116.63931744\n",
      "Epoch :  8 Step :  208 loss :  96.0296241398\n",
      "Epoch :  8 Step :  209 loss :  122.372771684\n",
      "Epoch :  8 Step :  210 loss :  129.560794327\n",
      "Epoch :  8 Step :  211 loss :  134.598701827\n",
      "Epoch :  8 Step :  212 loss :  107.008538312\n",
      "Epoch :  8 Step :  213 loss :  150.528485819\n",
      "Epoch :  8 Step :  214 loss :  148.065422792\n",
      "Epoch :  8 Step :  215 loss :  127.396856914\n",
      "Epoch :  8 Step :  216 loss :  143.260529033\n",
      "Epoch :  8 Step :  217 loss :  119.362656407\n",
      "Epoch :  8 Step :  218 loss :  144.064516285\n",
      "Epoch :  8 Step :  219 loss :  153.712342156\n",
      "Epoch :  9 Step :  0 loss :  108.215759013\n",
      "Epoch :  9 Step :  1 loss :  125.349644191\n",
      "Epoch :  9 Step :  2 loss :  128.56978944\n",
      "Epoch :  9 Step :  3 loss :  108.841369683\n",
      "Epoch :  9 Step :  4 loss :  148.437681087\n",
      "Epoch :  9 Step :  5 loss :  120.536032709\n",
      "Epoch :  9 Step :  6 loss :  92.3738597074\n",
      "Epoch :  9 Step :  7 loss :  101.584958395\n",
      "Epoch :  9 Step :  8 loss :  120.523693562\n",
      "Epoch :  9 Step :  9 loss :  122.019400765\n",
      "Epoch :  9 Step :  10 loss :  113.607544777\n",
      "Epoch :  9 Step :  11 loss :  143.839896051\n",
      "Epoch :  9 Step :  12 loss :  95.6368701284\n",
      "Epoch :  9 Step :  13 loss :  117.267736078\n",
      "Epoch :  9 Step :  14 loss :  129.188766473\n",
      "Epoch :  9 Step :  15 loss :  141.757748479\n",
      "Epoch :  9 Step :  16 loss :  95.2996901071\n",
      "Epoch :  9 Step :  17 loss :  116.633467697\n",
      "Epoch :  9 Step :  18 loss :  106.334425528\n",
      "Epoch :  9 Step :  19 loss :  99.4324704155\n",
      "Epoch :  9 Step :  20 loss :  154.20540502\n",
      "Epoch :  9 Step :  21 loss :  154.435266151\n",
      "Epoch :  9 Step :  22 loss :  123.564598803\n",
      "Epoch :  9 Step :  23 loss :  96.8138601302\n",
      "Epoch :  9 Step :  24 loss :  114.416515797\n",
      "Epoch :  9 Step :  25 loss :  126.74812176\n",
      "Epoch :  9 Step :  26 loss :  99.0070288541\n",
      "Epoch :  9 Step :  27 loss :  103.212681407\n",
      "Epoch :  9 Step :  28 loss :  112.38618513\n",
      "Epoch :  9 Step :  29 loss :  106.015698774\n",
      "Epoch :  9 Step :  30 loss :  129.496283199\n",
      "Epoch :  9 Step :  31 loss :  116.159136383\n",
      "Epoch :  9 Step :  32 loss :  112.329037428\n",
      "Epoch :  9 Step :  33 loss :  116.226170134\n",
      "Epoch :  9 Step :  34 loss :  112.034101617\n",
      "Epoch :  9 Step :  35 loss :  148.164314536\n",
      "Epoch :  9 Step :  36 loss :  108.097634968\n",
      "Epoch :  9 Step :  37 loss :  121.616792252\n",
      "Epoch :  9 Step :  38 loss :  126.396367363\n",
      "Epoch :  9 Step :  39 loss :  138.05626939\n",
      "Epoch :  9 Step :  40 loss :  114.547542624\n",
      "Epoch :  9 Step :  41 loss :  124.414496231\n",
      "Epoch :  9 Step :  42 loss :  110.603545827\n",
      "Epoch :  9 Step :  43 loss :  121.113897549\n",
      "Epoch :  9 Step :  44 loss :  116.051249307\n",
      "Epoch :  9 Step :  45 loss :  126.323987589\n",
      "Epoch :  9 Step :  46 loss :  140.16334336\n",
      "Epoch :  9 Step :  47 loss :  152.854791269\n",
      "Epoch :  9 Step :  48 loss :  129.715226249\n",
      "Epoch :  9 Step :  49 loss :  121.971807903\n",
      "Epoch :  9 Step :  50 loss :  127.337355836\n",
      "Epoch :  9 Step :  51 loss :  85.8997651768\n",
      "Epoch :  9 Step :  52 loss :  105.78962601\n",
      "Epoch :  9 Step :  53 loss :  107.894112218\n",
      "Epoch :  9 Step :  54 loss :  136.819686411\n",
      "Epoch :  9 Step :  55 loss :  132.621802033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  9 Step :  56 loss :  143.947140662\n",
      "Epoch :  9 Step :  57 loss :  128.500245569\n",
      "Epoch :  9 Step :  58 loss :  105.356348891\n",
      "Epoch :  9 Step :  59 loss :  124.235100757\n",
      "Epoch :  9 Step :  60 loss :  111.996683474\n",
      "Epoch :  9 Step :  61 loss :  122.547893933\n",
      "Epoch :  9 Step :  62 loss :  129.265757865\n",
      "Epoch :  9 Step :  63 loss :  103.604953925\n",
      "Epoch :  9 Step :  64 loss :  130.751345321\n",
      "Epoch :  9 Step :  65 loss :  101.87806624\n",
      "Epoch :  9 Step :  66 loss :  138.421129713\n",
      "Epoch :  9 Step :  67 loss :  125.203139898\n",
      "Epoch :  9 Step :  68 loss :  101.42558577\n",
      "Epoch :  9 Step :  69 loss :  153.527933582\n",
      "Epoch :  9 Step :  70 loss :  149.343421264\n",
      "Epoch :  9 Step :  71 loss :  124.143148206\n",
      "Epoch :  9 Step :  72 loss :  141.328855283\n",
      "Epoch :  9 Step :  73 loss :  127.143242115\n",
      "Epoch :  9 Step :  74 loss :  100.708482938\n",
      "Epoch :  9 Step :  75 loss :  130.356964464\n",
      "Epoch :  9 Step :  76 loss :  178.194286481\n",
      "Epoch :  9 Step :  77 loss :  120.426643458\n",
      "Epoch :  9 Step :  78 loss :  87.1239490176\n",
      "Epoch :  9 Step :  79 loss :  138.291916166\n",
      "Epoch :  9 Step :  80 loss :  127.781675748\n",
      "Epoch :  9 Step :  81 loss :  119.434279074\n",
      "Epoch :  9 Step :  82 loss :  131.163789324\n",
      "Epoch :  9 Step :  83 loss :  140.1892428\n",
      "Epoch :  9 Step :  84 loss :  102.306664818\n",
      "Epoch :  9 Step :  85 loss :  154.204407778\n",
      "Epoch :  9 Step :  86 loss :  87.1959660517\n",
      "Epoch :  9 Step :  87 loss :  109.23605603\n",
      "Epoch :  9 Step :  88 loss :  139.758574567\n",
      "Epoch :  9 Step :  89 loss :  88.3106269509\n",
      "Epoch :  9 Step :  90 loss :  111.193469196\n",
      "Epoch :  9 Step :  91 loss :  134.883445541\n",
      "Epoch :  9 Step :  92 loss :  115.96666919\n",
      "Epoch :  9 Step :  93 loss :  114.224839913\n",
      "Epoch :  9 Step :  94 loss :  106.769967923\n",
      "Epoch :  9 Step :  95 loss :  102.815429559\n",
      "Epoch :  9 Step :  96 loss :  109.170918995\n",
      "Epoch :  9 Step :  97 loss :  116.212172859\n",
      "Epoch :  9 Step :  98 loss :  120.203434455\n",
      "Epoch :  9 Step :  99 loss :  127.420907805\n",
      "Epoch :  9 Step :  100 loss :  90.419727559\n",
      "Epoch :  9 Step :  101 loss :  102.907495171\n",
      "Epoch :  9 Step :  102 loss :  127.65213379\n",
      "Epoch :  9 Step :  103 loss :  129.622675418\n",
      "Epoch :  9 Step :  104 loss :  131.105751103\n",
      "Epoch :  9 Step :  105 loss :  115.836272749\n",
      "Epoch :  9 Step :  106 loss :  89.2852243198\n",
      "Epoch :  9 Step :  107 loss :  99.0494272678\n",
      "Epoch :  9 Step :  108 loss :  116.267147327\n",
      "Epoch :  9 Step :  109 loss :  116.146260796\n",
      "Epoch :  9 Step :  110 loss :  129.867947998\n",
      "Epoch :  9 Step :  111 loss :  86.5161296967\n",
      "Epoch :  9 Step :  112 loss :  136.870555042\n",
      "Epoch :  9 Step :  113 loss :  129.106804269\n",
      "Epoch :  9 Step :  114 loss :  96.9589365834\n",
      "Epoch :  9 Step :  115 loss :  113.151065899\n",
      "Epoch :  9 Step :  116 loss :  126.567419195\n",
      "Epoch :  9 Step :  117 loss :  138.639770335\n",
      "Epoch :  9 Step :  118 loss :  141.703135389\n",
      "Epoch :  9 Step :  119 loss :  101.79730635\n",
      "Epoch :  9 Step :  120 loss :  118.339623045\n",
      "Epoch :  9 Step :  121 loss :  105.629340984\n",
      "Epoch :  9 Step :  122 loss :  129.595136377\n",
      "Epoch :  9 Step :  123 loss :  121.757987708\n",
      "Epoch :  9 Step :  124 loss :  105.073979479\n",
      "Epoch :  9 Step :  125 loss :  119.366295304\n",
      "Epoch :  9 Step :  126 loss :  119.292385341\n",
      "Epoch :  9 Step :  127 loss :  92.9776320721\n",
      "Epoch :  9 Step :  128 loss :  113.167932064\n",
      "Epoch :  9 Step :  129 loss :  139.191707619\n",
      "Epoch :  9 Step :  130 loss :  80.9334603723\n",
      "Epoch :  9 Step :  131 loss :  156.866973583\n",
      "Epoch :  9 Step :  132 loss :  100.081261953\n",
      "Epoch :  9 Step :  133 loss :  144.161374405\n",
      "Epoch :  9 Step :  134 loss :  142.138753556\n",
      "Epoch :  9 Step :  135 loss :  151.638354355\n",
      "Epoch :  9 Step :  136 loss :  130.009414801\n",
      "Epoch :  9 Step :  137 loss :  118.009710314\n",
      "Epoch :  9 Step :  138 loss :  117.078940415\n",
      "Epoch :  9 Step :  139 loss :  134.281791762\n",
      "Epoch :  9 Step :  140 loss :  98.4311827653\n",
      "Epoch :  9 Step :  141 loss :  131.922778113\n",
      "Epoch :  9 Step :  142 loss :  127.631677779\n",
      "Epoch :  9 Step :  143 loss :  116.24793691\n",
      "Epoch :  9 Step :  144 loss :  156.092841212\n",
      "Epoch :  9 Step :  145 loss :  131.382509294\n",
      "Epoch :  9 Step :  146 loss :  116.748734673\n",
      "Epoch :  9 Step :  147 loss :  142.565146168\n",
      "Epoch :  9 Step :  148 loss :  106.767671201\n",
      "Epoch :  9 Step :  149 loss :  147.801136589\n",
      "Epoch :  9 Step :  150 loss :  120.547154705\n",
      "Epoch :  9 Step :  151 loss :  118.624331113\n",
      "Epoch :  9 Step :  152 loss :  147.023280514\n",
      "Epoch :  9 Step :  153 loss :  105.913126778\n",
      "Epoch :  9 Step :  154 loss :  130.333323842\n",
      "Epoch :  9 Step :  155 loss :  122.785411396\n",
      "Epoch :  9 Step :  156 loss :  124.332965685\n",
      "Epoch :  9 Step :  157 loss :  132.872175246\n",
      "Epoch :  9 Step :  158 loss :  130.004377715\n",
      "Epoch :  9 Step :  159 loss :  98.134453336\n",
      "Epoch :  9 Step :  160 loss :  121.970620575\n",
      "Epoch :  9 Step :  161 loss :  102.409693777\n",
      "Epoch :  9 Step :  162 loss :  117.974832033\n",
      "Epoch :  9 Step :  163 loss :  117.356987647\n",
      "Epoch :  9 Step :  164 loss :  95.9498790165\n",
      "Epoch :  9 Step :  165 loss :  127.358311238\n",
      "Epoch :  9 Step :  166 loss :  103.159974725\n",
      "Epoch :  9 Step :  167 loss :  121.597680323\n",
      "Epoch :  9 Step :  168 loss :  120.374372659\n",
      "Epoch :  9 Step :  169 loss :  107.859645572\n",
      "Epoch :  9 Step :  170 loss :  119.655228228\n",
      "Epoch :  9 Step :  171 loss :  115.393983309\n",
      "Epoch :  9 Step :  172 loss :  107.801022539\n",
      "Epoch :  9 Step :  173 loss :  109.487434668\n",
      "Epoch :  9 Step :  174 loss :  108.045007943\n",
      "Epoch :  9 Step :  175 loss :  132.323207193\n",
      "Epoch :  9 Step :  176 loss :  123.42946042\n",
      "Epoch :  9 Step :  177 loss :  120.664194949\n",
      "Epoch :  9 Step :  178 loss :  109.253025875\n",
      "Epoch :  9 Step :  179 loss :  163.741106332\n",
      "Epoch :  9 Step :  180 loss :  125.821089337\n",
      "Epoch :  9 Step :  181 loss :  92.6963423266\n",
      "Epoch :  9 Step :  182 loss :  127.504651614\n",
      "Epoch :  9 Step :  183 loss :  120.495929926\n",
      "Epoch :  9 Step :  184 loss :  113.599679186\n",
      "Epoch :  9 Step :  185 loss :  110.486463133\n",
      "Epoch :  9 Step :  186 loss :  110.559535291\n",
      "Epoch :  9 Step :  187 loss :  124.803040787\n",
      "Epoch :  9 Step :  188 loss :  143.618784162\n",
      "Epoch :  9 Step :  189 loss :  123.595866141\n",
      "Epoch :  9 Step :  190 loss :  115.811628621\n",
      "Epoch :  9 Step :  191 loss :  83.3987911075\n",
      "Epoch :  9 Step :  192 loss :  74.9874721685\n",
      "Epoch :  9 Step :  193 loss :  127.645451106\n",
      "Epoch :  9 Step :  194 loss :  118.919955499\n",
      "Epoch :  9 Step :  195 loss :  111.558641145\n",
      "Epoch :  9 Step :  196 loss :  94.8651932052\n",
      "Epoch :  9 Step :  197 loss :  113.96786048\n",
      "Epoch :  9 Step :  198 loss :  116.414311663\n",
      "Epoch :  9 Step :  199 loss :  134.624196588\n",
      "Epoch :  9 Step :  200 loss :  139.2490223\n",
      "Epoch :  9 Step :  201 loss :  108.33922359\n",
      "Epoch :  9 Step :  202 loss :  114.727959472\n",
      "Epoch :  9 Step :  203 loss :  111.337953129\n",
      "Epoch :  9 Step :  204 loss :  124.453350868\n",
      "Epoch :  9 Step :  205 loss :  136.553256398\n",
      "Epoch :  9 Step :  206 loss :  126.702052126\n",
      "Epoch :  9 Step :  207 loss :  112.766972129\n",
      "Epoch :  9 Step :  208 loss :  92.471654904\n",
      "Epoch :  9 Step :  209 loss :  117.870330298\n",
      "Epoch :  9 Step :  210 loss :  124.691954173\n",
      "Epoch :  9 Step :  211 loss :  130.477318394\n",
      "Epoch :  9 Step :  212 loss :  102.064575949\n",
      "Epoch :  9 Step :  213 loss :  145.020039665\n",
      "Epoch :  9 Step :  214 loss :  143.871750036\n",
      "Epoch :  9 Step :  215 loss :  122.144971888\n",
      "Epoch :  9 Step :  216 loss :  139.173607513\n",
      "Epoch :  9 Step :  217 loss :  115.228168955\n",
      "Epoch :  9 Step :  218 loss :  140.819435366\n",
      "Epoch :  9 Step :  219 loss :  151.535416911\n",
      "Epoch :  10 Step :  0 loss :  104.557149807\n",
      "Epoch :  10 Step :  1 loss :  119.955138363\n",
      "Epoch :  10 Step :  2 loss :  123.783220969\n",
      "Epoch :  10 Step :  3 loss :  104.439493126\n",
      "Epoch :  10 Step :  4 loss :  145.230700192\n",
      "Epoch :  10 Step :  5 loss :  115.90734519\n",
      "Epoch :  10 Step :  6 loss :  90.50690169\n",
      "Epoch :  10 Step :  7 loss :  97.2392952602\n",
      "Epoch :  10 Step :  8 loss :  116.104747467\n",
      "Epoch :  10 Step :  9 loss :  117.931758497\n",
      "Epoch :  10 Step :  10 loss :  112.303406261\n",
      "Epoch :  10 Step :  11 loss :  139.843262509\n",
      "Epoch :  10 Step :  12 loss :  88.6503431443\n",
      "Epoch :  10 Step :  13 loss :  115.095400868\n",
      "Epoch :  10 Step :  14 loss :  126.156864707\n",
      "Epoch :  10 Step :  15 loss :  137.904377037\n",
      "Epoch :  10 Step :  16 loss :  91.35673709\n",
      "Epoch :  10 Step :  17 loss :  113.349957615\n",
      "Epoch :  10 Step :  18 loss :  100.98099736\n",
      "Epoch :  10 Step :  19 loss :  98.3814987016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  10 Step :  20 loss :  146.949248589\n",
      "Epoch :  10 Step :  21 loss :  150.616378719\n",
      "Epoch :  10 Step :  22 loss :  118.367503906\n",
      "Epoch :  10 Step :  23 loss :  94.5477025728\n",
      "Epoch :  10 Step :  24 loss :  111.873364899\n",
      "Epoch :  10 Step :  25 loss :  123.014733356\n",
      "Epoch :  10 Step :  26 loss :  92.6976456737\n",
      "Epoch :  10 Step :  27 loss :  98.6919459819\n",
      "Epoch :  10 Step :  28 loss :  109.173946949\n",
      "Epoch :  10 Step :  29 loss :  99.8795447075\n",
      "Epoch :  10 Step :  30 loss :  125.490011382\n",
      "Epoch :  10 Step :  31 loss :  112.082234576\n",
      "Epoch :  10 Step :  32 loss :  107.97069446\n",
      "Epoch :  10 Step :  33 loss :  110.412168276\n",
      "Epoch :  10 Step :  34 loss :  107.133328173\n",
      "Epoch :  10 Step :  35 loss :  142.894800169\n",
      "Epoch :  10 Step :  36 loss :  104.399908921\n",
      "Epoch :  10 Step :  37 loss :  118.348122038\n",
      "Epoch :  10 Step :  38 loss :  123.774543659\n",
      "Epoch :  10 Step :  39 loss :  134.594286842\n",
      "Epoch :  10 Step :  40 loss :  112.079634211\n",
      "Epoch :  10 Step :  41 loss :  120.168524689\n",
      "Epoch :  10 Step :  42 loss :  104.969008814\n",
      "Epoch :  10 Step :  43 loss :  117.12664977\n",
      "Epoch :  10 Step :  44 loss :  110.182198747\n",
      "Epoch :  10 Step :  45 loss :  122.804124554\n",
      "Epoch :  10 Step :  46 loss :  137.641805579\n",
      "Epoch :  10 Step :  47 loss :  151.177271665\n",
      "Epoch :  10 Step :  48 loss :  127.7565853\n",
      "Epoch :  10 Step :  49 loss :  119.05019195\n",
      "Epoch :  10 Step :  50 loss :  125.973911796\n",
      "Epoch :  10 Step :  51 loss :  82.5327022518\n",
      "Epoch :  10 Step :  52 loss :  101.076914478\n",
      "Epoch :  10 Step :  53 loss :  102.393249128\n",
      "Epoch :  10 Step :  54 loss :  132.515338068\n",
      "Epoch :  10 Step :  55 loss :  131.538749181\n",
      "Epoch :  10 Step :  56 loss :  138.905361737\n",
      "Epoch :  10 Step :  57 loss :  126.268886865\n",
      "Epoch :  10 Step :  58 loss :  100.412893357\n",
      "Epoch :  10 Step :  59 loss :  121.249689962\n",
      "Epoch :  10 Step :  60 loss :  108.087753604\n",
      "Epoch :  10 Step :  61 loss :  116.646868394\n",
      "Epoch :  10 Step :  62 loss :  126.325800789\n",
      "Epoch :  10 Step :  63 loss :  100.275590307\n",
      "Epoch :  10 Step :  64 loss :  126.705106063\n",
      "Epoch :  10 Step :  65 loss :  95.932778056\n",
      "Epoch :  10 Step :  66 loss :  133.450384375\n",
      "Epoch :  10 Step :  67 loss :  122.164001656\n",
      "Epoch :  10 Step :  68 loss :  97.5817825127\n",
      "Epoch :  10 Step :  69 loss :  149.583593968\n",
      "Epoch :  10 Step :  70 loss :  144.85219581\n",
      "Epoch :  10 Step :  71 loss :  117.200417676\n",
      "Epoch :  10 Step :  72 loss :  136.580579651\n",
      "Epoch :  10 Step :  73 loss :  119.078254129\n",
      "Epoch :  10 Step :  74 loss :  94.4575881199\n",
      "Epoch :  10 Step :  75 loss :  126.008440553\n",
      "Epoch :  10 Step :  76 loss :  170.763941095\n",
      "Epoch :  10 Step :  77 loss :  116.190888053\n",
      "Epoch :  10 Step :  78 loss :  80.4257751262\n",
      "Epoch :  10 Step :  79 loss :  134.672089285\n",
      "Epoch :  10 Step :  80 loss :  121.409676049\n",
      "Epoch :  10 Step :  81 loss :  113.51221457\n",
      "Epoch :  10 Step :  82 loss :  128.598306201\n",
      "Epoch :  10 Step :  83 loss :  135.721191948\n",
      "Epoch :  10 Step :  84 loss :  101.723166992\n",
      "Epoch :  10 Step :  85 loss :  147.47847833\n",
      "Epoch :  10 Step :  86 loss :  82.2970988507\n",
      "Epoch :  10 Step :  87 loss :  103.720373617\n",
      "Epoch :  10 Step :  88 loss :  135.12902795\n",
      "Epoch :  10 Step :  89 loss :  85.0947457221\n",
      "Epoch :  10 Step :  90 loss :  110.79135704\n",
      "Epoch :  10 Step :  91 loss :  131.338412711\n",
      "Epoch :  10 Step :  92 loss :  116.264664949\n",
      "Epoch :  10 Step :  93 loss :  107.909336604\n",
      "Epoch :  10 Step :  94 loss :  102.332339324\n",
      "Epoch :  10 Step :  95 loss :  101.752895539\n",
      "Epoch :  10 Step :  96 loss :  107.552186012\n",
      "Epoch :  10 Step :  97 loss :  113.068581688\n",
      "Epoch :  10 Step :  98 loss :  112.985920543\n",
      "Epoch :  10 Step :  99 loss :  122.35938459\n",
      "Epoch :  10 Step :  100 loss :  87.4428183844\n",
      "Epoch :  10 Step :  101 loss :  95.6085197173\n",
      "Epoch :  10 Step :  102 loss :  124.786854868\n",
      "Epoch :  10 Step :  103 loss :  122.327297691\n",
      "Epoch :  10 Step :  104 loss :  126.587178084\n",
      "Epoch :  10 Step :  105 loss :  107.996060429\n",
      "Epoch :  10 Step :  106 loss :  83.6082359338\n",
      "Epoch :  10 Step :  107 loss :  96.0022866792\n",
      "Epoch :  10 Step :  108 loss :  110.962119866\n",
      "Epoch :  10 Step :  109 loss :  112.799011118\n",
      "Epoch :  10 Step :  110 loss :  128.602902995\n",
      "Epoch :  10 Step :  111 loss :  82.8149674815\n",
      "Epoch :  10 Step :  112 loss :  132.734242094\n",
      "Epoch :  10 Step :  113 loss :  124.846936859\n",
      "Epoch :  10 Step :  114 loss :  93.1762560818\n",
      "Epoch :  10 Step :  115 loss :  104.534464383\n",
      "Epoch :  10 Step :  116 loss :  120.538611397\n",
      "Epoch :  10 Step :  117 loss :  132.326952335\n",
      "Epoch :  10 Step :  118 loss :  136.426686135\n",
      "Epoch :  10 Step :  119 loss :  94.235997554\n",
      "Epoch :  10 Step :  120 loss :  113.170071431\n",
      "Epoch :  10 Step :  121 loss :  100.292481088\n",
      "Epoch :  10 Step :  122 loss :  120.65161665\n",
      "Epoch :  10 Step :  123 loss :  117.885933384\n",
      "Epoch :  10 Step :  124 loss :  101.656684275\n",
      "Epoch :  10 Step :  125 loss :  112.574029245\n",
      "Epoch :  10 Step :  126 loss :  113.722084019\n",
      "Epoch :  10 Step :  127 loss :  88.8146321611\n",
      "Epoch :  10 Step :  128 loss :  108.882116248\n",
      "Epoch :  10 Step :  129 loss :  131.762313524\n",
      "Epoch :  10 Step :  130 loss :  76.8482521139\n",
      "Epoch :  10 Step :  131 loss :  147.677563271\n",
      "Epoch :  10 Step :  132 loss :  93.5369438074\n",
      "Epoch :  10 Step :  133 loss :  136.818179253\n",
      "Epoch :  10 Step :  134 loss :  138.775676579\n",
      "Epoch :  10 Step :  135 loss :  146.231352845\n",
      "Epoch :  10 Step :  136 loss :  122.504444934\n",
      "Epoch :  10 Step :  137 loss :  111.84974873\n",
      "Epoch :  10 Step :  138 loss :  110.483378237\n",
      "Epoch :  10 Step :  139 loss :  126.626994449\n",
      "Epoch :  10 Step :  140 loss :  91.5730092334\n",
      "Epoch :  10 Step :  141 loss :  125.385917722\n",
      "Epoch :  10 Step :  142 loss :  120.643295622\n",
      "Epoch :  10 Step :  143 loss :  108.014322528\n",
      "Epoch :  10 Step :  144 loss :  151.133886017\n",
      "Epoch :  10 Step :  145 loss :  123.490701437\n",
      "Epoch :  10 Step :  146 loss :  109.88110242\n",
      "Epoch :  10 Step :  147 loss :  138.636139559\n",
      "Epoch :  10 Step :  148 loss :  100.993615164\n",
      "Epoch :  10 Step :  149 loss :  140.548013245\n",
      "Epoch :  10 Step :  150 loss :  116.884328503\n",
      "Epoch :  10 Step :  151 loss :  112.141043711\n",
      "Epoch :  10 Step :  152 loss :  140.047180924\n",
      "Epoch :  10 Step :  153 loss :  101.792527851\n",
      "Epoch :  10 Step :  154 loss :  125.446734117\n",
      "Epoch :  10 Step :  155 loss :  117.744193429\n",
      "Epoch :  10 Step :  156 loss :  117.351662062\n",
      "Epoch :  10 Step :  157 loss :  130.035113084\n",
      "Epoch :  10 Step :  158 loss :  122.526467011\n",
      "Epoch :  10 Step :  159 loss :  91.7260640057\n",
      "Epoch :  10 Step :  160 loss :  116.61916833\n",
      "Epoch :  10 Step :  161 loss :  96.1707557848\n",
      "Epoch :  10 Step :  162 loss :  114.169435278\n",
      "Epoch :  10 Step :  163 loss :  111.447960736\n",
      "Epoch :  10 Step :  164 loss :  91.4532533728\n",
      "Epoch :  10 Step :  165 loss :  121.685870316\n",
      "Epoch :  10 Step :  166 loss :  98.1730438547\n",
      "Epoch :  10 Step :  167 loss :  116.173619893\n",
      "Epoch :  10 Step :  168 loss :  115.555833927\n",
      "Epoch :  10 Step :  169 loss :  104.813128145\n",
      "Epoch :  10 Step :  170 loss :  115.755898764\n",
      "Epoch :  10 Step :  171 loss :  107.628375226\n",
      "Epoch :  10 Step :  172 loss :  100.494372162\n",
      "Epoch :  10 Step :  173 loss :  104.782722967\n",
      "Epoch :  10 Step :  174 loss :  102.950643304\n",
      "Epoch :  10 Step :  175 loss :  129.092552533\n",
      "Epoch :  10 Step :  176 loss :  119.317788975\n",
      "Epoch :  10 Step :  177 loss :  113.89893481\n",
      "Epoch :  10 Step :  178 loss :  107.410229058\n",
      "Epoch :  10 Step :  179 loss :  160.112055775\n",
      "Epoch :  10 Step :  180 loss :  121.876413654\n",
      "Epoch :  10 Step :  181 loss :  88.3614771053\n",
      "Epoch :  10 Step :  182 loss :  124.173877014\n",
      "Epoch :  10 Step :  183 loss :  115.448210133\n",
      "Epoch :  10 Step :  184 loss :  107.631570855\n",
      "Epoch :  10 Step :  185 loss :  104.666863943\n",
      "Epoch :  10 Step :  186 loss :  104.986407239\n",
      "Epoch :  10 Step :  187 loss :  118.070984846\n",
      "Epoch :  10 Step :  188 loss :  133.949609549\n",
      "Epoch :  10 Step :  189 loss :  118.980497701\n",
      "Epoch :  10 Step :  190 loss :  106.835010287\n",
      "Epoch :  10 Step :  191 loss :  77.2870720069\n",
      "Epoch :  10 Step :  192 loss :  69.7019624572\n",
      "Epoch :  10 Step :  193 loss :  121.982873306\n",
      "Epoch :  10 Step :  194 loss :  113.139206631\n",
      "Epoch :  10 Step :  195 loss :  106.860661098\n",
      "Epoch :  10 Step :  196 loss :  88.2973475419\n",
      "Epoch :  10 Step :  197 loss :  108.985344643\n",
      "Epoch :  10 Step :  198 loss :  110.111946656\n",
      "Epoch :  10 Step :  199 loss :  130.239286566\n",
      "Epoch :  10 Step :  200 loss :  131.785590678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  10 Step :  201 loss :  102.096150298\n",
      "Epoch :  10 Step :  202 loss :  108.30094225\n",
      "Epoch :  10 Step :  203 loss :  105.336903249\n",
      "Epoch :  10 Step :  204 loss :  119.988053094\n",
      "Epoch :  10 Step :  205 loss :  130.199818385\n",
      "Epoch :  10 Step :  206 loss :  117.862630048\n",
      "Epoch :  10 Step :  207 loss :  106.07302636\n",
      "Epoch :  10 Step :  208 loss :  88.6394398211\n",
      "Epoch :  10 Step :  209 loss :  110.804021322\n",
      "Epoch :  10 Step :  210 loss :  115.798836691\n",
      "Epoch :  10 Step :  211 loss :  123.04286415\n",
      "Epoch :  10 Step :  212 loss :  98.4832722737\n",
      "Epoch :  10 Step :  213 loss :  133.37063371\n",
      "Epoch :  10 Step :  214 loss :  140.158349498\n",
      "Epoch :  10 Step :  215 loss :  114.237765516\n",
      "Epoch :  10 Step :  216 loss :  130.882794595\n",
      "Epoch :  10 Step :  217 loss :  106.955192888\n",
      "Epoch :  10 Step :  218 loss :  130.997083414\n",
      "Epoch :  10 Step :  219 loss :  147.583309329\n",
      "Epoch :  11 Step :  0 loss :  103.717368591\n",
      "Epoch :  11 Step :  1 loss :  116.853704565\n",
      "Epoch :  11 Step :  2 loss :  120.553157699\n",
      "Epoch :  11 Step :  3 loss :  101.904552196\n",
      "Epoch :  11 Step :  4 loss :  142.322046431\n",
      "Epoch :  11 Step :  5 loss :  114.988541652\n",
      "Epoch :  11 Step :  6 loss :  89.4378910651\n",
      "Epoch :  11 Step :  7 loss :  95.5685673517\n",
      "Epoch :  11 Step :  8 loss :  114.086485558\n",
      "Epoch :  11 Step :  9 loss :  115.903439698\n",
      "Epoch :  11 Step :  10 loss :  110.431840875\n",
      "Epoch :  11 Step :  11 loss :  137.716670591\n",
      "Epoch :  11 Step :  12 loss :  84.2527179265\n",
      "Epoch :  11 Step :  13 loss :  112.763856991\n",
      "Epoch :  11 Step :  14 loss :  125.173826769\n",
      "Epoch :  11 Step :  15 loss :  132.105976063\n",
      "Epoch :  11 Step :  16 loss :  89.2130366363\n",
      "Epoch :  11 Step :  17 loss :  110.836958595\n",
      "Epoch :  11 Step :  18 loss :  99.3992284011\n",
      "Epoch :  11 Step :  19 loss :  95.779873115\n",
      "Epoch :  11 Step :  20 loss :  144.212677224\n",
      "Epoch :  11 Step :  21 loss :  146.567029288\n",
      "Epoch :  11 Step :  22 loss :  115.268428098\n",
      "Epoch :  11 Step :  23 loss :  93.6597326453\n",
      "Epoch :  11 Step :  24 loss :  107.579038511\n",
      "Epoch :  11 Step :  25 loss :  120.067116193\n",
      "Epoch :  11 Step :  26 loss :  89.9517301726\n",
      "Epoch :  11 Step :  27 loss :  96.1519717917\n",
      "Epoch :  11 Step :  28 loss :  106.226029143\n",
      "Epoch :  11 Step :  29 loss :  96.8021955587\n",
      "Epoch :  11 Step :  30 loss :  123.149313509\n",
      "Epoch :  11 Step :  31 loss :  108.64998537\n",
      "Epoch :  11 Step :  32 loss :  104.584184714\n",
      "Epoch :  11 Step :  33 loss :  108.168493992\n",
      "Epoch :  11 Step :  34 loss :  103.620072588\n",
      "Epoch :  11 Step :  35 loss :  139.059282968\n",
      "Epoch :  11 Step :  36 loss :  100.333077338\n",
      "Epoch :  11 Step :  37 loss :  115.337663999\n",
      "Epoch :  11 Step :  38 loss :  119.322855021\n",
      "Epoch :  11 Step :  39 loss :  132.516849602\n",
      "Epoch :  11 Step :  40 loss :  110.04743061\n",
      "Epoch :  11 Step :  41 loss :  117.836407308\n",
      "Epoch :  11 Step :  42 loss :  102.379649116\n",
      "Epoch :  11 Step :  43 loss :  114.55471587\n",
      "Epoch :  11 Step :  44 loss :  108.12486763\n",
      "Epoch :  11 Step :  45 loss :  119.724880044\n",
      "Epoch :  11 Step :  46 loss :  134.84032898\n",
      "Epoch :  11 Step :  47 loss :  147.940939223\n",
      "Epoch :  11 Step :  48 loss :  124.96689664\n",
      "Epoch :  11 Step :  49 loss :  115.510785118\n",
      "Epoch :  11 Step :  50 loss :  123.386101798\n",
      "Epoch :  11 Step :  51 loss :  80.630100814\n",
      "Epoch :  11 Step :  52 loss :  97.9025551209\n",
      "Epoch :  11 Step :  53 loss :  99.8230286755\n",
      "Epoch :  11 Step :  54 loss :  129.70390343\n",
      "Epoch :  11 Step :  55 loss :  130.255503201\n",
      "Epoch :  11 Step :  56 loss :  135.815635535\n",
      "Epoch :  11 Step :  57 loss :  122.562735793\n",
      "Epoch :  11 Step :  58 loss :  97.8902708011\n",
      "Epoch :  11 Step :  59 loss :  117.983387995\n",
      "Epoch :  11 Step :  60 loss :  105.930317735\n",
      "Epoch :  11 Step :  61 loss :  114.210183882\n",
      "Epoch :  11 Step :  62 loss :  123.272773736\n",
      "Epoch :  11 Step :  63 loss :  96.6582383817\n",
      "Epoch :  11 Step :  64 loss :  124.335470125\n",
      "Epoch :  11 Step :  65 loss :  93.3288049898\n",
      "Epoch :  11 Step :  66 loss :  130.023067763\n",
      "Epoch :  11 Step :  67 loss :  120.217362763\n",
      "Epoch :  11 Step :  68 loss :  94.9119656857\n",
      "Epoch :  11 Step :  69 loss :  146.516068566\n",
      "Epoch :  11 Step :  70 loss :  142.064822821\n",
      "Epoch :  11 Step :  71 loss :  114.266722364\n",
      "Epoch :  11 Step :  72 loss :  132.937369674\n",
      "Epoch :  11 Step :  73 loss :  115.771591337\n",
      "Epoch :  11 Step :  74 loss :  91.3658929652\n",
      "Epoch :  11 Step :  75 loss :  123.827602419\n",
      "Epoch :  11 Step :  76 loss :  167.046132643\n",
      "Epoch :  11 Step :  77 loss :  114.081246753\n",
      "Epoch :  11 Step :  78 loss :  78.0999260165\n",
      "Epoch :  11 Step :  79 loss :  132.108713533\n",
      "Epoch :  11 Step :  80 loss :  118.23078608\n",
      "Epoch :  11 Step :  81 loss :  110.972208699\n",
      "Epoch :  11 Step :  82 loss :  125.800997273\n",
      "Epoch :  11 Step :  83 loss :  133.339350837\n",
      "Epoch :  11 Step :  84 loss :  98.1828686938\n",
      "Epoch :  11 Step :  85 loss :  144.645713701\n",
      "Epoch :  11 Step :  86 loss :  80.6981143534\n",
      "Epoch :  11 Step :  87 loss :  100.677576316\n",
      "Epoch :  11 Step :  88 loss :  132.670792646\n",
      "Epoch :  11 Step :  89 loss :  82.6365652688\n",
      "Epoch :  11 Step :  90 loss :  108.946595724\n",
      "Epoch :  11 Step :  91 loss :  128.00097761\n",
      "Epoch :  11 Step :  92 loss :  113.535258445\n",
      "Epoch :  11 Step :  93 loss :  105.2962904\n",
      "Epoch :  11 Step :  94 loss :  99.9823500189\n",
      "Epoch :  11 Step :  95 loss :  99.918724485\n",
      "Epoch :  11 Step :  96 loss :  105.034185096\n",
      "Epoch :  11 Step :  97 loss :  110.987785196\n",
      "Epoch :  11 Step :  98 loss :  111.108377173\n",
      "Epoch :  11 Step :  99 loss :  119.382771644\n",
      "Epoch :  11 Step :  100 loss :  84.7252377515\n",
      "Epoch :  11 Step :  101 loss :  93.6430663714\n",
      "Epoch :  11 Step :  102 loss :  122.320292555\n",
      "Epoch :  11 Step :  103 loss :  119.692472691\n",
      "Epoch :  11 Step :  104 loss :  123.925251954\n",
      "Epoch :  11 Step :  105 loss :  105.410879942\n",
      "Epoch :  11 Step :  106 loss :  82.2097345598\n",
      "Epoch :  11 Step :  107 loss :  92.877159368\n",
      "Epoch :  11 Step :  108 loss :  108.515304976\n",
      "Epoch :  11 Step :  109 loss :  110.233527966\n",
      "Epoch :  11 Step :  110 loss :  125.554256995\n",
      "Epoch :  11 Step :  111 loss :  81.9425087282\n",
      "Epoch :  11 Step :  112 loss :  129.783340621\n",
      "Epoch :  11 Step :  113 loss :  123.514873237\n",
      "Epoch :  11 Step :  114 loss :  91.7083731904\n",
      "Epoch :  11 Step :  115 loss :  101.792772684\n",
      "Epoch :  11 Step :  116 loss :  117.972404772\n",
      "Epoch :  11 Step :  117 loss :  129.612718582\n",
      "Epoch :  11 Step :  118 loss :  134.173234527\n",
      "Epoch :  11 Step :  119 loss :  92.8033701613\n",
      "Epoch :  11 Step :  120 loss :  111.358551242\n",
      "Epoch :  11 Step :  121 loss :  98.8169847564\n",
      "Epoch :  11 Step :  122 loss :  118.026690662\n",
      "Epoch :  11 Step :  123 loss :  115.636983371\n",
      "Epoch :  11 Step :  124 loss :  99.9926577281\n",
      "Epoch :  11 Step :  125 loss :  110.399571024\n",
      "Epoch :  11 Step :  126 loss :  111.580635249\n",
      "Epoch :  11 Step :  127 loss :  86.910329079\n",
      "Epoch :  11 Step :  128 loss :  106.08947401\n",
      "Epoch :  11 Step :  129 loss :  130.229643305\n",
      "Epoch :  11 Step :  130 loss :  75.3083898958\n",
      "Epoch :  11 Step :  131 loss :  145.577261867\n",
      "Epoch :  11 Step :  132 loss :  92.2163090372\n",
      "Epoch :  11 Step :  133 loss :  134.803107306\n",
      "Epoch :  11 Step :  134 loss :  136.850394881\n",
      "Epoch :  11 Step :  135 loss :  144.678122052\n",
      "Epoch :  11 Step :  136 loss :  120.219118612\n",
      "Epoch :  11 Step :  137 loss :  109.765193695\n",
      "Epoch :  11 Step :  138 loss :  108.713393973\n",
      "Epoch :  11 Step :  139 loss :  124.28733942\n",
      "Epoch :  11 Step :  140 loss :  89.7351304987\n",
      "Epoch :  11 Step :  141 loss :  123.806362584\n",
      "Epoch :  11 Step :  142 loss :  119.019634527\n",
      "Epoch :  11 Step :  143 loss :  105.455850637\n",
      "Epoch :  11 Step :  144 loss :  149.044534186\n",
      "Epoch :  11 Step :  145 loss :  121.077095142\n",
      "Epoch :  11 Step :  146 loss :  108.081425398\n",
      "Epoch :  11 Step :  147 loss :  137.055036025\n",
      "Epoch :  11 Step :  148 loss :  99.4518939484\n",
      "Epoch :  11 Step :  149 loss :  137.943196501\n",
      "Epoch :  11 Step :  150 loss :  114.943299948\n",
      "Epoch :  11 Step :  151 loss :  110.208200074\n",
      "Epoch :  11 Step :  152 loss :  137.662985045\n",
      "Epoch :  11 Step :  153 loss :  99.9322157581\n",
      "Epoch :  11 Step :  154 loss :  123.918141705\n",
      "Epoch :  11 Step :  155 loss :  115.20250779\n",
      "Epoch :  11 Step :  156 loss :  114.416665741\n",
      "Epoch :  11 Step :  157 loss :  128.442720167\n",
      "Epoch :  11 Step :  158 loss :  120.894148301\n",
      "Epoch :  11 Step :  159 loss :  89.5465033868\n",
      "Epoch :  11 Step :  160 loss :  115.482449032\n",
      "Epoch :  11 Step :  161 loss :  94.5497918221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  11 Step :  162 loss :  112.247104758\n",
      "Epoch :  11 Step :  163 loss :  109.841597285\n",
      "Epoch :  11 Step :  164 loss :  89.7987439662\n",
      "Epoch :  11 Step :  165 loss :  119.953684642\n",
      "Epoch :  11 Step :  166 loss :  96.7929440101\n",
      "Epoch :  11 Step :  167 loss :  114.977573312\n",
      "Epoch :  11 Step :  168 loss :  113.870559985\n",
      "Epoch :  11 Step :  169 loss :  102.617640426\n",
      "Epoch :  11 Step :  170 loss :  113.84282777\n",
      "Epoch :  11 Step :  171 loss :  105.599494479\n",
      "Epoch :  11 Step :  172 loss :  98.267438726\n",
      "Epoch :  11 Step :  173 loss :  103.087942128\n",
      "Epoch :  11 Step :  174 loss :  101.379234677\n",
      "Epoch :  11 Step :  175 loss :  127.248947513\n",
      "Epoch :  11 Step :  176 loss :  117.364139903\n",
      "Epoch :  11 Step :  177 loss :  112.879452203\n",
      "Epoch :  11 Step :  178 loss :  106.125282806\n",
      "Epoch :  11 Step :  179 loss :  158.8325551\n",
      "Epoch :  11 Step :  180 loss :  120.358749079\n",
      "Epoch :  11 Step :  181 loss :  86.7171551057\n",
      "Epoch :  11 Step :  182 loss :  123.559407525\n",
      "Epoch :  11 Step :  183 loss :  114.484735027\n",
      "Epoch :  11 Step :  184 loss :  106.466507616\n",
      "Epoch :  11 Step :  185 loss :  103.353519684\n",
      "Epoch :  11 Step :  186 loss :  103.328362648\n",
      "Epoch :  11 Step :  187 loss :  115.857174535\n",
      "Epoch :  11 Step :  188 loss :  131.937147896\n",
      "Epoch :  11 Step :  189 loss :  117.391947187\n",
      "Epoch :  11 Step :  190 loss :  105.129245494\n",
      "Epoch :  11 Step :  191 loss :  76.1146715263\n",
      "Epoch :  11 Step :  192 loss :  68.4165063361\n",
      "Epoch :  11 Step :  193 loss :  119.925067244\n",
      "Epoch :  11 Step :  194 loss :  111.546711565\n",
      "Epoch :  11 Step :  195 loss :  104.880566246\n",
      "Epoch :  11 Step :  196 loss :  86.8728258183\n",
      "Epoch :  11 Step :  197 loss :  107.286544942\n",
      "Epoch :  11 Step :  198 loss :  108.322809879\n",
      "Epoch :  11 Step :  199 loss :  128.556705718\n",
      "Epoch :  11 Step :  200 loss :  130.090496638\n",
      "Epoch :  11 Step :  201 loss :  100.793901462\n",
      "Epoch :  11 Step :  202 loss :  106.784247351\n",
      "Epoch :  11 Step :  203 loss :  103.889251223\n",
      "Epoch :  11 Step :  204 loss :  118.478579995\n",
      "Epoch :  11 Step :  205 loss :  128.520475829\n",
      "Epoch :  11 Step :  206 loss :  115.748154422\n",
      "Epoch :  11 Step :  207 loss :  104.346736119\n",
      "Epoch :  11 Step :  208 loss :  86.8575357081\n",
      "Epoch :  11 Step :  209 loss :  109.280200744\n",
      "Epoch :  11 Step :  210 loss :  114.072786545\n",
      "Epoch :  11 Step :  211 loss :  121.433346189\n",
      "Epoch :  11 Step :  212 loss :  96.7065819901\n",
      "Epoch :  11 Step :  213 loss :  131.282182578\n",
      "Epoch :  11 Step :  214 loss :  138.840313446\n",
      "Epoch :  11 Step :  215 loss :  112.325977994\n",
      "Epoch :  11 Step :  216 loss :  129.61277072\n",
      "Epoch :  11 Step :  217 loss :  104.978542032\n",
      "Epoch :  11 Step :  218 loss :  129.497235067\n",
      "Epoch :  11 Step :  219 loss :  146.445780487\n",
      "Epoch :  12 Step :  0 loss :  101.74640273\n",
      "Epoch :  12 Step :  1 loss :  114.174179853\n",
      "Epoch :  12 Step :  2 loss :  117.837025076\n",
      "Epoch :  12 Step :  3 loss :  99.914546633\n",
      "Epoch :  12 Step :  4 loss :  140.341077608\n",
      "Epoch :  12 Step :  5 loss :  112.602335742\n",
      "Epoch :  12 Step :  6 loss :  87.7459187537\n",
      "Epoch :  12 Step :  7 loss :  93.6080967949\n",
      "Epoch :  12 Step :  8 loss :  112.001097382\n",
      "Epoch :  12 Step :  9 loss :  114.263653724\n",
      "Epoch :  12 Step :  10 loss :  108.150391866\n",
      "Epoch :  12 Step :  11 loss :  135.113962765\n",
      "Epoch :  12 Step :  12 loss :  81.7301395591\n",
      "Epoch :  12 Step :  13 loss :  110.574402186\n",
      "Epoch :  12 Step :  14 loss :  123.603451455\n",
      "Epoch :  12 Step :  15 loss :  128.776390466\n",
      "Epoch :  12 Step :  16 loss :  87.2809582819\n",
      "Epoch :  12 Step :  17 loss :  109.045859805\n",
      "Epoch :  12 Step :  18 loss :  97.8253414713\n",
      "Epoch :  12 Step :  19 loss :  94.0756991554\n",
      "Epoch :  12 Step :  20 loss :  141.450670655\n",
      "Epoch :  12 Step :  21 loss :  143.598881177\n",
      "Epoch :  12 Step :  22 loss :  112.353188196\n",
      "Epoch :  12 Step :  23 loss :  92.1306869686\n",
      "Epoch :  12 Step :  24 loss :  105.400134826\n",
      "Epoch :  12 Step :  25 loss :  117.54703567\n",
      "Epoch :  12 Step :  26 loss :  87.579648764\n",
      "Epoch :  12 Step :  27 loss :  93.8620170638\n",
      "Epoch :  12 Step :  28 loss :  104.397282437\n",
      "Epoch :  12 Step :  29 loss :  94.4835781211\n",
      "Epoch :  12 Step :  30 loss :  120.833379297\n",
      "Epoch :  12 Step :  31 loss :  105.722833325\n",
      "Epoch :  12 Step :  32 loss :  101.999317978\n",
      "Epoch :  12 Step :  33 loss :  106.225075915\n",
      "Epoch :  12 Step :  34 loss :  101.072998166\n",
      "Epoch :  12 Step :  35 loss :  136.507206774\n",
      "Epoch :  12 Step :  36 loss :  97.5987832203\n",
      "Epoch :  12 Step :  37 loss :  113.09757632\n",
      "Epoch :  12 Step :  38 loss :  116.837307491\n",
      "Epoch :  12 Step :  39 loss :  130.148518429\n",
      "Epoch :  12 Step :  40 loss :  108.117406131\n",
      "Epoch :  12 Step :  41 loss :  116.148407628\n",
      "Epoch :  12 Step :  42 loss :  100.039856555\n",
      "Epoch :  12 Step :  43 loss :  112.565065766\n",
      "Epoch :  12 Step :  44 loss :  106.350948162\n",
      "Epoch :  12 Step :  45 loss :  117.405308214\n",
      "Epoch :  12 Step :  46 loss :  132.902843166\n",
      "Epoch :  12 Step :  47 loss :  145.528593535\n",
      "Epoch :  12 Step :  48 loss :  122.893254538\n",
      "Epoch :  12 Step :  49 loss :  113.136816623\n",
      "Epoch :  12 Step :  50 loss :  121.365982029\n",
      "Epoch :  12 Step :  51 loss :  79.0767009057\n",
      "Epoch :  12 Step :  52 loss :  95.9622685892\n",
      "Epoch :  12 Step :  53 loss :  97.5901971554\n",
      "Epoch :  12 Step :  54 loss :  127.7397943\n",
      "Epoch :  12 Step :  55 loss :  128.880335492\n",
      "Epoch :  12 Step :  56 loss :  133.411942803\n",
      "Epoch :  12 Step :  57 loss :  120.090354617\n",
      "Epoch :  12 Step :  58 loss :  96.0459257655\n",
      "Epoch :  12 Step :  59 loss :  115.858940377\n",
      "Epoch :  12 Step :  60 loss :  104.341473261\n",
      "Epoch :  12 Step :  61 loss :  112.292831591\n",
      "Epoch :  12 Step :  62 loss :  120.670312266\n",
      "Epoch :  12 Step :  63 loss :  94.256258724\n",
      "Epoch :  12 Step :  64 loss :  122.874621907\n",
      "Epoch :  12 Step :  65 loss :  91.1271588365\n",
      "Epoch :  12 Step :  66 loss :  128.003087882\n",
      "Epoch :  12 Step :  67 loss :  118.407184787\n",
      "Epoch :  12 Step :  68 loss :  93.1154669664\n",
      "Epoch :  12 Step :  69 loss :  144.054014249\n",
      "Epoch :  12 Step :  70 loss :  139.82090641\n",
      "Epoch :  12 Step :  71 loss :  111.632967176\n",
      "Epoch :  12 Step :  72 loss :  130.116558906\n",
      "Epoch :  12 Step :  73 loss :  112.851221701\n",
      "Epoch :  12 Step :  74 loss :  88.8883593487\n",
      "Epoch :  12 Step :  75 loss :  122.049671011\n",
      "Epoch :  12 Step :  76 loss :  164.119975961\n",
      "Epoch :  12 Step :  77 loss :  112.121294065\n",
      "Epoch :  12 Step :  78 loss :  75.8905180604\n",
      "Epoch :  12 Step :  79 loss :  129.985376885\n",
      "Epoch :  12 Step :  80 loss :  115.78717433\n",
      "Epoch :  12 Step :  81 loss :  108.737705868\n",
      "Epoch :  12 Step :  82 loss :  123.503822556\n",
      "Epoch :  12 Step :  83 loss :  131.549025684\n",
      "Epoch :  12 Step :  84 loss :  95.4584709099\n",
      "Epoch :  12 Step :  85 loss :  142.360823965\n",
      "Epoch :  12 Step :  86 loss :  79.2183577458\n",
      "Epoch :  12 Step :  87 loss :  98.199755449\n",
      "Epoch :  12 Step :  88 loss :  130.517702213\n",
      "Epoch :  12 Step :  89 loss :  81.0178179684\n",
      "Epoch :  12 Step :  90 loss :  107.607235114\n",
      "Epoch :  12 Step :  91 loss :  125.547804812\n",
      "Epoch :  12 Step :  92 loss :  111.868790119\n",
      "Epoch :  12 Step :  93 loss :  103.130473093\n",
      "Epoch :  12 Step :  94 loss :  97.8480000552\n",
      "Epoch :  12 Step :  95 loss :  98.2064214279\n",
      "Epoch :  12 Step :  96 loss :  103.452805383\n",
      "Epoch :  12 Step :  97 loss :  109.15636646\n",
      "Epoch :  12 Step :  98 loss :  109.471505558\n",
      "Epoch :  12 Step :  99 loss :  116.633648412\n",
      "Epoch :  12 Step :  100 loss :  82.4403444966\n",
      "Epoch :  12 Step :  101 loss :  91.9004928632\n",
      "Epoch :  12 Step :  102 loss :  119.986548985\n",
      "Epoch :  12 Step :  103 loss :  117.489351857\n",
      "Epoch :  12 Step :  104 loss :  121.728526058\n",
      "Epoch :  12 Step :  105 loss :  103.550876192\n",
      "Epoch :  12 Step :  106 loss :  80.9664500677\n",
      "Epoch :  12 Step :  107 loss :  90.6836326204\n",
      "Epoch :  12 Step :  108 loss :  106.43589752\n",
      "Epoch :  12 Step :  109 loss :  108.262265535\n",
      "Epoch :  12 Step :  110 loss :  123.097540938\n",
      "Epoch :  12 Step :  111 loss :  81.0762127526\n",
      "Epoch :  12 Step :  112 loss :  127.501262977\n",
      "Epoch :  12 Step :  113 loss :  122.166489789\n",
      "Epoch :  12 Step :  114 loss :  90.4708816628\n",
      "Epoch :  12 Step :  115 loss :  99.2910414981\n",
      "Epoch :  12 Step :  116 loss :  115.67394486\n",
      "Epoch :  12 Step :  117 loss :  127.106223761\n",
      "Epoch :  12 Step :  118 loss :  131.903318028\n",
      "Epoch :  12 Step :  119 loss :  91.4499531151\n",
      "Epoch :  12 Step :  120 loss :  109.651396573\n",
      "Epoch :  12 Step :  121 loss :  97.2855061884\n",
      "Epoch :  12 Step :  122 loss :  115.865108195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  12 Step :  123 loss :  113.951072432\n",
      "Epoch :  12 Step :  124 loss :  98.5700788842\n",
      "Epoch :  12 Step :  125 loss :  108.272946441\n",
      "Epoch :  12 Step :  126 loss :  109.7693557\n",
      "Epoch :  12 Step :  127 loss :  85.1038342278\n",
      "Epoch :  12 Step :  128 loss :  103.918113308\n",
      "Epoch :  12 Step :  129 loss :  128.850256532\n",
      "Epoch :  12 Step :  130 loss :  73.8910296433\n",
      "Epoch :  12 Step :  131 loss :  143.686233124\n",
      "Epoch :  12 Step :  132 loss :  90.9639548354\n",
      "Epoch :  12 Step :  133 loss :  132.833486391\n",
      "Epoch :  12 Step :  134 loss :  135.11754362\n",
      "Epoch :  12 Step :  135 loss :  143.18866327\n",
      "Epoch :  12 Step :  136 loss :  118.041355287\n",
      "Epoch :  12 Step :  137 loss :  107.851498783\n",
      "Epoch :  12 Step :  138 loss :  106.972503148\n",
      "Epoch :  12 Step :  139 loss :  122.151196703\n",
      "Epoch :  12 Step :  140 loss :  88.2747233649\n",
      "Epoch :  12 Step :  141 loss :  122.263121971\n",
      "Epoch :  12 Step :  142 loss :  117.397280359\n",
      "Epoch :  12 Step :  143 loss :  103.26283295\n",
      "Epoch :  12 Step :  144 loss :  146.782650471\n",
      "Epoch :  12 Step :  145 loss :  118.817533343\n",
      "Epoch :  12 Step :  146 loss :  106.203278815\n",
      "Epoch :  12 Step :  147 loss :  135.338935663\n",
      "Epoch :  12 Step :  148 loss :  97.8056966525\n",
      "Epoch :  12 Step :  149 loss :  135.047997371\n"
     ]
    }
   ],
   "source": [
    "model.fit(training_data,training_data_class)\n",
    "#model.resume(training_data,training_data_class)\n",
    "#model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(len(validating_data)-np.count_nonzero(model.predict(validating_data)-validating_data_class))/5000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dumpModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing_data=test.iloc[:,1:785].copy().as_matrix()/255.0\n",
    "#testing_data=clf.transform(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_results=model.predict(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp=[i for i in range(10000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_result=np.array(zip(tmp,test_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    4]\n",
      " [   1    4]\n",
      " [   2    2]\n",
      " ..., \n",
      " [9997    3]\n",
      " [9998    7]\n",
      " [9999    3]]\n"
     ]
    }
   ],
   "source": [
    "print csv_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('./res.csv',csv_result,delimiter=',',fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
